{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6283161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need a way to specify unique model name, or save model outputs based on indices.\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from model_data_definitions import *\n",
    "from concurrent.futures import ThreadPoolExecutor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fea57a98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>n_instances</th>\n",
       "      <th>n_features</th>\n",
       "      <th>n_binary_features</th>\n",
       "      <th>n_categorical_features</th>\n",
       "      <th>n_continuous_features</th>\n",
       "      <th>endpoint_type</th>\n",
       "      <th>n_classes</th>\n",
       "      <th>imbalance</th>\n",
       "      <th>task</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1029_LEV</td>\n",
       "      <td>1000</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>continuous</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.111245</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1030_ERA</td>\n",
       "      <td>1000</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>continuous</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.031251</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    dataset  n_instances  n_features  n_binary_features  \\\n",
       "2  1029_LEV         1000           4                  0   \n",
       "3  1030_ERA         1000           4                  0   \n",
       "\n",
       "   n_categorical_features  n_continuous_features endpoint_type  n_classes  \\\n",
       "2                       0                      4    continuous        5.0   \n",
       "3                       0                      4    continuous        9.0   \n",
       "\n",
       "   imbalance        task  \n",
       "2   0.111245  regression  \n",
       "3   0.031251  regression  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6bbd04bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    dataset  n_instances  n_features  n_binary_features  \\\n",
      "2  1029_LEV         1000           4                  0   \n",
      "3  1030_ERA         1000           4                  0   \n",
      "\n",
      "   n_categorical_features  n_continuous_features endpoint_type  n_classes  \\\n",
      "2                       0                      4    continuous        5.0   \n",
      "3                       0                      4    continuous        9.0   \n",
      "\n",
      "   imbalance        task  \n",
      "2   0.111245  regression  \n",
      "3   0.031251  regression  \n",
      "Evaluating dataset: 1029_LEV\n",
      "     In1  In2  In3  In4  target\n",
      "0    4.0  2.0  3.0  0.0     3.0\n",
      "1    3.0  3.0  0.0  3.0     3.0\n",
      "2    2.0  4.0  1.0  0.0     2.0\n",
      "3    2.0  1.0  2.0  3.0     2.0\n",
      "4    2.0  3.0  4.0  2.0     2.0\n",
      "..   ...  ...  ...  ...     ...\n",
      "995  2.0  2.0  1.0  4.0     2.0\n",
      "996  1.0  2.0  2.0  3.0     2.0\n",
      "997  0.0  0.0  1.0  4.0     0.0\n",
      "998  0.0  2.0  1.0  3.0     1.0\n",
      "999  2.0  0.0  3.0  4.0     1.0\n",
      "\n",
      "[1000 rows x 5 columns]\n",
      "Evaluating dataset: 1030_ERA\n",
      "      in1   in2   in3   in4  target\n",
      "0    13.0   6.0  12.0   2.0     4.0\n",
      "1     2.0   7.0   9.0   2.0     2.0\n",
      "2    12.0   8.0   7.0   6.0     7.0\n",
      "3     7.0  10.0   8.0  13.0     6.0\n",
      "4    13.0   6.0   5.0   0.0     4.0\n",
      "..    ...   ...   ...   ...     ...\n",
      "995   2.0  14.0   2.0   9.0     1.0\n",
      "996   5.0   7.0   3.0  12.0     3.0\n",
      "997   1.0   2.0  12.0   4.0     3.0\n",
      "998   1.0   2.0  12.0   6.0     2.0\n",
      "999  10.0   3.0   6.0  14.0     2.0\n",
      "\n",
      "[1000 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# expensive and slow operation done once.\n",
    "filtered_datasets, datasets = fetch_return_filtered_pmlb_data_sets() \n",
    "print(filtered_datasets)\n",
    "\n",
    "for dataset, row in zip(datasets, filtered_datasets.iterrows()):\n",
    "    dataset_name = row[1]['dataset']\n",
    "    print(f\"Evaluating dataset: {dataset_name}\")\n",
    "\n",
    "    print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ed617ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import multiprocessing as mp\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "def generate_cross_validation_dataset(data, num_folds):\n",
    "    X, y = data.drop('target', axis=1).values, data['target'].values\n",
    "    \n",
    "    dataset_list = []\n",
    "    kf = KFold(n_splits=num_folds)\n",
    "    fold = 0\n",
    "\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        fold += 1\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        dataset_list.append((X_train, y_train, X_test, y_test , fold))\n",
    "    \n",
    "    return dataset_list\n",
    "\n",
    "def train_evaluate_model(model_tuple, fold_data, epoch_number):\n",
    "    \n",
    "    model, name = model_tuple\n",
    "    X_train, y_train, X_test, y_test , fold = fold_data\n",
    "    \n",
    "    history = model.fit(X_train, y_train,\n",
    "                        epochs=epoch_number,\n",
    "                        verbose=0,\n",
    "                        validation_data=(X_test, y_test))\n",
    "\n",
    "    loss = model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "    predictions = model.predict(X_test)\n",
    "    r_squared_value = r2_score(y_test,predictions)\n",
    "    test_error = mean_squared_error(y_test,predictions)\n",
    "\n",
    "    results = {\n",
    "        'model': name,\n",
    "        'fold': fold,\n",
    "        'train_history': history.history['loss'],\n",
    "        'val_history': history.history['val_loss'],\n",
    "        'loss': loss,\n",
    "        'r_squared_value': r_squared_value,\n",
    "        'test_error': test_error}\n",
    "    \n",
    "    return results\n",
    "\n",
    "def evaluate_models_parallel(fold_data, dataset_name):\n",
    "    \n",
    "    models = initialize_all_models(fold_data[0].shape[1], seed_val=fold_data[4])\n",
    "    compile_models(models)\n",
    "\n",
    "    results = []\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        futures = {executor.submit(train_evaluate_model, model, fold_data, 2): model for model in models}\n",
    "        for future in futures:\n",
    "            result = future.result()\n",
    "            results.append(result)\n",
    "            print(f'Trained {futures[future][1]} on {dataset_name}, fold {fold_data[4]}')\n",
    "    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5e77d639",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    dataset  n_instances  n_features  n_binary_features  \\\n",
      "2  1029_LEV         1000           4                  0   \n",
      "3  1030_ERA         1000           4                  0   \n",
      "\n",
      "   n_categorical_features  n_continuous_features endpoint_type  n_classes  \\\n",
      "2                       0                      4    continuous        5.0   \n",
      "3                       0                      4    continuous        9.0   \n",
      "\n",
      "   imbalance        task  \n",
      "2   0.111245  regression  \n",
      "3   0.031251  regression  \n",
      "Evaluating dataset: 1029_LEV\n",
      "     In1  In2  In3  In4  target\n",
      "0    4.0  2.0  3.0  0.0     3.0\n",
      "1    3.0  3.0  0.0  3.0     3.0\n",
      "2    2.0  4.0  1.0  0.0     2.0\n",
      "3    2.0  1.0  2.0  3.0     2.0\n",
      "4    2.0  3.0  4.0  2.0     2.0\n",
      "..   ...  ...  ...  ...     ...\n",
      "995  2.0  2.0  1.0  4.0     2.0\n",
      "996  1.0  2.0  2.0  3.0     2.0\n",
      "997  0.0  0.0  1.0  4.0     0.0\n",
      "998  0.0  2.0  1.0  3.0     1.0\n",
      "999  2.0  0.0  3.0  4.0     1.0\n",
      "\n",
      "[1000 rows x 5 columns]\n",
      "Evaluating dataset: 1030_ERA\n",
      "      in1   in2   in3   in4  target\n",
      "0    13.0   6.0  12.0   2.0     4.0\n",
      "1     2.0   7.0   9.0   2.0     2.0\n",
      "2    12.0   8.0   7.0   6.0     7.0\n",
      "3     7.0  10.0   8.0  13.0     6.0\n",
      "4    13.0   6.0   5.0   0.0     4.0\n",
      "..    ...   ...   ...   ...     ...\n",
      "995   2.0  14.0   2.0   9.0     1.0\n",
      "996   5.0   7.0   3.0  12.0     3.0\n",
      "997   1.0   2.0  12.0   4.0     3.0\n",
      "998   1.0   2.0  12.0   6.0     2.0\n",
      "999  10.0   3.0   6.0  14.0     2.0\n",
      "\n",
      "[1000 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# expensive and slow operation done once.\n",
    "filtered_datasets_metadata, datasets = fetch_return_filtered_pmlb_data_sets() \n",
    "print(filtered_datasets_metadata)\n",
    "\n",
    "num_folds = 3\n",
    "\n",
    "list_of_kfold_datasets = []\n",
    "for dataset, row in zip(datasets, filtered_datasets_metadata.iterrows()):\n",
    "    dataset_name = row[1]['dataset']\n",
    "    print(f\"Evaluating dataset: {dataset_name}\")\n",
    "    print(dataset)\n",
    "    list_of_kfold_datasets.append(generate_cross_validation_dataset(dataset, num_folds))\n",
    "    \n",
    "evaluate_models_parallel(list_of_kfold_datasets[0][0], '1029_LEV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "edd188b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 4ms/step\n",
      "Trained Linear Model on 1029_LEV, fold 1\n",
      "11/11 [==============================] - 0s 4ms/step\n",
      "Trained Wide ReLU ANN on 1029_LEV, fold 1\n",
      "11/11 [==============================] - 0s 6ms/step\n",
      "11/11 [==============================] - 0s 5ms/step\n",
      "11/11 [==============================] - 0s 6ms/step\n",
      "11/11 [==============================] - 0s 7ms/step\n",
      "11/11 [==============================] - 0s 6ms/step\n",
      "11/11 [==============================] - 0s 4ms/step\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "Trained Deep ReLU ANN on 1029_LEV, fold 1\n",
      "Trained One Parameter on 1029_LEV, fold 1\n",
      "11/11 [==============================] - 1s 4ms/step\n",
      "Trained Spline ANN (z=1) on 1029_LEV, fold 1\n",
      "Trained Lookup Table (z=1) on 1029_LEV, fold 1\n",
      "11/11 [==============================] - 1s 2ms/step\n",
      "11/11 [==============================] - 1s 3ms/step\n",
      "11/11 [==============================] - 1s 2ms/step\n",
      "11/11 [==============================] - 1s 2ms/step\n",
      "11/11 [==============================] - 1s 2ms/step\n",
      "11/11 [==============================] - 1s 3ms/step\n",
      "11/11 [==============================] - 1s 3ms/step\n",
      "11/11 [==============================] - 1s 2ms/step\n",
      "11/11 [==============================] - 0s 1ms/step\n",
      "Trained ABEL-Spline (z=1) on 1029_LEV, fold 1\n",
      "Trained Spline ANN (z=2) on 1029_LEV, fold 1\n",
      "Trained Lookup Table (z=2) on 1029_LEV, fold 1\n",
      "Trained ABEL-Spline (z=2) on 1029_LEV, fold 1\n",
      "Trained Spline ANN (z=4) on 1029_LEV, fold 1\n",
      "Trained Lookup Table (z=4) on 1029_LEV, fold 1\n",
      "Trained ABEL-Spline (z=4) on 1029_LEV, fold 1\n",
      "Trained Spline ANN (z=8) on 1029_LEV, fold 1\n",
      "Trained Lookup Table (z=8) on 1029_LEV, fold 1\n",
      "Trained ABEL-Spline (z=8) on 1029_LEV, fold 1\n",
      "Trained Spline ANN (z=10) on 1029_LEV, fold 1\n",
      "Trained Lookup Table (z=10) on 1029_LEV, fold 1\n",
      "Trained ABEL-Spline (z=10) on 1029_LEV, fold 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'model': 'Linear Model',\n",
       "  'fold': 1,\n",
       "  'train_history': [1.9475066661834717, 1.8716416358947754],\n",
       "  'val_history': [1.9166139364242554, 1.8463597297668457],\n",
       "  'loss': 1.8463597297668457,\n",
       "  'r_squared_value': -4.387006978549823,\n",
       "  'test_error': 5.201381330215842},\n",
       " {'model': 'Wide ReLU ANN',\n",
       "  'fold': 1,\n",
       "  'train_history': [1.1485446691513062, 0.5165647864341736],\n",
       "  'val_history': [0.6381819844245911, 0.517496645450592],\n",
       "  'loss': 0.517496645450592,\n",
       "  'r_squared_value': 0.5063415902226197,\n",
       "  'test_error': 0.47664791345997687},\n",
       " {'model': 'Deep ReLU ANN',\n",
       "  'fold': 1,\n",
       "  'train_history': [0.8637235164642334, 0.7284939885139465],\n",
       "  'val_history': [0.8072277903556824, 0.6935036778450012],\n",
       "  'loss': 0.6935036778450012,\n",
       "  'r_squared_value': 0.18787895420174738,\n",
       "  'test_error': 0.7841369543997757},\n",
       " {'model': 'One Parameter',\n",
       "  'fold': 1,\n",
       "  'train_history': [2.7603604793548584, 2.7393605709075928],\n",
       "  'val_history': [2.7933714389801025, 2.772371530532837],\n",
       "  'loss': 2.772371530532837,\n",
       "  'r_squared_value': -7.96034313033142,\n",
       "  'test_error': 8.651587357508856},\n",
       " {'model': 'Spline ANN (z=1)',\n",
       "  'fold': 1,\n",
       "  'train_history': [1.767303705215454, 1.7024962902069092],\n",
       "  'val_history': [1.7754851579666138, 1.7134804725646973],\n",
       "  'loss': 1.7134804725646973,\n",
       "  'r_squared_value': -2.9706259218223314,\n",
       "  'test_error': 3.833805974500044},\n",
       " {'model': 'Lookup Table (z=1)',\n",
       "  'fold': 1,\n",
       "  'train_history': [2.7603604793548584, 2.7393605709075928],\n",
       "  'val_history': [2.7933714389801025, 2.772371530532837],\n",
       "  'loss': 2.772371530532837,\n",
       "  'r_squared_value': -7.96034313033142,\n",
       "  'test_error': 8.651587357508856},\n",
       " {'model': 'ABEL-Spline (z=1)',\n",
       "  'fold': 1,\n",
       "  'train_history': [1.6143416166305542, 1.3605279922485352],\n",
       "  'val_history': [1.5181667804718018, 1.2561784982681274],\n",
       "  'loss': 1.2561784982681274,\n",
       "  'r_squared_value': -1.341576066360914,\n",
       "  'test_error': 2.2608899679073},\n",
       " {'model': 'Spline ANN (z=2)',\n",
       "  'fold': 1,\n",
       "  'train_history': [1.7450779676437378, 1.6816778182983398],\n",
       "  'val_history': [1.7545430660247803, 1.690950870513916],\n",
       "  'loss': 1.690950870513916,\n",
       "  'r_squared_value': -2.8646705570391124,\n",
       "  'test_error': 3.731501622860239},\n",
       " {'model': 'Lookup Table (z=2)',\n",
       "  'fold': 1,\n",
       "  'train_history': [2.7166430950164795, 2.696183919906616],\n",
       "  'val_history': [2.7444257736206055, 2.7241291999816895],\n",
       "  'loss': 2.7241291999816895,\n",
       "  'r_squared_value': -7.846676474566934,\n",
       "  'test_error': 8.541837430784122},\n",
       " {'model': 'ABEL-Spline (z=2)',\n",
       "  'fold': 1,\n",
       "  'train_history': [1.6465296745300293, 1.3945058584213257],\n",
       "  'val_history': [1.552202820777893, 1.3005114793777466],\n",
       "  'loss': 1.3005114793777466,\n",
       "  'r_squared_value': -1.468661169780849,\n",
       "  'test_error': 2.3835959690149773},\n",
       " {'model': 'Spline ANN (z=4)',\n",
       "  'fold': 1,\n",
       "  'train_history': [1.7321546077728271, 1.669395089149475],\n",
       "  'val_history': [1.74160897731781, 1.679866075515747],\n",
       "  'loss': 1.679866075515747,\n",
       "  'r_squared_value': -2.803072801825802,\n",
       "  'test_error': 3.6720264049469393},\n",
       " {'model': 'Lookup Table (z=4)',\n",
       "  'fold': 1,\n",
       "  'train_history': [2.6090235710144043, 2.5902700424194336],\n",
       "  'val_history': [2.6176793575286865, 2.599133253097534],\n",
       "  'loss': 2.599133253097534,\n",
       "  'r_squared_value': -7.2978150262252,\n",
       "  'test_error': 8.011888666721365},\n",
       " {'model': 'ABEL-Spline (z=4)',\n",
       "  'fold': 1,\n",
       "  'train_history': [1.647040605545044, 1.4009144306182861],\n",
       "  'val_history': [1.5538296699523926, 1.3040088415145874],\n",
       "  'loss': 1.3040088415145874,\n",
       "  'r_squared_value': -1.456795278424638,\n",
       "  'test_error': 2.372138952899661},\n",
       " {'model': 'Spline ANN (z=8)',\n",
       "  'fold': 1,\n",
       "  'train_history': [1.7392377853393555, 1.675337553024292],\n",
       "  'val_history': [1.743483543395996, 1.6810953617095947],\n",
       "  'loss': 1.6810953617095947,\n",
       "  'r_squared_value': -2.8241636276742694,\n",
       "  'test_error': 3.6923904824845897},\n",
       " {'model': 'Lookup Table (z=8)',\n",
       "  'fold': 1,\n",
       "  'train_history': [2.5686824321746826, 2.55014705657959],\n",
       "  'val_history': [2.581664562225342, 2.563400983810425],\n",
       "  'loss': 2.563400983810425,\n",
       "  'r_squared_value': -7.120853575464611,\n",
       "  'test_error': 7.841024958948369},\n",
       " {'model': 'ABEL-Spline (z=8)',\n",
       "  'fold': 1,\n",
       "  'train_history': [1.6354377269744873, 1.384683609008789],\n",
       "  'val_history': [1.545363426208496, 1.2952033281326294],\n",
       "  'loss': 1.2952033281326294,\n",
       "  'r_squared_value': -1.4681701031457668,\n",
       "  'test_error': 2.383121823568762},\n",
       " {'model': 'Spline ANN (z=10)',\n",
       "  'fold': 1,\n",
       "  'train_history': [1.7431387901306152, 1.6794461011886597],\n",
       "  'val_history': [1.7535512447357178, 1.692192554473877],\n",
       "  'loss': 1.692192554473877,\n",
       "  'r_squared_value': -2.8732331633417667,\n",
       "  'test_error': 3.73976917861763},\n",
       " {'model': 'Lookup Table (z=10)',\n",
       "  'fold': 1,\n",
       "  'train_history': [2.567671537399292, 2.549144744873047],\n",
       "  'val_history': [2.5796806812286377, 2.561694383621216],\n",
       "  'loss': 2.561694383621216,\n",
       "  'r_squared_value': -7.114401369011716,\n",
       "  'test_error': 7.8347950828193005},\n",
       " {'model': 'ABEL-Spline (z=10)',\n",
       "  'fold': 1,\n",
       "  'train_history': [1.6381175518035889, 1.3891481161117554],\n",
       "  'val_history': [1.5419492721557617, 1.2936609983444214],\n",
       "  'loss': 1.2936609983444214,\n",
       "  'r_squared_value': -1.4250645594632467,\n",
       "  'test_error': 2.341501612005676}]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_models_parallel(list_of_kfold_datasets[0][0], '1029_LEV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77bc45ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "def evaluate_all_folds_parallel(kfold_datasets, dataset_name):\n",
    "    \n",
    "    results = []\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        futures = {executor.submit(evaluate_models_parallel, fold_data, dataset_name): fold_data for fold_data in kfold_datasets}\n",
    "        for future in futures:\n",
    "            result = future.result()\n",
    "            results.extend(result)\n",
    "            print(f'Completed models evaluation on dataset {dataset_name}, fold {futures[future][4]}')\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "# usage\n",
    "evaluate_all_folds_parallel(list_of_kfold_datasets[0], '1029_LEV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a260337",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3d2440",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824fbfdd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8ba770",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104d421b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774086dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56edf72a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f1f99c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_cross_validation_dataset(data, num_folds):\n",
    "    X, y = data.drop('target', axis=1).values, data['target'].values\n",
    "    \n",
    "    dataset_list = []\n",
    "    kf = KFold(n_splits=num_folds)\n",
    "    fold = 0\n",
    "\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        fold += 1\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        dataset_list.append((X_train, y_train, X_test, y_test , fold))\n",
    "    \n",
    "    return dataset_list\n",
    "\n",
    "def generate_cross_validation_models(input_dim, num_folds):\n",
    "    model_lists = []\n",
    "    for fold in range(num_folds):\n",
    "        models = initialize_all_models(input_dim, seed_val=fold)\n",
    "        compile_models(models)\n",
    "        model_lists.append(models)\n",
    "    return model_lists\n",
    "\n",
    "def train_evaluate_model(model_tuple, fold_data, epoch_number):\n",
    "    \n",
    "    model, name = model_tuple\n",
    "    X_train, y_train, X_test, y_test , fold = fold_data\n",
    "    \n",
    "    history = model.fit(X_train, y_train,\n",
    "                        epochs=epoch_number,\n",
    "                        verbose=0,\n",
    "                        validation_data=(X_test, y_test))\n",
    "\n",
    "    loss = model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "    predictions = model.predict(X_test)\n",
    "    r_squared_value = r2_score(y_test,predictions)\n",
    "    test_error = mean_squared_error(y_test,predictions)\n",
    "\n",
    "    results = {\n",
    "        'model': name,\n",
    "        'fold': fold,\n",
    "        'train_history': history['loss'],\n",
    "        'val_history': history['val_loss'],\n",
    "        'loss': loss,\n",
    "        'r_squared_value': r_squared_value,\n",
    "        'test_error': test_error}\n",
    "    \n",
    "    return results    \n",
    "\n",
    "def cross_validation(data, epoch_number, num_folds):\n",
    "    \n",
    "    # Generate cross validation datasets\n",
    "    cv_datasets = generate_cross_validation_dataset(data, num_folds)\n",
    "    cv_models = generate_cross_validation_models(X_train.shape[1], num_folds)\n",
    "    \n",
    "    for fold in range(num_folds):\n",
    "        fold_data = cv_datasets[fold]\n",
    "        models = cv_models[fold]\n",
    "        for model_tuple in models:\n",
    "            train_evaluate_model(model_tuple, fold_data, epoch_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e59b056",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae6dde9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf57f42c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e5f695",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17596319",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967724d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1597de9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126f91b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(data, epoch_number, num_folds):\n",
    "    \n",
    "    # Generate cross validation datasets\n",
    "    cv_datasets = generate_cross_validation_dataset(data, num_folds)\n",
    "    cv_models = generate_cross_validation_models(X_train.shape[1], num_folds)\n",
    "    \n",
    "    for fold in range(num_folds):\n",
    "        fold_data = cv_datasets[fold]\n",
    "        models = cv_models[fold]\n",
    "        for model_tuple in models:\n",
    "            train_evaluate_model(model_tuple, fold_data, epoch_number)\n",
    "            \n",
    "            \n",
    "    \n",
    "    all_results = []\n",
    "    \n",
    "    for fold_data in cv_datasets:\n",
    "        X_train, y_train, X_test, y_test , fold = fold_data\n",
    "        \n",
    "        # Generate models for this fold\n",
    "        models = generate_cross_validation_models(X_train.shape[1], num_folds)\n",
    "        \n",
    "        fold_results = []\n",
    "        \n",
    "        # Train and evaluate each model on this fold's data\n",
    "        for model_tuple in models:\n",
    "            result = train_evaluate_model(model_tuple, fold_data, epoch_number)\n",
    "            fold_results.append(result)\n",
    "        \n",
    "        all_results.append(fold_results)\n",
    "\n",
    "    return all_results\n",
    "\n",
    "all_results = {}\n",
    "\n",
    "for dataset, row in zip(datasets, filtered_datasets.iterrows()):\n",
    "    dataset_name = row[1]['dataset']\n",
    "    print(f\"Evaluating dataset: {dataset_name}\")\n",
    "\n",
    "    results = cross_validation(dataset)\n",
    "    all_results[dataset_name] = results\n",
    "\n",
    "# save results to a JSON file\n",
    "with open('results.json', 'w') as f:\n",
    "    json.dump(all_results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab1d3f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085a9e83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1abb58c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a51163",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd3e7ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9350a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# the k-fold\n",
    "[(train_index, test_index) for train_index,test_index in kf.split(X)]\n",
    "\n",
    "input_dimension = row[1]['n_features']\n",
    "X_train, X_test = X[train_index], X[test_index]\n",
    "\n",
    "models = initialize_all_models(X_train.shape[1], seed_val=fold) #input dimension specify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb3b46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_evaluate_model(model_name_tuple, data, indices, fold, epochs):\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
