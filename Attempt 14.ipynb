{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4058ba51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary modules\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from model_data_definitions import *\n",
    "from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor\n",
    "\n",
    "# Function to generate cross validation dataset\n",
    "def generate_cross_validation_dataset(data, num_folds):\n",
    "    X, y = data.drop('target', axis=1).values, data['target'].values\n",
    "    \n",
    "    dataset_list = []\n",
    "    kf = KFold(n_splits=num_folds)\n",
    "    fold = 0\n",
    "\n",
    "    # Splitting data into training and testing set for each fold in the cross-validation \n",
    "    for train_index, test_index in kf.split(X):\n",
    "        fold += 1\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        dataset_list.append((X_train, y_train, X_test, y_test , fold))\n",
    "    \n",
    "    return dataset_list\n",
    "\n",
    "# Function to train and evaluate model\n",
    "def train_evaluate_model(model_tuple, fold_data, epoch_number, dataset_name,num_folds):\n",
    "    \n",
    "    model, name = model_tuple\n",
    "    X_train, y_train, X_test, y_test , fold = fold_data\n",
    "    \n",
    "    # Training the model \n",
    "    history = model.fit(X_train,\n",
    "                        y_train,\n",
    "                        epochs=epoch_number,\n",
    "                        verbose=0,\n",
    "                        validation_data=(X_test,y_test))\n",
    "\n",
    "     # Evaluating the trained model on test data \n",
    "    loss = model.evaluate(X_test,y_test)\n",
    "\n",
    "     # Making predictions on the test data \n",
    "    predictions = model.predict(X_test)\n",
    "    \n",
    "     # Calculate metrics \n",
    "    r_squared_value=r2_score(y_true=y_test,y_pred=predictions)\n",
    "    test_error=mean_squared_error(y_true=y_test,y_pred=predictions)\n",
    "\n",
    "    results = {\n",
    "        'model': name,\n",
    "        'fold': fold,\n",
    "        'train_history': history.history['loss'],\n",
    "        'val_history': history.history['val_loss'],\n",
    "        'loss': loss,\n",
    "        'r_squared_value': r_squared_value,\n",
    "        'test_error': test_error}\n",
    "\n",
    "    # Save results to numpy file\n",
    "    if not os.path.exists('aggregate_results'):\n",
    "        os.makedirs('aggregate_results')\n",
    "\n",
    "    np.save(f'aggregate_results/{dataset_name}-{name}-fold-{fold}-of-{num_folds}.npy', results)\n",
    "\n",
    "# Function to evaluate models in parallel\n",
    "def evaluate_models_parallel(fold_data, dataset_name, epoch_number,num_folds):\n",
    "    \n",
    "    models = initialize_all_models(fold_data[0].shape[1], seed_val=fold_data[4])\n",
    "    compile_models(models)\n",
    "\n",
    "     # Training and evaluating all models in parallel using ThreadPoolExecutor \n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        futures = {executor.submit(train_evaluate_model, model, fold_data, epoch_number, dataset_name,num_folds): model for model in models}\n",
    "        for future in futures:\n",
    "            future.result()  # Just to make sure all tasks are finished\n",
    "\n",
    "# Function to evaluate all folds in parallel\n",
    "def evaluate_all_folds_parallel(kfold_datasets, dataset_name, epoch_number,num_folds):\n",
    "    \n",
    "     # Evaluating all folds in parallel using ThreadPoolExecutor \n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        futures = {executor.submit(evaluate_models_parallel, fold_data, dataset_name, epoch_number,num_folds): fold_data for fold_data in kfold_datasets}\n",
    "        for future in futures:\n",
    "            future.result()  # Just to make sure all tasks are finished\n",
    "\n",
    "# New function to retrieve all datasets and their names and feed it to relevant functions with a for loop.\n",
    "def retrieve_datasets_and_run_evaluations(num_folds=5, epoch_number=100):\n",
    "    # Fetching data \n",
    "    filtered_datasets_metadata, datasets = fetch_return_filtered_pmlb_data_sets()\n",
    "\n",
    "    for dataset, row in zip(datasets, filtered_datasets_metadata.iterrows()):\n",
    "        dataset_name = row[1]['dataset']\n",
    "        kfold_datasets = generate_cross_validation_dataset(dataset, num_folds)\n",
    "        evaluate_all_folds_parallel(kfold_datasets, dataset_name, epoch_number,num_folds)\n",
    "\n",
    "# Call the new function \n",
    "start_time = time.time()\n",
    "retrieve_datasets_and_run_evaluations(num_folds=4, epoch_number=2, =True)\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"The experiment took {elapsed_time} seconds to complete.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b05947c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f71d7a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aecb727d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7942a882",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e63b81e",
   "metadata": {},
   "outputs": [
    {
     "ename": "BrokenProcessPool",
     "evalue": "A process in the process pool was terminated abruptly while the future was running or pending.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mBrokenProcessPool\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 118\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;66;03m# Call the new function \u001b[39;00m\n\u001b[0;32m    117\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m--> 118\u001b[0m \u001b[43mretrieve_datasets_and_run_evaluations\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_folds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch_number\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    119\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m    120\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m end_time \u001b[38;5;241m-\u001b[39m start_time\n",
      "Cell \u001b[1;32mIn[2], line 107\u001b[0m, in \u001b[0;36mretrieve_datasets_and_run_evaluations\u001b[1;34m(num_folds, epoch_number, parallel)\u001b[0m\n\u001b[0;32m    105\u001b[0m         futures \u001b[38;5;241m=\u001b[39m {executor\u001b[38;5;241m.\u001b[39msubmit(evaluate_all_folds_parallel, generate_cross_validation_dataset(dataset\u001b[38;5;241m.\u001b[39mcopy(), num_folds), row[\u001b[38;5;241m1\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdataset\u001b[39m\u001b[38;5;124m'\u001b[39m], epoch_number,num_folds): dataset \u001b[38;5;28;01mfor\u001b[39;00m dataset, row \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(datasets, filtered_datasets_metadata\u001b[38;5;241m.\u001b[39miterrows())}\n\u001b[0;32m    106\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m future \u001b[38;5;129;01min\u001b[39;00m futures:\n\u001b[1;32m--> 107\u001b[0m             \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    109\u001b[0m     \u001b[38;5;66;03m# Use a simple for loop to process each dataset sequentially.\u001b[39;00m\n\u001b[0;32m    110\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m dataset, row \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(datasets, filtered_datasets_metadata\u001b[38;5;241m.\u001b[39miterrows()):\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\concurrent\\futures\\_base.py:458\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    457\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m--> 458\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    459\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    460\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m()\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\concurrent\\futures\\_base.py:403\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 403\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[0;32m    404\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    405\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    406\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mBrokenProcessPool\u001b[0m: A process in the process pool was terminated abruptly while the future was running or pending."
     ]
    }
   ],
   "source": [
    "# Importing necessary modules\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from model_data_definitions import *\n",
    "from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor\n",
    "\n",
    "# Function to generate cross validation dataset with object copies for each fold\n",
    "def generate_cross_validation_dataset(data, num_folds):\n",
    "    X, y = data.drop('target', axis=1).values.copy(), data['target'].values.copy()\n",
    "    \n",
    "    dataset_list = []\n",
    "    kf = KFold(n_splits=num_folds)\n",
    "    fold = 0\n",
    "\n",
    "    # Splitting data into training and testing set for each fold in the cross-validation \n",
    "    for train_index, test_index in kf.split(X):\n",
    "        fold += 1\n",
    "        X_train, X_test = X[train_index].copy(), X[test_index].copy()\n",
    "        y_train, y_test = y[train_index].copy(), y[test_index].copy()\n",
    "        \n",
    "        dataset_list.append((X_train, y_train, X_test, y_test , fold))\n",
    "    \n",
    "    return dataset_list\n",
    "\n",
    "# Function to train and evaluate model\n",
    "def train_evaluate_model(model_tuple, fold_data, epoch_number, dataset_name,num_folds):\n",
    "    \n",
    "    model, name = model_tuple\n",
    "    X_train, y_train, X_test, y_test , fold = fold_data\n",
    "    \n",
    "    # Training the model \n",
    "    history = model.fit(X_train,\n",
    "                        y_train,\n",
    "                        epochs=epoch_number,\n",
    "                        verbose=0,\n",
    "                        validation_data=(X_test,y_test))\n",
    "\n",
    "     # Evaluating the trained model on test data \n",
    "    loss = model.evaluate(X_test,y_test)\n",
    "\n",
    "     # Making predictions on the test data \n",
    "    predictions = model.predict(X_test)\n",
    "    \n",
    "     # Calculate metrics \n",
    "    r_squared_value=r2_score(y_true=y_test,y_pred=predictions)\n",
    "    test_error=mean_squared_error(y_true=y_test,y_pred=predictions)\n",
    "\n",
    "    results = {\n",
    "        'model': name,\n",
    "        'fold': fold,\n",
    "        'train_history': history.history['loss'],\n",
    "        'val_history': history.history['val_loss'],\n",
    "        'loss': loss,\n",
    "        'r_squared_value': r_squared_value,\n",
    "        'test_error': test_error}\n",
    "\n",
    "    # Save results to numpy file\n",
    "    if not os.path.exists('aggregate_results'):\n",
    "        os.makedirs('aggregate_results')\n",
    "\n",
    "    np.save(f'aggregate_results/{dataset_name}-{name}-fold-{fold}-of-{num_folds}.npy', results)\n",
    "\n",
    "# Function to evaluate models in parallel\n",
    "def evaluate_models_parallel(fold_data, dataset_name, epoch_number,num_folds):\n",
    "    \n",
    "    models = initialize_all_models(fold_data[0].shape[1], seed_val=fold_data[4])\n",
    "    compile_models(models)\n",
    "\n",
    "     # Training and evaluating all models in parallel using ThreadPoolExecutor \n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        futures = {executor.submit(train_evaluate_model, model, fold_data, epoch_number, dataset_name,num_folds): model for model in models}\n",
    "        for future in futures:\n",
    "            future.result()  # Just to make sure all tasks are finished\n",
    "\n",
    "# Function to evaluate all folds in parallel\n",
    "def evaluate_all_folds_parallel(kfold_datasets, dataset_name, epoch_number,num_folds):\n",
    "    \n",
    "     # Evaluating all folds in parallel using ThreadPoolExecutor \n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        futures = {executor.submit(evaluate_models_parallel, fold_data, dataset_name, epoch_number,num_folds): fold_data for fold_data in kfold_datasets}\n",
    "        for future in futures:\n",
    "            future.result()  # Just to make sure all tasks are finished\n",
    "\n",
    "# New function to retrieve all datasets and their names and feed it to relevant functions with a for loop.\n",
    "def retrieve_datasets_and_run_evaluations(num_folds=5, epoch_number=100):\n",
    "    # Fetching data \n",
    "    filtered_datasets_metadata, datasets = fetch_return_filtered_pmlb_data_sets()\n",
    "\n",
    "    for dataset, row in zip(datasets, filtered_datasets_metadata.iterrows()):\n",
    "        dataset_name = row[1]['dataset']\n",
    "        kfold_datasets = generate_cross_validation_dataset(dataset, num_folds)\n",
    "        evaluate_all_folds_parallel(kfold_datasets, dataset_name, epoch_number,num_folds)\n",
    "\n",
    "# Call the new function \n",
    "start_time = time.time()\n",
    "retrieve_datasets_and_run_evaluations(num_folds=4, epoch_number=2, = True)\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"The experiment took {elapsed_time} seconds to complete.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e50b76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
