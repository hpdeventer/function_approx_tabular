{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ca612a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary modules\n",
    "import gc\n",
    "import copy\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from model_data_definitions import *\n",
    "from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor\n",
    "\n",
    "# Function to generate cross validation dataset\n",
    "def generate_cross_validation_dataset(data, num_folds):\n",
    "    X, y = data.drop('target', axis=1).values, data['target'].values\n",
    "    \n",
    "    dataset_list = []\n",
    "    kf = KFold(n_splits=num_folds)\n",
    "    fold = 0\n",
    "\n",
    "    # Splitting data into training and testing set for each fold in the cross-validation \n",
    "    for train_index, test_index in kf.split(X):\n",
    "        fold += 1\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        X_train, X_test = preprocess_data(X_train, X_test)\n",
    "        y_train, y_test = preprocess_target_values(y_train, y_test)\n",
    "        \n",
    "        dataset_list.append((X_train, y_train, X_test, y_test , fold))\n",
    "    \n",
    "    return dataset_list\n",
    "\n",
    "# Function to train and evaluate model\n",
    "\n",
    "def train_evaluate_model(model_tuple, fold_data, epoch_number, dataset_name,num_folds, parallel=False):\n",
    "    # Create deep copies of input parameters\n",
    "    model_tuple_local = copy.deepcopy(model_tuple)\n",
    "    fold_data_local = copy.deepcopy(fold_data)\n",
    "    \n",
    "    model, name = model_tuple\n",
    "    X_train, y_train, X_test, y_test , fold = fold_data\n",
    "    \n",
    "    print(f\"Evaluating{name} for {fold}\")\n",
    "    \n",
    "    # Training the model \n",
    "    history = model.fit(X_train,\n",
    "                        y_train,\n",
    "                        epochs=epoch_number,\n",
    "                        verbose=1,\n",
    "                        validation_data=(X_test,y_test))\n",
    "\n",
    "     # Evaluating the trained model on test data \n",
    "    loss = model.evaluate(X_test,y_test)\n",
    "\n",
    "     # Making predictions on the test data \n",
    "    predictions = model.predict(X_test)\n",
    "    \n",
    "     # Calculate metrics \n",
    "    r_squared_value=r2_score(y_true=y_test,y_pred=predictions)\n",
    "    test_error=mean_squared_error(y_true=y_test,y_pred=predictions)\n",
    "\n",
    "    results = {\n",
    "        'model': name,\n",
    "        'fold': fold,\n",
    "        'train_history': history.history['loss'],\n",
    "        'val_history': history.history['val_loss'],\n",
    "        'loss': loss,\n",
    "        'r_squared_value': r_squared_value,\n",
    "        'test_error': test_error}\n",
    "\n",
    "   # Save results to numpy file\n",
    "    if not os.path.exists('aggregate_results'):\n",
    "        os.makedirs('aggregate_results')\n",
    "        \n",
    "    np.save(f'aggregate_results/{dataset_name}-{name}-epochs-{epoch_number}-fold-{fold}-of-{num_folds}.npy', results)\n",
    "    \n",
    "    # Delete local variables\n",
    "    del model, history, X_train, y_train, X_test, y_test , predictions, model_tuple_local, fold_data_local\n",
    "     \n",
    "    # Run garbage collector\n",
    "    gc.collect()\n",
    "\n",
    "# Function to evaluate models in parallel or using for loop\n",
    "def evaluate_models_parallel(fold_data, dataset_name, epoch_number,num_folds, parallel=False):\n",
    "\n",
    "    models = initialize_all_models(fold_data[0].shape[1], seed_val=fold_data[4])\n",
    "    compile_models(models)\n",
    "\n",
    "    if parallel:\n",
    "        with ThreadPoolExecutor() as executor:\n",
    "            futures = {executor.submit(train_evaluate_model,\n",
    "                                       model,\n",
    "                                       fold_data,\n",
    "                                       epoch_number,\n",
    "                                       dataset_name,\n",
    "                                       num_folds,\n",
    "                                       parallel): model for model in models}\n",
    "            for future in futures:\n",
    "                future.result()\n",
    "    else:\n",
    "        for model in models:\n",
    "            train_evaluate_model(model,\n",
    "                                 fold_data,\n",
    "                                 epoch_number,\n",
    "                                 dataset_name,\n",
    "                                 num_folds)\n",
    "\n",
    "# Function to evaluate all folds in parallel or using for loop\n",
    "def evaluate_all_folds_parallel(kfold_datasets, dataset_name, epoch_number,num_folds, parallel=False):\n",
    "    \n",
    "    if parallel:\n",
    "        with ThreadPoolExecutor() as executor:\n",
    "            futures = {executor.submit(evaluate_models_parallel, \n",
    "                                       fold_data, \n",
    "                                       dataset_name, \n",
    "                                       epoch_number,\n",
    "                                       num_folds,\n",
    "                                       parallel): fold_data for fold_data in kfold_datasets}\n",
    "            for future in futures:\n",
    "                future.result()\n",
    "    else:\n",
    "        for fold_data in kfold_datasets:\n",
    "            evaluate_models_parallel(fold_data,\n",
    "                                     dataset_name,\n",
    "                                     epoch_number,\n",
    "                                     num_folds)\n",
    "\n",
    "# New function to retrieve all datasets and their names and feed it to relevant functions with a for loop.\n",
    "def retrieve_datasets_and_run_evaluations(num_folds=10, epoch_number=101, parallel=False):\n",
    "    # Fetching data \n",
    "    filtered_datasets_metadata, datasets = fetch_return_filtered_pmlb_data_sets()\n",
    "\n",
    "    for dataset, row in zip(datasets, filtered_datasets_metadata.iterrows()):\n",
    "        dataset_name = row[1]['dataset']\n",
    "        kfold_datasets = generate_cross_validation_dataset(dataset, num_folds)\n",
    "        evaluate_all_folds_parallel(kfold_datasets, dataset_name, epoch_number,num_folds, parallel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d6d4849",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>n_instances</th>\n",
       "      <th>n_features</th>\n",
       "      <th>n_binary_features</th>\n",
       "      <th>n_categorical_features</th>\n",
       "      <th>n_continuous_features</th>\n",
       "      <th>endpoint_type</th>\n",
       "      <th>n_classes</th>\n",
       "      <th>imbalance</th>\n",
       "      <th>task</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1027_ESL</td>\n",
       "      <td>488</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>continuous</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.099363</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1029_LEV</td>\n",
       "      <td>1000</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>continuous</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.111245</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1030_ERA</td>\n",
       "      <td>1000</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>continuous</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.031251</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1096_FacultySalaries</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>continuous</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.004063</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>192_vineyard</td>\n",
       "      <td>52</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>continuous</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.040475</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>228_elusage</td>\n",
       "      <td>55</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>continuous</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.000953</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>230_machine_cpu</td>\n",
       "      <td>209</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>continuous</td>\n",
       "      <td>116.0</td>\n",
       "      <td>0.004906</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>485_analcatdata_vehicle</td>\n",
       "      <td>48</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>continuous</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0.000434</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>519_vinnie</td>\n",
       "      <td>380</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>continuous</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.030146</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>523_analcatdata_neavote</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>continuous</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.136914</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>529_pollen</td>\n",
       "      <td>3848</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>continuous</td>\n",
       "      <td>3784.0</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>556_analcatdata_apnea2</td>\n",
       "      <td>475</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>continuous</td>\n",
       "      <td>178.0</td>\n",
       "      <td>0.272393</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>557_analcatdata_apnea1</td>\n",
       "      <td>475</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>continuous</td>\n",
       "      <td>164.0</td>\n",
       "      <td>0.325260</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>579_fri_c0_250_5</td>\n",
       "      <td>250</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>continuous</td>\n",
       "      <td>250.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>594_fri_c2_100_5</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>continuous</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>596_fri_c2_250_5</td>\n",
       "      <td>250</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>continuous</td>\n",
       "      <td>250.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>597_fri_c2_500_5</td>\n",
       "      <td>500</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>continuous</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>599_fri_c2_1000_5</td>\n",
       "      <td>1000</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>continuous</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>601_fri_c1_250_5</td>\n",
       "      <td>250</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>continuous</td>\n",
       "      <td>250.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>609_fri_c0_1000_5</td>\n",
       "      <td>1000</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>continuous</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>611_fri_c3_100_5</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>continuous</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>612_fri_c1_1000_5</td>\n",
       "      <td>1000</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>continuous</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>613_fri_c3_250_5</td>\n",
       "      <td>250</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>continuous</td>\n",
       "      <td>250.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>617_fri_c3_500_5</td>\n",
       "      <td>500</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>continuous</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>624_fri_c0_100_5</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>continuous</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>628_fri_c3_1000_5</td>\n",
       "      <td>1000</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>continuous</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>631_fri_c1_500_5</td>\n",
       "      <td>500</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>continuous</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>649_fri_c0_500_5</td>\n",
       "      <td>500</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>continuous</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>656_fri_c1_100_5</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>continuous</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>663_rabe_266</td>\n",
       "      <td>120</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>continuous</td>\n",
       "      <td>96.0</td>\n",
       "      <td>0.001825</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>665_sleuth_case2002</td>\n",
       "      <td>147</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>continuous</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.096020</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>678_visualizing_environmental</td>\n",
       "      <td>111</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>continuous</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.019608</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>687_sleuth_ex1605</td>\n",
       "      <td>62</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>continuous</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.006465</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>690_visualizing_galaxy</td>\n",
       "      <td>323</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>continuous</td>\n",
       "      <td>208.0</td>\n",
       "      <td>0.001246</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>706_sleuth_case1202</td>\n",
       "      <td>93</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>continuous</td>\n",
       "      <td>79.0</td>\n",
       "      <td>0.001583</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>712_chscase_geyser1</td>\n",
       "      <td>222</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>continuous</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.012844</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>banana</td>\n",
       "      <td>5300</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>continuous</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.010691</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>titanic</td>\n",
       "      <td>2201</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>continuous</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.125266</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           dataset  n_instances  n_features  \\\n",
       "0                         1027_ESL          488           4   \n",
       "2                         1029_LEV         1000           4   \n",
       "3                         1030_ERA         1000           4   \n",
       "5             1096_FacultySalaries           50           4   \n",
       "13                    192_vineyard           52           2   \n",
       "23                     228_elusage           55           2   \n",
       "25                 230_machine_cpu          209           6   \n",
       "29         485_analcatdata_vehicle           48           4   \n",
       "32                      519_vinnie          380           2   \n",
       "34         523_analcatdata_neavote          100           2   \n",
       "36                      529_pollen         3848           4   \n",
       "40          556_analcatdata_apnea2          475           3   \n",
       "41          557_analcatdata_apnea1          475           3   \n",
       "48                579_fri_c0_250_5          250           5   \n",
       "60                594_fri_c2_100_5          100           5   \n",
       "62                596_fri_c2_250_5          250           5   \n",
       "63                597_fri_c2_500_5          500           5   \n",
       "65               599_fri_c2_1000_5         1000           5   \n",
       "66                601_fri_c1_250_5          250           5   \n",
       "74               609_fri_c0_1000_5         1000           5   \n",
       "75                611_fri_c3_100_5          100           5   \n",
       "76               612_fri_c1_1000_5         1000           5   \n",
       "77                613_fri_c3_250_5          250           5   \n",
       "80                617_fri_c3_500_5          500           5   \n",
       "86                624_fri_c0_100_5          100           5   \n",
       "89               628_fri_c3_1000_5         1000           5   \n",
       "90                631_fri_c1_500_5          500           5   \n",
       "102               649_fri_c0_500_5          500           5   \n",
       "107               656_fri_c1_100_5          100           5   \n",
       "111                   663_rabe_266          120           2   \n",
       "112            665_sleuth_case2002          147           6   \n",
       "114  678_visualizing_environmental          111           3   \n",
       "115              687_sleuth_ex1605           62           5   \n",
       "116         690_visualizing_galaxy          323           4   \n",
       "118            706_sleuth_case1202           93           6   \n",
       "119            712_chscase_geyser1          222           2   \n",
       "155                         banana         5300           2   \n",
       "270                        titanic         2201           3   \n",
       "\n",
       "     n_binary_features  n_categorical_features  n_continuous_features  \\\n",
       "0                    0                       0                      4   \n",
       "2                    0                       0                      4   \n",
       "3                    0                       0                      4   \n",
       "5                    0                       0                      4   \n",
       "13                   0                       0                      2   \n",
       "23                   0                       0                      2   \n",
       "25                   0                       0                      6   \n",
       "29                   0                       0                      4   \n",
       "32                   0                       0                      2   \n",
       "34                   0                       0                      2   \n",
       "36                   0                       0                      4   \n",
       "40                   0                       0                      3   \n",
       "41                   0                       0                      3   \n",
       "48                   0                       0                      5   \n",
       "60                   0                       0                      5   \n",
       "62                   0                       0                      5   \n",
       "63                   0                       0                      5   \n",
       "65                   0                       0                      5   \n",
       "66                   0                       0                      5   \n",
       "74                   0                       0                      5   \n",
       "75                   0                       0                      5   \n",
       "76                   0                       0                      5   \n",
       "77                   0                       0                      5   \n",
       "80                   0                       0                      5   \n",
       "86                   0                       0                      5   \n",
       "89                   0                       0                      5   \n",
       "90                   0                       0                      5   \n",
       "102                  0                       0                      5   \n",
       "107                  0                       0                      5   \n",
       "111                  0                       0                      2   \n",
       "112                  0                       0                      6   \n",
       "114                  0                       0                      3   \n",
       "115                  0                       0                      5   \n",
       "116                  0                       0                      4   \n",
       "118                  0                       0                      6   \n",
       "119                  0                       0                      2   \n",
       "155                  0                       0                      2   \n",
       "270                  0                       0                      3   \n",
       "\n",
       "    endpoint_type  n_classes  imbalance        task  \n",
       "0      continuous        9.0   0.099363  regression  \n",
       "2      continuous        5.0   0.111245  regression  \n",
       "3      continuous        9.0   0.031251  regression  \n",
       "5      continuous       39.0   0.004063  regression  \n",
       "13     continuous       19.0   0.040475  regression  \n",
       "23     continuous       52.0   0.000953  regression  \n",
       "25     continuous      116.0   0.004906  regression  \n",
       "29     continuous       47.0   0.000434  regression  \n",
       "32     continuous       16.0   0.030146  regression  \n",
       "34     continuous        8.0   0.136914  regression  \n",
       "36     continuous     3784.0   0.000004  regression  \n",
       "40     continuous      178.0   0.272393  regression  \n",
       "41     continuous      164.0   0.325260  regression  \n",
       "48     continuous      250.0   0.000000  regression  \n",
       "60     continuous      100.0   0.000000  regression  \n",
       "62     continuous      250.0   0.000000  regression  \n",
       "63     continuous      500.0   0.000000  regression  \n",
       "65     continuous     1000.0   0.000000  regression  \n",
       "66     continuous      250.0   0.000000  regression  \n",
       "74     continuous     1000.0   0.000000  regression  \n",
       "75     continuous      100.0   0.000000  regression  \n",
       "76     continuous     1000.0   0.000000  regression  \n",
       "77     continuous      250.0   0.000000  regression  \n",
       "80     continuous      500.0   0.000000  regression  \n",
       "86     continuous      100.0   0.000000  regression  \n",
       "89     continuous     1000.0   0.000000  regression  \n",
       "90     continuous      500.0   0.000000  regression  \n",
       "102    continuous      500.0   0.000000  regression  \n",
       "107    continuous      100.0   0.000000  regression  \n",
       "111    continuous       96.0   0.001825  regression  \n",
       "112    continuous       19.0   0.096020  regression  \n",
       "114    continuous       28.0   0.019608  regression  \n",
       "115    continuous       41.0   0.006465  regression  \n",
       "116    continuous      208.0   0.001246  regression  \n",
       "118    continuous       79.0   0.001583  regression  \n",
       "119    continuous       50.0   0.012844  regression  \n",
       "155    continuous        2.0   0.010691  regression  \n",
       "270    continuous        2.0   0.125266  regression  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_datasets_metadata, datasets = fetch_return_filtered_pmlb_data_sets()\n",
    "filtered_datasets_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec4c1701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(270, dataset                      titanic\n",
      "n_instances                     2201\n",
      "n_features                         3\n",
      "n_binary_features                  0\n",
      "n_categorical_features             0\n",
      "n_continuous_features              3\n",
      "endpoint_type             continuous\n",
      "n_classes                        2.0\n",
      "imbalance                   0.125266\n",
      "task                      regression\n",
      "Name: 270, dtype: object)\n",
      "Dataset for fold 1 is valid.\n",
      "Dataset for fold 2 is valid.\n",
      "Dataset for fold 3 is valid.\n",
      "INFO:tensorflow:Assets written to: ram://9e550aa0-71c5-4e33-afa2-b1dfde52958f/assets\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "Unsuccessful TensorSliceReader constructor: Failed to find any matching files for ram://ad00049a-8b8b-4a92-a23a-c94520fec503/variables/variables\n You may be trying to load on a different device from the computational device. Consider setting the `experimental_io_device` option in `tf.saved_model.LoadOptions` to the io_device such as '/job:localhost'.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 16\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     15\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset for fold \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is valid.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 16\u001b[0m \u001b[43mevaluate_all_folds_parallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkfold_datasets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch_number\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m101\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mnum_folds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[11], line 124\u001b[0m, in \u001b[0;36mevaluate_all_folds_parallel\u001b[1;34m(kfold_datasets, dataset_name, epoch_number, num_folds, parallel)\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    123\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m fold_data \u001b[38;5;129;01min\u001b[39;00m kfold_datasets:\n\u001b[1;32m--> 124\u001b[0m         \u001b[43mevaluate_models_parallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfold_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    125\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    126\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mepoch_number\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    127\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mnum_folds\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[11], line 103\u001b[0m, in \u001b[0;36mevaluate_models_parallel\u001b[1;34m(fold_data, dataset_name, epoch_number, num_folds, parallel)\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    102\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m model \u001b[38;5;129;01min\u001b[39;00m models:\n\u001b[1;32m--> 103\u001b[0m         \u001b[43mtrain_evaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    104\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mfold_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    105\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mepoch_number\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    106\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    107\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mnum_folds\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[11], line 38\u001b[0m, in \u001b[0;36mtrain_evaluate_model\u001b[1;34m(model_tuple, fold_data, epoch_number, dataset_name, num_folds, parallel)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_evaluate_model\u001b[39m(model_tuple, fold_data, epoch_number, dataset_name,num_folds, parallel\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;66;03m# Create deep copies of input parameters\u001b[39;00m\n\u001b[1;32m---> 38\u001b[0m     model_tuple_local \u001b[38;5;241m=\u001b[39m \u001b[43mcopy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_tuple\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m     fold_data_local \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(fold_data)\n\u001b[0;32m     41\u001b[0m     model, name \u001b[38;5;241m=\u001b[39m model_tuple\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    144\u001b[0m copier \u001b[38;5;241m=\u001b[39m _deepcopy_dispatch\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 146\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcopier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mtype\u001b[39m):\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\copy.py:211\u001b[0m, in \u001b[0;36m_deepcopy_tuple\u001b[1;34m(x, memo, deepcopy)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_deepcopy_tuple\u001b[39m(x, memo, deepcopy\u001b[38;5;241m=\u001b[39mdeepcopy):\n\u001b[1;32m--> 211\u001b[0m     y \u001b[38;5;241m=\u001b[39m [deepcopy(a, memo) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m x]\n\u001b[0;32m    212\u001b[0m     \u001b[38;5;66;03m# We're not going to put the tuple in the memo, but it's still important we\u001b[39;00m\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;66;03m# check for it, in case the tuple contains recursive mutable structures.\u001b[39;00m\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\copy.py:211\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_deepcopy_tuple\u001b[39m(x, memo, deepcopy\u001b[38;5;241m=\u001b[39mdeepcopy):\n\u001b[1;32m--> 211\u001b[0m     y \u001b[38;5;241m=\u001b[39m [\u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m x]\n\u001b[0;32m    212\u001b[0m     \u001b[38;5;66;03m# We're not going to put the tuple in the memo, but it's still important we\u001b[39;00m\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;66;03m# check for it, in case the tuple contains recursive mutable structures.\u001b[39;00m\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\copy.py:153\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    151\u001b[0m copier \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__deepcopy__\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 153\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcopier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m     reductor \u001b[38;5;241m=\u001b[39m dispatch_table\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py:377\u001b[0m, in \u001b[0;36mModel.__deepcopy__\u001b[1;34m(self, memo)\u001b[0m\n\u001b[0;32m    375\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__deepcopy__\u001b[39m(\u001b[38;5;28mself\u001b[39m, memo):\n\u001b[0;32m    376\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuilt:\n\u001b[1;32m--> 377\u001b[0m         new \u001b[38;5;241m=\u001b[39m \u001b[43mpickle_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeserialize_model_from_bytecode\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    378\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpickle_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mserialize_model_as_bytecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    379\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    380\u001b[0m         memo[\u001b[38;5;28mid\u001b[39m(\u001b[38;5;28mself\u001b[39m)] \u001b[38;5;241m=\u001b[39m new\n\u001b[0;32m    381\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    382\u001b[0m         \u001b[38;5;66;03m# See comment in __reduce__ for explanation\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\keras\\saving\\pickle_utils.py:47\u001b[0m, in \u001b[0;36mdeserialize_model_from_bytecode\u001b[1;34m(serialized_model)\u001b[0m\n\u001b[0;32m     45\u001b[0m             \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mgfile\u001b[38;5;241m.\u001b[39mGFile(dest_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m     46\u001b[0m                 f\u001b[38;5;241m.\u001b[39mwrite(archive\u001b[38;5;241m.\u001b[39mextractfile(name)\u001b[38;5;241m.\u001b[39mread())\n\u001b[1;32m---> 47\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43msave_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtemp_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     48\u001b[0m tf\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mgfile\u001b[38;5;241m.\u001b[39mrmtree(temp_dir)\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\tensorflow\\python\\saved_model\\load.py:933\u001b[0m, in \u001b[0;36mload_partial\u001b[1;34m(export_dir, filters, tags, options)\u001b[0m\n\u001b[0;32m    930\u001b[0m   loader \u001b[38;5;241m=\u001b[39m Loader(object_graph_proto, saved_model_proto, export_dir,\n\u001b[0;32m    931\u001b[0m                   ckpt_options, options, filters)\n\u001b[0;32m    932\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mNotFoundError \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m--> 933\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\n\u001b[0;32m    934\u001b[0m       \u001b[38;5;28mstr\u001b[39m(err) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m You may be trying to load on a different device \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    935\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom the computational device. Consider setting the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    936\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`experimental_io_device` option in `tf.saved_model.LoadOptions` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    937\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto the io_device such as \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/job:localhost\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    938\u001b[0m root \u001b[38;5;241m=\u001b[39m loader\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    939\u001b[0m root\u001b[38;5;241m.\u001b[39mgraph_debug_info \u001b[38;5;241m=\u001b[39m loader\u001b[38;5;241m.\u001b[39madjust_debug_info_func_names(debug_info)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for ram://ad00049a-8b8b-4a92-a23a-c94520fec503/variables/variables\n You may be trying to load on a different device from the computational device. Consider setting the `experimental_io_device` option in `tf.saved_model.LoadOptions` to the io_device such as '/job:localhost'."
     ]
    }
   ],
   "source": [
    "num_folds = 3\n",
    "\n",
    "for dataset, row in zip(datasets, filtered_datasets_metadata.iterrows()):\n",
    "    dataset_name = row[1]['dataset']\n",
    "    if dataset_name == 'titanic':\n",
    "        print(row)\n",
    "        #print(dataset)\n",
    "        kfold_datasets = generate_cross_validation_dataset(dataset, num_folds)\n",
    "        # Check if kfold_datasets contains valid numbers\n",
    "        for dataset in kfold_datasets:\n",
    "            X_train, y_train, X_test, y_test , fold = dataset\n",
    "            if not (np.isfinite(X_train).all() and np.isfinite(y_train).all() and np.isfinite(X_test).all() and np.isfinite(y_test).all()):\n",
    "                print(f\"Dataset for fold {fold} contains invalid numbers.\")\n",
    "            else:\n",
    "                print(f\"Dataset for fold {fold} is valid.\")\n",
    "        evaluate_all_folds_parallel(kfold_datasets, dataset_name, epoch_number=101,num_folds=10, parallel=False)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918b35e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
