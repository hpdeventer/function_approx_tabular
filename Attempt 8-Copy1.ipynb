{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6d65269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    dataset  n_instances  n_features  n_binary_features  \\\n",
      "2  1029_LEV         1000           4                  0   \n",
      "3  1030_ERA         1000           4                  0   \n",
      "\n",
      "   n_categorical_features  n_continuous_features endpoint_type  n_classes  \\\n",
      "2                       0                      4    continuous        5.0   \n",
      "3                       0                      4    continuous        9.0   \n",
      "\n",
      "   imbalance        task  \n",
      "2   0.111245  regression  \n",
      "3   0.031251  regression  \n"
     ]
    }
   ],
   "source": [
    "# we need a way to specify unique model name, or save model outputs based on indices.\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from model_data_definitions import *\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# expensive and slow operation done once.\n",
    "filtered_datasets, datasets = fetch_return_filtered_pmlb_data_sets() \n",
    "print(filtered_datasets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f51ca941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Model\n",
      "Wide ReLU ANN\n",
      "Deep ReLU ANN\n",
      "One Parameter\n",
      "Spline ANN (z=1)\n",
      "Lookup Table (z=1)\n",
      "ABEL-Spline (z=1)\n",
      "Spline ANN (z=2)\n",
      "Lookup Table (z=2)\n",
      "ABEL-Spline (z=2)\n",
      "Spline ANN (z=4)\n",
      "Lookup Table (z=4)\n",
      "ABEL-Spline (z=4)\n",
      "Spline ANN (z=8)\n",
      "Lookup Table (z=8)\n",
      "ABEL-Spline (z=8)\n",
      "Spline ANN (z=10)\n",
      "Lookup Table (z=10)\n",
      "ABEL-Spline (z=10)\n"
     ]
    }
   ],
   "source": [
    "models = initialize_all_models(input_dimension=2, seed_val=42)\n",
    "\n",
    "compile_models(models)\n",
    "\n",
    "for model, name in models:\n",
    "    # Access the model and its unique name\n",
    "    print(name)\n",
    "    #print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "571fb97a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function model_data_definitions.initialize_all_models(input_dimension: int, seed_val: int, output_dim: int = 1, hidden_units_wide: int = 1000, hidden_units_deep: int = 16, hidden_layers: int = 8, num_exps: int = 6) -> list>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initialize_all_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "adafc59d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(array([  0,   1,   2,   4,   5,   6,   7,   8,  10,  11,  14,  16,  17,\n",
       "          18,  19,  20,  21,  23,  25,  26,  27,  28,  29,  33,  34,  35,\n",
       "          36,  38,  42,  43,  44,  45,  46,  49,  50,  51,  53,  54,  56,\n",
       "          57,  58,  59,  62,  65,  66,  67,  68,  69,  71,  72,  76,  78,\n",
       "          79,  80,  81,  82,  84,  85,  93,  95,  96,  97,  98, 100, 102,\n",
       "         103, 105, 106, 107, 110, 111, 112, 113, 117, 118, 119, 120, 121,\n",
       "         122, 123, 124, 126, 127, 129, 133, 135, 136, 138, 140, 142, 143,\n",
       "         144, 145, 147, 148, 149, 151, 152, 154, 155, 162, 163, 164, 165,\n",
       "         166, 168, 171, 172, 173, 174, 175, 177, 181, 182, 183, 184, 185,\n",
       "         186, 188, 189, 192, 197, 198, 199, 200, 202, 203, 204, 205, 208,\n",
       "         209, 210, 212, 213, 214, 215, 218, 219, 220, 221, 223, 224, 225,\n",
       "         227, 230, 232, 233, 234, 235, 236, 238, 242, 244, 245, 246, 247,\n",
       "         248, 250, 252, 253, 254, 256, 257, 258, 259, 261, 262, 265, 266,\n",
       "         267, 268, 269, 272, 273, 274, 275, 276, 279, 280, 282, 286, 287,\n",
       "         288, 290, 291, 296, 297, 299, 300, 301, 302, 303, 304, 305, 306,\n",
       "         307, 308, 310, 311, 312, 314, 315, 317, 318, 321, 322, 323, 324,\n",
       "         325, 327, 328, 331, 333, 334, 335, 337, 339, 340, 342, 343, 344,\n",
       "         346, 347, 348, 349, 350, 352, 353, 354, 356, 357, 358, 359, 361,\n",
       "         362, 363, 364, 365, 366, 368, 369, 370, 371, 372, 373, 374, 376,\n",
       "         377, 380, 383, 384, 385, 386, 387, 388, 389, 390, 392, 393, 395,\n",
       "         397, 398, 399, 401, 402, 406, 407, 408, 409, 410, 411, 413, 414,\n",
       "         415, 416, 417, 420, 421, 422, 423, 425, 427, 428, 429, 430, 431,\n",
       "         432, 433, 434, 435, 436, 437, 439, 443, 444, 445, 447, 448, 450,\n",
       "         451, 454, 455, 456, 457, 458, 459, 460, 461, 462, 465, 466, 467,\n",
       "         470, 471, 473, 474, 475, 476, 477, 478, 479, 480, 481, 483, 487,\n",
       "         488, 489, 490, 493, 494, 495, 497, 498, 500, 501, 502, 504, 506,\n",
       "         508, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521,\n",
       "         524, 525, 526, 528, 529, 531, 532, 534, 535, 536, 537, 542, 544,\n",
       "         545, 549, 554, 558, 559, 560, 561, 562, 564, 565, 567, 568, 569,\n",
       "         570, 571, 572, 573, 574, 576, 577, 578, 579, 580, 581, 582, 583,\n",
       "         584, 585, 586, 587, 589, 591, 593, 594, 595, 597, 601, 603, 604,\n",
       "         605, 607, 609, 610, 611, 612, 613, 614, 617, 618, 619, 622, 623,\n",
       "         625, 626, 627, 628, 629, 632, 633, 634, 635, 636, 637, 638, 639,\n",
       "         641, 642, 644, 645, 647, 648, 649, 650, 652, 653, 654, 655, 658,\n",
       "         660, 661, 662, 663, 664, 665, 666, 667, 668, 670, 672, 673, 675,\n",
       "         679, 680, 682, 683, 685, 686, 687, 688, 689, 690, 691, 693, 694,\n",
       "         695, 696, 698, 699, 700, 703, 704, 706, 707, 708, 709, 712, 715,\n",
       "         717, 718, 720, 721, 723, 727, 729, 730, 732, 735, 736, 738, 739,\n",
       "         740, 741, 743, 744, 747, 748, 749, 750, 751, 753, 758, 759, 761,\n",
       "         764, 765, 767, 768, 770, 771, 773, 775, 777, 778, 779, 780, 781,\n",
       "         784, 785, 786, 789, 793, 794, 796, 797, 803, 804, 805, 806, 807,\n",
       "         808, 809, 810, 813, 815, 817, 818, 820, 821, 822, 823, 824, 826,\n",
       "         830, 831, 833, 835, 836, 837, 838, 840, 841, 842, 843, 844, 845,\n",
       "         847, 848, 849, 850, 851, 852, 855, 857, 858, 860, 861, 862, 863,\n",
       "         864, 866, 868, 869, 870, 871, 873, 875, 876, 877, 879, 880, 881,\n",
       "         882, 883, 884, 885, 886, 887, 888, 889, 890, 893, 894, 895, 896,\n",
       "         897, 902, 903, 904, 906, 907, 908, 911, 912, 913, 916, 918, 919,\n",
       "         920, 921, 926, 927, 929, 930, 931, 932, 935, 937, 939, 940, 942,\n",
       "         944, 945, 946, 947, 948, 949, 950, 952, 953, 954, 956, 958, 959,\n",
       "         960, 961, 962, 963, 964, 966, 969, 970, 972, 973, 974, 975, 976,\n",
       "         977, 980, 981, 982, 983, 985, 986, 988, 989, 991, 993, 994, 995,\n",
       "         996, 997, 999]),\n",
       "  array([  3,   9,  12,  13,  15,  22,  24,  30,  31,  32,  37,  39,  40,\n",
       "          41,  47,  48,  52,  55,  60,  61,  63,  64,  70,  73,  74,  75,\n",
       "          77,  83,  86,  87,  88,  89,  90,  91,  92,  94,  99, 101, 104,\n",
       "         108, 109, 114, 115, 116, 125, 128, 130, 131, 132, 134, 137, 139,\n",
       "         141, 146, 150, 153, 156, 157, 158, 159, 160, 161, 167, 169, 170,\n",
       "         176, 178, 179, 180, 187, 190, 191, 193, 194, 195, 196, 201, 206,\n",
       "         207, 211, 216, 217, 222, 226, 228, 229, 231, 237, 239, 240, 241,\n",
       "         243, 249, 251, 255, 260, 263, 264, 270, 271, 277, 278, 281, 283,\n",
       "         284, 285, 289, 292, 293, 294, 295, 298, 309, 313, 316, 319, 320,\n",
       "         326, 329, 330, 332, 336, 338, 341, 345, 351, 355, 360, 367, 375,\n",
       "         378, 379, 381, 382, 391, 394, 396, 400, 403, 404, 405, 412, 418,\n",
       "         419, 424, 426, 438, 440, 441, 442, 446, 449, 452, 453, 463, 464,\n",
       "         468, 469, 472, 482, 484, 485, 486, 491, 492, 496, 499, 503, 505,\n",
       "         507, 509, 522, 523, 527, 530, 533, 538, 539, 540, 541, 543, 546,\n",
       "         547, 548, 550, 551, 552, 553, 555, 556, 557, 563, 566, 575, 588,\n",
       "         590, 592, 596, 598, 599, 600, 602, 606, 608, 615, 616, 620, 621,\n",
       "         624, 630, 631, 640, 643, 646, 651, 656, 657, 659, 669, 671, 674,\n",
       "         676, 677, 678, 681, 684, 692, 697, 701, 702, 705, 710, 711, 713,\n",
       "         714, 716, 719, 722, 724, 725, 726, 728, 731, 733, 734, 737, 742,\n",
       "         745, 746, 752, 754, 755, 756, 757, 760, 762, 763, 766, 769, 772,\n",
       "         774, 776, 782, 783, 787, 788, 790, 791, 792, 795, 798, 799, 800,\n",
       "         801, 802, 811, 812, 814, 816, 819, 825, 827, 828, 829, 832, 834,\n",
       "         839, 846, 853, 854, 856, 859, 865, 867, 872, 874, 878, 891, 892,\n",
       "         898, 899, 900, 901, 905, 909, 910, 914, 915, 917, 922, 923, 924,\n",
       "         925, 928, 933, 934, 936, 938, 941, 943, 951, 955, 957, 965, 967,\n",
       "         968, 971, 978, 979, 984, 987, 990, 992, 998])),\n",
       " (array([  0,   1,   2,   3,   6,   7,   8,   9,  10,  12,  13,  14,  15,\n",
       "          16,  20,  21,  22,  24,  26,  29,  30,  31,  32,  35,  36,  37,\n",
       "          38,  39,  40,  41,  44,  47,  48,  49,  52,  55,  56,  57,  59,\n",
       "          60,  61,  62,  63,  64,  67,  68,  70,  71,  72,  73,  74,  75,\n",
       "          77,  79,  80,  81,  83,  86,  87,  88,  89,  90,  91,  92,  94,\n",
       "          97,  99, 100, 101, 103, 104, 108, 109, 114, 115, 116, 118, 119,\n",
       "         121, 123, 124, 125, 128, 129, 130, 131, 132, 133, 134, 135, 137,\n",
       "         139, 141, 142, 143, 144, 146, 147, 149, 150, 151, 152, 153, 154,\n",
       "         155, 156, 157, 158, 159, 160, 161, 167, 169, 170, 172, 174, 175,\n",
       "         176, 178, 179, 180, 181, 183, 184, 185, 186, 187, 188, 189, 190,\n",
       "         191, 192, 193, 194, 195, 196, 198, 200, 201, 204, 205, 206, 207,\n",
       "         208, 209, 210, 211, 212, 216, 217, 218, 222, 223, 224, 226, 228,\n",
       "         229, 230, 231, 234, 237, 239, 240, 241, 242, 243, 244, 247, 248,\n",
       "         249, 251, 252, 255, 257, 260, 261, 263, 264, 268, 270, 271, 274,\n",
       "         277, 278, 279, 281, 282, 283, 284, 285, 287, 288, 289, 291, 292,\n",
       "         293, 294, 295, 296, 298, 303, 307, 309, 310, 311, 312, 313, 314,\n",
       "         316, 317, 318, 319, 320, 321, 324, 326, 329, 330, 331, 332, 336,\n",
       "         337, 338, 339, 341, 342, 343, 344, 345, 346, 351, 352, 355, 356,\n",
       "         360, 362, 363, 365, 367, 369, 372, 374, 375, 377, 378, 379, 381,\n",
       "         382, 383, 384, 386, 390, 391, 392, 393, 394, 396, 399, 400, 402,\n",
       "         403, 404, 405, 407, 408, 410, 411, 412, 414, 416, 417, 418, 419,\n",
       "         420, 421, 424, 425, 426, 427, 430, 432, 433, 435, 436, 437, 438,\n",
       "         439, 440, 441, 442, 443, 444, 445, 446, 448, 449, 451, 452, 453,\n",
       "         457, 458, 459, 460, 462, 463, 464, 465, 466, 467, 468, 469, 470,\n",
       "         472, 473, 474, 477, 478, 480, 482, 483, 484, 485, 486, 487, 488,\n",
       "         489, 490, 491, 492, 494, 496, 497, 499, 500, 503, 504, 505, 506,\n",
       "         507, 509, 510, 513, 514, 517, 518, 519, 520, 522, 523, 524, 527,\n",
       "         528, 530, 533, 536, 538, 539, 540, 541, 542, 543, 546, 547, 548,\n",
       "         549, 550, 551, 552, 553, 554, 555, 556, 557, 562, 563, 564, 566,\n",
       "         567, 568, 570, 571, 573, 574, 575, 576, 577, 580, 581, 583, 587,\n",
       "         588, 590, 592, 593, 594, 596, 598, 599, 600, 602, 605, 606, 608,\n",
       "         611, 613, 615, 616, 617, 619, 620, 621, 622, 623, 624, 627, 628,\n",
       "         630, 631, 633, 634, 635, 637, 638, 640, 642, 643, 644, 645, 646,\n",
       "         648, 650, 651, 652, 655, 656, 657, 658, 659, 661, 662, 666, 669,\n",
       "         671, 674, 676, 677, 678, 679, 681, 684, 686, 690, 692, 693, 695,\n",
       "         697, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711,\n",
       "         712, 713, 714, 716, 718, 719, 721, 722, 723, 724, 725, 726, 728,\n",
       "         729, 730, 731, 733, 734, 737, 738, 739, 740, 742, 745, 746, 747,\n",
       "         748, 749, 750, 752, 754, 755, 756, 757, 758, 760, 762, 763, 766,\n",
       "         769, 770, 772, 773, 774, 775, 776, 777, 779, 782, 783, 784, 787,\n",
       "         788, 790, 791, 792, 793, 795, 796, 797, 798, 799, 800, 801, 802,\n",
       "         803, 804, 805, 808, 809, 811, 812, 813, 814, 815, 816, 817, 819,\n",
       "         820, 822, 823, 825, 826, 827, 828, 829, 832, 834, 835, 838, 839,\n",
       "         842, 845, 846, 847, 848, 849, 851, 853, 854, 855, 856, 857, 858,\n",
       "         859, 861, 862, 864, 865, 866, 867, 868, 872, 874, 875, 877, 878,\n",
       "         879, 881, 882, 884, 885, 886, 891, 892, 893, 895, 896, 897, 898,\n",
       "         899, 900, 901, 902, 903, 905, 908, 909, 910, 911, 913, 914, 915,\n",
       "         916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 927, 928, 929,\n",
       "         931, 933, 934, 935, 936, 938, 939, 940, 941, 943, 944, 947, 949,\n",
       "         950, 951, 952, 953, 955, 957, 962, 963, 965, 966, 967, 968, 969,\n",
       "         971, 972, 976, 977, 978, 979, 982, 983, 984, 986, 987, 988, 990,\n",
       "         992, 995, 997, 998]),\n",
       "  array([  4,   5,  11,  17,  18,  19,  23,  25,  27,  28,  33,  34,  42,\n",
       "          43,  45,  46,  50,  51,  53,  54,  58,  65,  66,  69,  76,  78,\n",
       "          82,  84,  85,  93,  95,  96,  98, 102, 105, 106, 107, 110, 111,\n",
       "         112, 113, 117, 120, 122, 126, 127, 136, 138, 140, 145, 148, 162,\n",
       "         163, 164, 165, 166, 168, 171, 173, 177, 182, 197, 199, 202, 203,\n",
       "         213, 214, 215, 219, 220, 221, 225, 227, 232, 233, 235, 236, 238,\n",
       "         245, 246, 250, 253, 254, 256, 258, 259, 262, 265, 266, 267, 269,\n",
       "         272, 273, 275, 276, 280, 286, 290, 297, 299, 300, 301, 302, 304,\n",
       "         305, 306, 308, 315, 322, 323, 325, 327, 328, 333, 334, 335, 340,\n",
       "         347, 348, 349, 350, 353, 354, 357, 358, 359, 361, 364, 366, 368,\n",
       "         370, 371, 373, 376, 380, 385, 387, 388, 389, 395, 397, 398, 401,\n",
       "         406, 409, 413, 415, 422, 423, 428, 429, 431, 434, 447, 450, 454,\n",
       "         455, 456, 461, 471, 475, 476, 479, 481, 493, 495, 498, 501, 502,\n",
       "         508, 511, 512, 515, 516, 521, 525, 526, 529, 531, 532, 534, 535,\n",
       "         537, 544, 545, 558, 559, 560, 561, 565, 569, 572, 578, 579, 582,\n",
       "         584, 585, 586, 589, 591, 595, 597, 601, 603, 604, 607, 609, 610,\n",
       "         612, 614, 618, 625, 626, 629, 632, 636, 639, 641, 647, 649, 653,\n",
       "         654, 660, 663, 664, 665, 667, 668, 670, 672, 673, 675, 680, 682,\n",
       "         683, 685, 687, 688, 689, 691, 694, 696, 698, 699, 715, 717, 720,\n",
       "         727, 732, 735, 736, 741, 743, 744, 751, 753, 759, 761, 764, 765,\n",
       "         767, 768, 771, 778, 780, 781, 785, 786, 789, 794, 806, 807, 810,\n",
       "         818, 821, 824, 830, 831, 833, 836, 837, 840, 841, 843, 844, 850,\n",
       "         852, 860, 863, 869, 870, 871, 873, 876, 880, 883, 887, 888, 889,\n",
       "         890, 894, 904, 906, 907, 912, 926, 930, 932, 937, 942, 945, 946,\n",
       "         948, 954, 956, 958, 959, 960, 961, 964, 970, 973, 974, 975, 980,\n",
       "         981, 985, 989, 991, 993, 994, 996, 999])),\n",
       " (array([  3,   4,   5,   9,  11,  12,  13,  15,  17,  18,  19,  22,  23,\n",
       "          24,  25,  27,  28,  30,  31,  32,  33,  34,  37,  39,  40,  41,\n",
       "          42,  43,  45,  46,  47,  48,  50,  51,  52,  53,  54,  55,  58,\n",
       "          60,  61,  63,  64,  65,  66,  69,  70,  73,  74,  75,  76,  77,\n",
       "          78,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,  92,  93,\n",
       "          94,  95,  96,  98,  99, 101, 102, 104, 105, 106, 107, 108, 109,\n",
       "         110, 111, 112, 113, 114, 115, 116, 117, 120, 122, 125, 126, 127,\n",
       "         128, 130, 131, 132, 134, 136, 137, 138, 139, 140, 141, 145, 146,\n",
       "         148, 150, 153, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165,\n",
       "         166, 167, 168, 169, 170, 171, 173, 176, 177, 178, 179, 180, 182,\n",
       "         187, 190, 191, 193, 194, 195, 196, 197, 199, 201, 202, 203, 206,\n",
       "         207, 211, 213, 214, 215, 216, 217, 219, 220, 221, 222, 225, 226,\n",
       "         227, 228, 229, 231, 232, 233, 235, 236, 237, 238, 239, 240, 241,\n",
       "         243, 245, 246, 249, 250, 251, 253, 254, 255, 256, 258, 259, 260,\n",
       "         262, 263, 264, 265, 266, 267, 269, 270, 271, 272, 273, 275, 276,\n",
       "         277, 278, 280, 281, 283, 284, 285, 286, 289, 290, 292, 293, 294,\n",
       "         295, 297, 298, 299, 300, 301, 302, 304, 305, 306, 308, 309, 313,\n",
       "         315, 316, 319, 320, 322, 323, 325, 326, 327, 328, 329, 330, 332,\n",
       "         333, 334, 335, 336, 338, 340, 341, 345, 347, 348, 349, 350, 351,\n",
       "         353, 354, 355, 357, 358, 359, 360, 361, 364, 366, 367, 368, 370,\n",
       "         371, 373, 375, 376, 378, 379, 380, 381, 382, 385, 387, 388, 389,\n",
       "         391, 394, 395, 396, 397, 398, 400, 401, 403, 404, 405, 406, 409,\n",
       "         412, 413, 415, 418, 419, 422, 423, 424, 426, 428, 429, 431, 434,\n",
       "         438, 440, 441, 442, 446, 447, 449, 450, 452, 453, 454, 455, 456,\n",
       "         461, 463, 464, 468, 469, 471, 472, 475, 476, 479, 481, 482, 484,\n",
       "         485, 486, 491, 492, 493, 495, 496, 498, 499, 501, 502, 503, 505,\n",
       "         507, 508, 509, 511, 512, 515, 516, 521, 522, 523, 525, 526, 527,\n",
       "         529, 530, 531, 532, 533, 534, 535, 537, 538, 539, 540, 541, 543,\n",
       "         544, 545, 546, 547, 548, 550, 551, 552, 553, 555, 556, 557, 558,\n",
       "         559, 560, 561, 563, 565, 566, 569, 572, 575, 578, 579, 582, 584,\n",
       "         585, 586, 588, 589, 590, 591, 592, 595, 596, 597, 598, 599, 600,\n",
       "         601, 602, 603, 604, 606, 607, 608, 609, 610, 612, 614, 615, 616,\n",
       "         618, 620, 621, 624, 625, 626, 629, 630, 631, 632, 636, 639, 640,\n",
       "         641, 643, 646, 647, 649, 651, 653, 654, 656, 657, 659, 660, 663,\n",
       "         664, 665, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677,\n",
       "         678, 680, 681, 682, 683, 684, 685, 687, 688, 689, 691, 692, 694,\n",
       "         696, 697, 698, 699, 701, 702, 705, 710, 711, 713, 714, 715, 716,\n",
       "         717, 719, 720, 722, 724, 725, 726, 727, 728, 731, 732, 733, 734,\n",
       "         735, 736, 737, 741, 742, 743, 744, 745, 746, 751, 752, 753, 754,\n",
       "         755, 756, 757, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768,\n",
       "         769, 771, 772, 774, 776, 778, 780, 781, 782, 783, 785, 786, 787,\n",
       "         788, 789, 790, 791, 792, 794, 795, 798, 799, 800, 801, 802, 806,\n",
       "         807, 810, 811, 812, 814, 816, 818, 819, 821, 824, 825, 827, 828,\n",
       "         829, 830, 831, 832, 833, 834, 836, 837, 839, 840, 841, 843, 844,\n",
       "         846, 850, 852, 853, 854, 856, 859, 860, 863, 865, 867, 869, 870,\n",
       "         871, 872, 873, 874, 876, 878, 880, 883, 887, 888, 889, 890, 891,\n",
       "         892, 894, 898, 899, 900, 901, 904, 905, 906, 907, 909, 910, 912,\n",
       "         914, 915, 917, 922, 923, 924, 925, 926, 928, 930, 932, 933, 934,\n",
       "         936, 937, 938, 941, 942, 943, 945, 946, 948, 951, 954, 955, 956,\n",
       "         957, 958, 959, 960, 961, 964, 965, 967, 968, 970, 971, 973, 974,\n",
       "         975, 978, 979, 980, 981, 984, 985, 987, 989, 990, 991, 992, 993,\n",
       "         994, 996, 998, 999]),\n",
       "  array([  0,   1,   2,   6,   7,   8,  10,  14,  16,  20,  21,  26,  29,\n",
       "          35,  36,  38,  44,  49,  56,  57,  59,  62,  67,  68,  71,  72,\n",
       "          79,  80,  81,  97, 100, 103, 118, 119, 121, 123, 124, 129, 133,\n",
       "         135, 142, 143, 144, 147, 149, 151, 152, 154, 155, 172, 174, 175,\n",
       "         181, 183, 184, 185, 186, 188, 189, 192, 198, 200, 204, 205, 208,\n",
       "         209, 210, 212, 218, 223, 224, 230, 234, 242, 244, 247, 248, 252,\n",
       "         257, 261, 268, 274, 279, 282, 287, 288, 291, 296, 303, 307, 310,\n",
       "         311, 312, 314, 317, 318, 321, 324, 331, 337, 339, 342, 343, 344,\n",
       "         346, 352, 356, 362, 363, 365, 369, 372, 374, 377, 383, 384, 386,\n",
       "         390, 392, 393, 399, 402, 407, 408, 410, 411, 414, 416, 417, 420,\n",
       "         421, 425, 427, 430, 432, 433, 435, 436, 437, 439, 443, 444, 445,\n",
       "         448, 451, 457, 458, 459, 460, 462, 465, 466, 467, 470, 473, 474,\n",
       "         477, 478, 480, 483, 487, 488, 489, 490, 494, 497, 500, 504, 506,\n",
       "         510, 513, 514, 517, 518, 519, 520, 524, 528, 536, 542, 549, 554,\n",
       "         562, 564, 567, 568, 570, 571, 573, 574, 576, 577, 580, 581, 583,\n",
       "         587, 593, 594, 605, 611, 613, 617, 619, 622, 623, 627, 628, 633,\n",
       "         634, 635, 637, 638, 642, 644, 645, 648, 650, 652, 655, 658, 661,\n",
       "         662, 666, 679, 686, 690, 693, 695, 700, 703, 704, 706, 707, 708,\n",
       "         709, 712, 718, 721, 723, 729, 730, 738, 739, 740, 747, 748, 749,\n",
       "         750, 758, 770, 773, 775, 777, 779, 784, 793, 796, 797, 803, 804,\n",
       "         805, 808, 809, 813, 815, 817, 820, 822, 823, 826, 835, 838, 842,\n",
       "         845, 847, 848, 849, 851, 855, 857, 858, 861, 862, 864, 866, 868,\n",
       "         875, 877, 879, 881, 882, 884, 885, 886, 893, 895, 896, 897, 902,\n",
       "         903, 908, 911, 913, 916, 918, 919, 920, 921, 927, 929, 931, 935,\n",
       "         939, 940, 944, 947, 949, 950, 952, 953, 962, 963, 966, 969, 972,\n",
       "         976, 977, 982, 983, 986, 988, 995, 997]))]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(train_index, test_index) for train_index,test_index in kf.split(X)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "43cd9d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=3,shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "346dd69f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  7  15  16  21  23  27  31  34  36  38  40  43  44  45  46  47  48  52\n",
      "  53  55  56  63  68  70  71  81  90  92  97 100 108 113 114 116 117 118\n",
      " 119 121 122 123 125 126 130 131 133 134 135 138 140 142 150 155 162 163\n",
      " 164 166 167 170 171 178 180 182 183 186 190 193 198 199 200 203 204 208\n",
      " 209 210 211 215 219 220 224 225 228 230 233 243 245 246 247 254 258 262\n",
      " 263 271 273 274 275 276 278 281 286 291 295 296 300 306 307 317 318 322\n",
      " 327 337 338 339 350 351 353 354 362 364 369 370 371 373 379 381 384 386\n",
      " 388 392 393 397 398 399 401 405 407 408 410 412 414 415 420 421 423 425\n",
      " 433 438 442 444 448 457 458 460 463 464 465 466 468 470 472 474 475 477\n",
      " 480 484 486 495 496 498 499 501 504 508 509 510 518 520 527 533 534 535\n",
      " 536 537 539 541 543 544 545 549 553 554 557 558 576 585 586 587 588 589\n",
      " 595 597 602 608 609 613 614 615 617 618 619 625 626 630 633 634 635 636\n",
      " 638 640 643 645 646 647 648 650 652 654 657 666 669 672 673 677 679 683\n",
      " 694 695 697 699 701 702 714 715 718 719 728 733 735 737 739 740 744 746\n",
      " 747 749 751 753 754 758 761 763 764 767 776 777 780 783 784 785 787 788\n",
      " 791 795 800 809 811 820 823 824 826 827 828 831 832 833 839 840 844 846\n",
      " 847 850 851 854 861 864 870 873 874 878 885 886 888 890 892 893 894 898\n",
      " 901 905 911 912 917 919 921 929 930 931 934 936 937 941 942 944 950 952\n",
      " 955 971 972 973 980 981 988 989 994 996]\n",
      "[  0   3   4   5   6   8   9  11  12  13  17  19  20  24  25  26  29  32\n",
      "  33  35  37  42  49  50  57  58  59  60  61  62  65  66  67  72  73  74\n",
      "  78  79  80  83  84  85  86  87  88  93  98  99 104 105 106 107 109 110\n",
      " 112 120 128 136 139 144 148 151 152 153 154 157 158 159 160 161 165 172\n",
      " 181 184 188 191 201 202 206 207 212 214 216 218 226 227 231 236 237 238\n",
      " 239 248 250 253 255 260 265 266 268 269 270 272 280 283 284 285 288 289\n",
      " 292 297 299 301 303 304 305 308 309 311 312 313 314 316 319 320 321 323\n",
      " 328 329 334 335 336 340 343 347 352 355 358 359 360 363 372 374 375 376\n",
      " 377 378 382 385 389 391 394 396 400 402 403 404 409 411 413 417 419 424\n",
      " 426 428 431 432 436 443 445 447 450 451 453 456 469 471 473 476 479 483\n",
      " 485 487 488 490 493 494 502 503 506 514 519 521 523 525 528 530 531 532\n",
      " 540 548 550 552 555 559 562 563 564 567 572 577 580 582 584 590 594 596\n",
      " 599 601 603 604 624 631 632 641 649 655 656 658 661 663 675 680 685 686\n",
      " 687 688 689 691 692 693 696 705 706 707 711 712 717 723 724 725 726 732\n",
      " 736 741 743 748 760 774 781 782 789 793 794 798 801 807 810 812 813 814\n",
      " 815 816 825 829 836 841 843 845 848 853 857 860 866 868 869 877 879 880\n",
      " 881 882 889 891 895 896 897 899 900 903 914 915 916 920 922 924 927 928\n",
      " 932 935 939 951 954 957 959 960 961 963 965 966 967 969 974 975 977 978\n",
      " 979 982 984 986 990 992 993 997 999]\n",
      "[  1   2  10  14  18  22  28  30  39  41  51  54  64  69  75  76  77  82\n",
      "  89  91  94  95  96 101 102 103 111 115 124 127 129 132 137 141 143 145\n",
      " 146 147 149 156 168 169 173 174 175 176 177 179 185 187 189 192 194 195\n",
      " 196 197 205 213 217 221 222 223 229 232 234 235 240 241 242 244 249 251\n",
      " 252 256 257 259 261 264 267 277 279 282 287 290 293 294 298 302 310 315\n",
      " 324 325 326 330 331 332 333 341 342 344 345 346 348 349 356 357 361 365\n",
      " 366 367 368 380 383 387 390 395 406 416 418 422 427 429 430 434 435 437\n",
      " 439 440 441 446 449 452 454 455 459 461 462 467 478 481 482 489 491 492\n",
      " 497 500 505 507 511 512 513 515 516 517 522 524 526 529 538 542 546 547\n",
      " 551 556 560 561 565 566 568 569 570 571 573 574 575 578 579 581 583 591\n",
      " 592 593 598 600 605 606 607 610 611 612 616 620 621 622 623 627 628 629\n",
      " 637 639 642 644 651 653 659 660 662 664 665 667 668 670 671 674 676 678\n",
      " 681 682 684 690 698 700 703 704 708 709 710 713 716 720 721 722 727 729\n",
      " 730 731 734 738 742 745 750 752 755 756 757 759 762 765 766 768 769 770\n",
      " 771 772 773 775 778 779 786 790 792 796 797 799 802 803 804 805 806 808\n",
      " 817 818 819 821 822 830 834 835 837 838 842 849 852 855 856 858 859 862\n",
      " 863 865 867 871 872 875 876 883 884 887 902 904 906 907 908 909 910 913\n",
      " 918 923 925 926 933 938 940 943 945 946 947 948 949 953 956 958 962 964\n",
      " 968 970 976 983 985 987 991 995 998]\n"
     ]
    }
   ],
   "source": [
    "for train_index, test_index in kf.split(X):\n",
    "    print(test_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "803dd252",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06412da5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating dataset: 1029_LEV\n",
      "Fold #1\n",
      "16/16 [==============================] - 0s 800us/step\n",
      "16/16 [==============================] - 0s 867us/step\n",
      "16/16 [==============================] - 0s 797us/step\n",
      "16/16 [==============================] - 0s 868us/step\n",
      "16/16 [==============================] - 0s 867us/step\n",
      "16/16 [==============================] - 0s 860us/step\n",
      "16/16 [==============================] - 0s 1ms/step\n",
      "16/16 [==============================] - 0s 867us/step\n",
      "16/16 [==============================] - 0s 934us/step\n",
      "16/16 [==============================] - 0s 1ms/step\n",
      "16/16 [==============================] - 0s 934us/step\n",
      "16/16 [==============================] - 0s 934us/step\n",
      "16/16 [==============================] - 0s 1ms/step\n",
      "16/16 [==============================] - 0s 1ms/step\n",
      "16/16 [==============================] - 0s 867us/step\n",
      "16/16 [==============================] - 0s 1ms/step\n",
      "16/16 [==============================] - 0s 925us/step\n",
      "16/16 [==============================] - 0s 623us/step\n",
      "16/16 [==============================] - 0s 1000us/step\n",
      "Fold #2\n",
      "16/16 [==============================] - 0s 865us/step\n",
      "16/16 [==============================] - 0s 932us/step\n",
      "16/16 [==============================] - 0s 864us/step\n",
      "16/16 [==============================] - 0s 933us/step\n",
      "16/16 [==============================] - 2s 1ms/step\n",
      "16/16 [==============================] - 0s 807us/step\n",
      "16/16 [==============================] - 0s 1ms/step\n",
      "16/16 [==============================] - 0s 1000us/step\n",
      "16/16 [==============================] - 0s 860us/step\n",
      "16/16 [==============================] - 0s 1ms/step\n",
      "16/16 [==============================] - 0s 1ms/step\n",
      "16/16 [==============================] - 0s 939us/step\n",
      "16/16 [==============================] - 0s 1ms/step\n",
      "16/16 [==============================] - 0s 1ms/step\n",
      "16/16 [==============================] - 0s 800us/step\n",
      "16/16 [==============================] - 0s 1ms/step\n",
      "16/16 [==============================] - 0s 869us/step\n",
      "16/16 [==============================] - 0s 871us/step\n",
      "16/16 [==============================] - 0s 1ms/step\n",
      "Evaluating dataset: 1030_ERA\n",
      "Fold #1\n",
      "16/16 [==============================] - 0s 800us/step\n",
      "16/16 [==============================] - 0s 1ms/step\n",
      "16/16 [==============================] - 0s 995us/step\n",
      "16/16 [==============================] - 0s 730us/step\n",
      "16/16 [==============================] - 0s 997us/step\n",
      "16/16 [==============================] - 0s 933us/step\n",
      "16/16 [==============================] - 0s 1ms/step\n",
      "16/16 [==============================] - 0s 934us/step\n",
      "16/16 [==============================] - 0s 931us/step\n",
      "16/16 [==============================] - 1s 1ms/step\n",
      "16/16 [==============================] - 0s 1ms/step\n",
      "16/16 [==============================] - 0s 962us/step\n",
      "16/16 [==============================] - 0s 1ms/step\n",
      "16/16 [==============================] - 0s 933us/step\n",
      "16/16 [==============================] - 0s 933us/step\n",
      "16/16 [==============================] - 0s 1ms/step\n",
      "16/16 [==============================] - 0s 933us/step\n",
      "16/16 [==============================] - 0s 867us/step\n",
      "16/16 [==============================] - 0s 1ms/step\n",
      "Fold #2\n",
      "16/16 [==============================] - 0s 871us/step\n",
      "16/16 [==============================] - 0s 1ms/step\n",
      "16/16 [==============================] - 0s 933us/step\n",
      "16/16 [==============================] - 0s 868us/step\n",
      "16/16 [==============================] - 0s 941us/step\n",
      "16/16 [==============================] - 0s 867us/step\n",
      "16/16 [==============================] - 0s 1000us/step\n",
      "16/16 [==============================] - 0s 1ms/step\n",
      "16/16 [==============================] - 0s 868us/step\n",
      "16/16 [==============================] - 0s 933us/step\n",
      "16/16 [==============================] - 0s 800us/step\n",
      "16/16 [==============================] - 0s 1ms/step\n",
      "16/16 [==============================] - 0s 1ms/step\n",
      "16/16 [==============================] - 0s 933us/step\n",
      "16/16 [==============================] - 0s 1ms/step\n",
      "16/16 [==============================] - 0s 997us/step\n",
      "16/16 [==============================] - 0s 874us/step\n",
      "16/16 [==============================] - 0s 859us/step\n",
      "16/16 [==============================] - 0s 1000us/step\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "all_results = {}\n",
    "epoch_number = 1\n",
    "\n",
    "for dataset, row in zip(datasets, filtered_datasets.iterrows()):\n",
    "    dataset_name = row[1]['dataset']\n",
    "    print(f\"Evaluating dataset: {dataset_name}\")\n",
    "\n",
    "    input_dimension = row[1]['n_features']\n",
    "    #models = initialize_all_models(input_dimension)\n",
    "    #compile_models(models)\n",
    "    \n",
    "    data = dataset\n",
    "\n",
    "    X, y = data.drop('target', axis=1).values, data['target'].values\n",
    "\n",
    "    results = []\n",
    "    kf = KFold(n_splits=2,shuffle=True)\n",
    "    fold = 0\n",
    "\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        fold += 1\n",
    "        print(f\"Fold #{fold}\")\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        # Initialize and compile models with unique seed value for each fold\n",
    "        models = initialize_all_models(X_train.shape[1], seed_val=fold)\n",
    "        compile_models(models)\n",
    "\n",
    "        for model, name in models:\n",
    "            history = model.fit(X_train, y_train,\n",
    "                                epochs=epoch_number,\n",
    "                                verbose=0,\n",
    "                                validation_data=(X_test, y_test))\n",
    "\n",
    "            # Get loss and accuracy on test data\n",
    "            #loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "            loss = model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "            # Make predictions to calculate R squared value and test error\n",
    "            predictions = model.predict(X_test)\n",
    "            r_squared_value = r2_score(y_test,predictions)\n",
    "            test_error = mean_squared_error(y_test,predictions)\n",
    "\n",
    "            results.append({\n",
    "                'model': name,\n",
    "                'fold': fold,\n",
    "                'history': history,\n",
    "                'loss': loss,\n",
    "                'r_squared_value': r_squared_value,\n",
    "                'test_error': test_error})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65fad091",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fac62385",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "def cross_validation(data, epoch_number=2):\n",
    "    X, y = data.drop('target', axis=1).values, data['target'].values\n",
    "    \n",
    "    results = []\n",
    "    kf = KFold(n_splits=2)\n",
    "    fold = 0\n",
    "\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        fold += 1\n",
    "        print(f\"Fold #{fold}\")\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        # Initialize and compile models with unique seed value for each fold\n",
    "        models = initialize_all_models(X_train.shape[1], seed_val=fold)\n",
    "        compile_models(models)\n",
    "\n",
    "        for model, name in models:\n",
    "            history = model.fit(X_train, y_train,\n",
    "                                epochs=epoch_number,\n",
    "                                verbose=0,\n",
    "                                validation_data=(X_test, y_test))\n",
    "            \n",
    "            # Get loss and accuracy on test data\n",
    "            #loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "            loss = model.evaluate(X_test, y_test, verbose=0)\n",
    "            \n",
    "            # Make predictions to calculate R squared value and test error\n",
    "            predictions = model.predict(X_test)\n",
    "            r_squared_value = r2_score(y_test,predictions)\n",
    "            test_error = mean_squared_error(y_test,predictions)\n",
    "\n",
    "            results.append({\n",
    "                'model': name,\n",
    "                'fold': fold,\n",
    "                'history': history,\n",
    "                'loss': loss,\n",
    "                'r_squared_value': r_squared_value,\n",
    "                'test_error': test_error})\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "578662bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating dataset: 1029_LEV\n",
      "Fold #1\n",
      "16/16 [==============================] - 0s 874us/step\n",
      "16/16 [==============================] - 0s 868us/step\n",
      "16/16 [==============================] - 0s 797us/step\n",
      "16/16 [==============================] - 0s 735us/step\n",
      "16/16 [==============================] - 0s 933us/step\n",
      "16/16 [==============================] - 0s 1ms/step\n",
      "16/16 [==============================] - 0s 1ms/step\n",
      "16/16 [==============================] - 0s 992us/step\n",
      "16/16 [==============================] - 0s 800us/step\n",
      "16/16 [==============================] - 0s 1000us/step\n",
      "16/16 [==============================] - 0s 800us/step\n",
      "16/16 [==============================] - 0s 933us/step\n",
      "16/16 [==============================] - 0s 1ms/step\n",
      "16/16 [==============================] - 0s 930us/step\n",
      "16/16 [==============================] - 0s 867us/step\n",
      "16/16 [==============================] - 0s 1ms/step\n",
      "16/16 [==============================] - 0s 801us/step\n",
      "16/16 [==============================] - 0s 935us/step\n",
      "16/16 [==============================] - 0s 1000us/step\n",
      "Fold #2\n",
      "16/16 [==============================] - 0s 802us/step\n",
      "16/16 [==============================] - 0s 804us/step\n",
      "16/16 [==============================] - 0s 800us/step\n",
      "16/16 [==============================] - 0s 868us/step\n",
      "16/16 [==============================] - 0s 867us/step\n",
      "16/16 [==============================] - 0s 734us/step\n",
      "16/16 [==============================] - 0s 1000us/step\n",
      "16/16 [==============================] - 0s 930us/step\n",
      "16/16 [==============================] - 0s 933us/step\n",
      "16/16 [==============================] - 0s 1ms/step\n",
      "16/16 [==============================] - 0s 866us/step\n",
      "16/16 [==============================] - 0s 867us/step\n",
      "16/16 [==============================] - 0s 1ms/step\n",
      "16/16 [==============================] - 0s 929us/step\n",
      "16/16 [==============================] - 0s 960us/step\n",
      "16/16 [==============================] - 0s 934us/step\n",
      "16/16 [==============================] - 0s 937us/step\n",
      "16/16 [==============================] - 0s 862us/step\n",
      "16/16 [==============================] - 0s 1ms/step\n",
      "Evaluating dataset: 1030_ERA\n",
      "Fold #1\n",
      "16/16 [==============================] - 0s 844us/step\n",
      "16/16 [==============================] - 0s 867us/step\n",
      "16/16 [==============================] - 0s 866us/step\n",
      "16/16 [==============================] - 0s 1ms/step\n",
      "16/16 [==============================] - 0s 867us/step\n",
      "16/16 [==============================] - 0s 935us/step\n",
      "16/16 [==============================] - 0s 1ms/step\n",
      "16/16 [==============================] - 0s 866us/step\n",
      "16/16 [==============================] - 0s 868us/step\n",
      "16/16 [==============================] - 0s 1000us/step\n",
      "16/16 [==============================] - 0s 933us/step\n",
      "16/16 [==============================] - 0s 740us/step\n",
      "16/16 [==============================] - 0s 1ms/step\n",
      "16/16 [==============================] - 0s 1000us/step\n",
      "16/16 [==============================] - 0s 863us/step\n",
      "16/16 [==============================] - 0s 1ms/step\n",
      "16/16 [==============================] - 0s 929us/step\n",
      "16/16 [==============================] - 0s 734us/step\n",
      "16/16 [==============================] - 0s 1ms/step\n",
      "Fold #2\n",
      "16/16 [==============================] - 0s 733us/step\n",
      "16/16 [==============================] - 0s 867us/step\n",
      "16/16 [==============================] - 0s 735us/step\n",
      "16/16 [==============================] - 0s 799us/step\n",
      "16/16 [==============================] - 0s 867us/step\n",
      "16/16 [==============================] - 0s 866us/step\n",
      "16/16 [==============================] - 0s 1000us/step\n",
      "16/16 [==============================] - 0s 934us/step\n",
      "16/16 [==============================] - 0s 1000us/step\n",
      "16/16 [==============================] - 0s 1ms/step\n",
      "16/16 [==============================] - 0s 892us/step\n",
      "16/16 [==============================] - 0s 874us/step\n",
      "16/16 [==============================] - 0s 1ms/step\n",
      "16/16 [==============================] - 0s 933us/step\n",
      "16/16 [==============================] - 0s 867us/step\n",
      "16/16 [==============================] - 0s 1ms/step\n",
      "16/16 [==============================] - 0s 867us/step\n",
      "16/16 [==============================] - 0s 800us/step\n",
      "16/16 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Object of type History is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 18\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# save results to a JSON file\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresults.json\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m---> 18\u001b[0m     \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_results\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\json\\__init__.py:179\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(obj, fp, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[0;32m    173\u001b[0m     iterable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m(skipkeys\u001b[38;5;241m=\u001b[39mskipkeys, ensure_ascii\u001b[38;5;241m=\u001b[39mensure_ascii,\n\u001b[0;32m    174\u001b[0m         check_circular\u001b[38;5;241m=\u001b[39mcheck_circular, allow_nan\u001b[38;5;241m=\u001b[39mallow_nan, indent\u001b[38;5;241m=\u001b[39mindent,\n\u001b[0;32m    175\u001b[0m         separators\u001b[38;5;241m=\u001b[39mseparators,\n\u001b[0;32m    176\u001b[0m         default\u001b[38;5;241m=\u001b[39mdefault, sort_keys\u001b[38;5;241m=\u001b[39msort_keys, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\u001b[38;5;241m.\u001b[39miterencode(obj)\n\u001b[0;32m    177\u001b[0m \u001b[38;5;66;03m# could accelerate with writelines in some versions of Python, at\u001b[39;00m\n\u001b[0;32m    178\u001b[0m \u001b[38;5;66;03m# a debuggability cost\u001b[39;00m\n\u001b[1;32m--> 179\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[0;32m    180\u001b[0m     fp\u001b[38;5;241m.\u001b[39mwrite(chunk)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\json\\encoder.py:431\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode\u001b[1;34m(o, _current_indent_level)\u001b[0m\n\u001b[0;32m    429\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m _iterencode_list(o, _current_indent_level)\n\u001b[0;32m    430\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(o, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m--> 431\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m _iterencode_dict(o, _current_indent_level)\n\u001b[0;32m    432\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    433\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m markers \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\json\\encoder.py:405\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode_dict\u001b[1;34m(dct, _current_indent_level)\u001b[0m\n\u001b[0;32m    403\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    404\u001b[0m             chunks \u001b[38;5;241m=\u001b[39m _iterencode(value, _current_indent_level)\n\u001b[1;32m--> 405\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m chunks\n\u001b[0;32m    406\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m newline_indent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    407\u001b[0m     _current_indent_level \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\json\\encoder.py:325\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode_list\u001b[1;34m(lst, _current_indent_level)\u001b[0m\n\u001b[0;32m    323\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    324\u001b[0m             chunks \u001b[38;5;241m=\u001b[39m _iterencode(value, _current_indent_level)\n\u001b[1;32m--> 325\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m chunks\n\u001b[0;32m    326\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m newline_indent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    327\u001b[0m     _current_indent_level \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\json\\encoder.py:405\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode_dict\u001b[1;34m(dct, _current_indent_level)\u001b[0m\n\u001b[0;32m    403\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    404\u001b[0m             chunks \u001b[38;5;241m=\u001b[39m _iterencode(value, _current_indent_level)\n\u001b[1;32m--> 405\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m chunks\n\u001b[0;32m    406\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m newline_indent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    407\u001b[0m     _current_indent_level \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\json\\encoder.py:438\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode\u001b[1;34m(o, _current_indent_level)\u001b[0m\n\u001b[0;32m    436\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCircular reference detected\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    437\u001b[0m     markers[markerid] \u001b[38;5;241m=\u001b[39m o\n\u001b[1;32m--> 438\u001b[0m o \u001b[38;5;241m=\u001b[39m \u001b[43m_default\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    439\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m _iterencode(o, _current_indent_level)\n\u001b[0;32m    440\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m markers \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\json\\encoder.py:179\u001b[0m, in \u001b[0;36mJSONEncoder.default\u001b[1;34m(self, o)\u001b[0m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault\u001b[39m(\u001b[38;5;28mself\u001b[39m, o):\n\u001b[0;32m    161\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Implement this method in a subclass such that it returns\u001b[39;00m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;124;03m    a serializable object for ``o``, or calls the base implementation\u001b[39;00m\n\u001b[0;32m    163\u001b[0m \u001b[38;5;124;03m    (to raise a ``TypeError``).\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    177\u001b[0m \n\u001b[0;32m    178\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 179\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mObject of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mo\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    180\u001b[0m                     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis not JSON serializable\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: Object of type History is not JSON serializable"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "all_results = {}\n",
    "\n",
    "for dataset, row in zip(datasets, filtered_datasets.iterrows()):\n",
    "    dataset_name = row[1]['dataset']\n",
    "    print(f\"Evaluating dataset: {dataset_name}\")\n",
    "\n",
    "    input_dimension = row[1]['n_features']\n",
    "    #models = initialize_all_models(input_dimension)\n",
    "    #compile_models(models)\n",
    "\n",
    "    results = cross_validation(dataset)\n",
    "    all_results[dataset_name] = results\n",
    "\n",
    "# save results to a JSON file\n",
    "with open('results.json', 'w') as f:\n",
    "    json.dump(all_results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31768391",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d549c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0dfda2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4724174",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5f6f3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e051ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2100363c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = {}\n",
    "\n",
    "for dataset, row in zip(datasets, filtered_datasets.iterrows()):\n",
    "    dataset_name = row[1]['dataset']\n",
    "    print(f\"Evaluating dataset: {dataset_name}\")\n",
    "\n",
    "    input_dimension = row[1]['n_features']\n",
    "    models = initialize_all_models(input_dimension, seed_val=42)\n",
    "    compile_models(models)\n",
    "\n",
    "    results = cross_val(models, dataset)\n",
    "    all_results[dataset_name] = results\n",
    "\n",
    "print(all_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04344e19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72fee099",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b9b0f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6b504e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eac75af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a5ca5e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating dataset: 1030_ERA\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 981us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1000us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 994us/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 989us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 992us/step\n",
      "4/4 [==============================] - 0s 992us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 996us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 979us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 980us/step\n",
      "4/4 [==============================] - 0s 999us/step\n",
      "4/4 [==============================] - 0s 991us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 684us/step\n",
      "4/4 [==============================] - 0s 987us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 993us/step\n",
      "4/4 [==============================] - 0s 981us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 982us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 688us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 996us/step\n",
      "4/4 [==============================] - 0s 965us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1000us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 999us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 998us/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 994us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 989us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 991us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 998us/step\n",
      "4/4 [==============================] - 0s 1000us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1000us/step\n",
      "4/4 [==============================] - 0s 999us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 993us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 988us/step\n",
      "4/4 [==============================] - 0s 981us/step\n",
      "4/4 [==============================] - 0s 989us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 666us/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 977us/step\n",
      "4/4 [==============================] - 0s 999us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 983us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 986us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 980us/step\n",
      "4/4 [==============================] - 0s 690us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 984us/step\n",
      "4/4 [==============================] - 0s 974us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 966us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 998us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 968us/step\n",
      "4/4 [==============================] - 0s 705us/step\n",
      "4/4 [==============================] - 0s 990us/step\n",
      "4/4 [==============================] - 0s 981us/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 981us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 988us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 963us/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1000us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 667us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 976us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 985us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "{'1030_ERA': {'Linear Model': [3.8531771981716156, 3.819590944945812, 3.7945997408032417, 3.1281222593784332, 2.861634168624878, 2.398332995772362, 1.9819897782802582, 1.9569971477985382, 2.015181655883789, 1.8134105348587035], 'Wide ReLU ANN': [1.1086437726020812, 1.3716701412200927, 1.2909508776664733, 1.2591666722297667, 1.1933196902275085, 1.0947322845458984, 1.2583980798721313, 1.1224033093452455, 1.310504549741745, 1.2581566095352172], 'Deep ReLU ANN': [1.1132738101482391, 1.4158685731887817, 1.3811927342414856, 1.2575048041343688, 1.1670758676528932, 1.0914067101478577, 1.2408037304878234, 1.1180108380317688, 1.3448182368278503, 1.2617321062088012], 'One Parameter': [3.8217566275596617, 3.7517603611946106, 3.8117640948295595, 3.1428709745407106, 2.857427086830139, 2.4835174036026, 2.064221992492676, 2.111298151016235, 2.1524038219451906, 1.9879837465286254], 'Spline ANN (z=1)': [3.0057036113739013, 2.420246036052704, 2.1653963994979857, 1.7359522080421448, 1.667496724128723, 1.339041211605072, 1.2702502489089966, 1.2764686918258668, 1.3420899391174317, 1.300627292394638], 'Lookup Table (z=1)': [3.8217566275596617, 3.7517603611946106, 3.8117640948295595, 3.1422643518447875, 2.8577601718902588, 2.4820826053619385, 2.0609497165679933, 2.109037184715271, 2.1473672771453858, 1.9849324655532836], 'ABEL-Spline (z=1)': [1.392329788208008, 1.3915201556682586, 1.3097103691101075, 1.267121456861496, 1.1825968194007874, 1.0979814195632935, 1.2762589764595031, 1.116168417930603, 1.3764040875434875, 1.2711957001686096], 'Spline ANN (z=2)': [2.9966184484958647, 2.416906715631485, 2.180957722663879, 1.7296543622016907, 1.6358657503128051, 1.318711359500885, 1.2488045072555543, 1.2511910438537597, 1.3608493649959563, 1.2897015392780304], 'Lookup Table (z=2)': [3.8646799486875536, 3.8544283467531204, 3.967177751660347, 3.3209688770771026, 3.023624210357666, 2.713580938577652, 2.3347015953063965, 2.292964074611664, 2.341232657432556, 2.1607451283931733], 'ABEL-Spline (z=2)': [1.3678218507766724, 1.397044141292572, 1.3056993722915649, 1.2494385600090028, 1.1627726709842683, 1.103510766029358, 1.2399392652511596, 1.1230074906349181, 1.353660353422165, 1.2485291731357575], 'Spline ANN (z=4)': [3.0307297897338867, 2.473769735097885, 2.2417872095108033, 1.736538438796997, 1.6189511513710022, 1.3278136706352235, 1.2144450521469117, 1.2490053582191467, 1.3831937277317048, 1.3006822562217712], 'Lookup Table (z=4)': [3.8948090465366842, 3.9231517538428307, 4.089332952499389, 3.469763660430908, 3.1781806111335755, 2.87610914349556, 2.5827603554725647, 2.5027572965621947, 2.58297979593277, 2.359542980194092], 'ABEL-Spline (z=4)': [1.365631082057953, 1.414903062582016, 1.3157648754119873, 1.2639078640937804, 1.165104638338089, 1.0801715302467345, 1.227629281282425, 1.132690864801407, 1.2850228869915008, 1.2297863698005675], 'Spline ANN (z=8)': [3.0904270362854005, 2.5721943521499635, 2.3371572375297545, 1.7717692279815673, 1.6247546696662902, 1.3402610611915589, 1.1902720594406129, 1.2326865196228027, 1.3805143356323242, 1.2855949401855469], 'Lookup Table (z=8)': [3.914685636907816, 3.9419270834326743, 4.114495525360107, 3.5101322692632677, 3.212032732963562, 2.9322136479616163, 2.64692336499691, 2.5771523332595825, 2.6549682593345643, 2.4828236472606657], 'ABEL-Spline (z=8)': [1.3917340993881226, 1.4085582828521728, 1.3051419734954834, 1.2639669394493103, 1.1780497860908508, 1.067772080898285, 1.1854198503494262, 1.144283528327942, 1.267516723871231, 1.248876198530197], 'Spline ANN (z=10)': [3.1077489894628525, 2.588061375617981, 2.348632060289383, 1.7898243570327759, 1.6327488350868224, 1.3422745656967163, 1.1879433441162108, 1.2307293570041657, 1.378462574481964, 1.2879929590225219], 'Lookup Table (z=10)': [3.9143488086014986, 3.9494783625006677, 4.117688221037388, 3.523516554236412, 3.2324251699447633, 2.9568409198522567, 2.677677748799324, 2.608396632671356, 2.692777935266495, 2.4895982468128204], 'ABEL-Spline (z=10)': [1.4045124077796936, 1.4356283593177794, 1.2925674700737, 1.2834748649597167, 1.1715928900241852, 1.078358256816864, 1.1780815720558167, 1.1300725078582763, 1.2833737659454345, 1.2506616914272308]}}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Create a list of names for datasets locally, along with the number of epochs for training, and the model names\n",
    "dataset_names = filtered_datasets['dataset'].tolist()\n",
    "epochs = 10\n",
    "model_names = [name for _, name in models]\n",
    "\n",
    "# Define experiment settings\n",
    "experiment_settings = {\n",
    "    'dataset_names': dataset_names,\n",
    "    'epochs': epochs,\n",
    "    'model_names': model_names\n",
    "}\n",
    "\n",
    "# Check if the file for experimental setup exists and whether it matches the current experimental variable\n",
    "try:\n",
    "    with open('experimental_setup.json', 'r') as f:\n",
    "        saved_experiment_settings = json.load(f)\n",
    "except FileNotFoundError:\n",
    "    saved_experiment_settings = None\n",
    "\n",
    "if saved_experiment_settings != experiment_settings:\n",
    "    # If there are differences or the text file does not exist, then create and save your description to a text file with the same name.\n",
    "    with open('experimental_setup.json', 'w') as f:\n",
    "        json.dump(experiment_settings, f)\n",
    "\n",
    "    # If experimental settings have changed, wipe progress clean\n",
    "    completed_datasets = []\n",
    "else:\n",
    "    # If experimental setup has not changed, load progress from previous run (if it exists)\n",
    "    try:\n",
    "        with open('progress.json', 'r') as f:\n",
    "            completed_datasets = json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        completed_datasets = []\n",
    "        \n",
    "all_results = {}\n",
    "\n",
    "for dataset, row in zip(datasets, filtered_datasets.iterrows()):\n",
    "    dataset_name = row[1]['dataset']\n",
    "    \n",
    "    if dataset_name in completed_datasets:  # Skip already processed datasets\n",
    "        continue\n",
    "\n",
    "    print(f\"Evaluating dataset: {dataset_name}\")\n",
    "\n",
    "    input_dimension = row[1]['n_features']\n",
    "    \n",
    "    models = initialize_all_models(input_dimension=input_dimension,\n",
    "                                   seed_val=42)\n",
    "\n",
    "    compile_models(models)\n",
    "\n",
    "    results = cross_val(models=models,\n",
    "                        data=dataset)\n",
    "\n",
    "    \n",
    "    all_results[dataset_name] = results\n",
    "\n",
    "    # Add dataset to the list of completed datasets and save progress\n",
    "    completed_datasets.append(dataset_name)\n",
    "    with open('progress.json', 'w') as f:\n",
    "        json.dump(completed_datasets, f)\n",
    "\n",
    "print(all_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5304235",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Model  Average MAE  Std Deviation\n",
      "0          Linear Model     0.817498            0.0\n",
      "1         Wide ReLU ANN     0.438172            0.0\n",
      "2         Deep ReLU ANN     0.427755            0.0\n",
      "3         One Parameter     1.027055            0.0\n",
      "4      Spline ANN (z=1)     0.578913            0.0\n",
      "5    Lookup Table (z=1)     1.026886            0.0\n",
      "6     ABEL-Spline (z=1)     0.478548            0.0\n",
      "7      Spline ANN (z=2)     0.574952            0.0\n",
      "8    Lookup Table (z=2)     0.981407            0.0\n",
      "9     ABEL-Spline (z=2)     0.471621            0.0\n",
      "10     Spline ANN (z=4)     0.573082            0.0\n",
      "11   Lookup Table (z=4)     1.172064            0.0\n",
      "12    ABEL-Spline (z=4)     0.473223            0.0\n",
      "13     Spline ANN (z=8)     0.580037            0.0\n",
      "14   Lookup Table (z=8)     1.247612            0.0\n",
      "15    ABEL-Spline (z=8)     0.470044            0.0\n",
      "16    Spline ANN (z=10)     0.572392            0.0\n",
      "17  Lookup Table (z=10)     1.243610            0.0\n",
      "18   ABEL-Spline (z=10)     0.471452            0.0\n"
     ]
    }
   ],
   "source": [
    "# Create a DataFrame to store the results\n",
    "result_data = []\n",
    "\n",
    "# Iterate through all_results and compute mean and std for each model\n",
    "for model_name in all_results[list(all_results.keys())[0]].keys():\n",
    "    all_maes = [np.mean(all_results[dataset][model_name]) for dataset in all_results]\n",
    "    avg_mae = np.mean(all_maes)\n",
    "    std_mae = np.std(all_maes)\n",
    "    result_data.append([model_name, avg_mae, std_mae])\n",
    "\n",
    "# Convert the results to a pandas DataFrame\n",
    "results_df = pd.DataFrame(result_data, columns=['Model', 'Average MAE', 'Std Deviation'])\n",
    "print(results_df)\n",
    "\n",
    "# Add R-squared error,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60beb5d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3384e322",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a494bac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca5d242",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "137efda8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating dataset: 1029_LEV\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 996us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 977us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 667us/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 984us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 975us/step\n",
      "4/4 [==============================] - 0s 1000us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 667us/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1000us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 667us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1000us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 983us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 999us/step\n",
      "4/4 [==============================] - 0s 987us/step\n",
      "4/4 [==============================] - 0s 994us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1000us/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 996us/step\n",
      "4/4 [==============================] - 0s 1000us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 978us/step\n",
      "4/4 [==============================] - 0s 992us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1000us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1000us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1000us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 994us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 988us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1000us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 991us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 982us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 999us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 993us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 995us/step\n",
      "4/4 [==============================] - 0s 943us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 995us/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 998us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 679us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 996us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 980us/step\n",
      "4/4 [==============================] - 0s 661us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 994us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 669us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1000us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 994us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 965us/step\n",
      "4/4 [==============================] - 0s 683us/step\n",
      "4/4 [==============================] - 0s 990us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 667us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "Evaluating dataset: 1030_ERA\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 971us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 999us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 999us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 666us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 988us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 989us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 966us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 662us/step\n",
      "4/4 [==============================] - 0s 985us/step\n",
      "4/4 [==============================] - 0s 981us/step\n",
      "4/4 [==============================] - 0s 966us/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 998us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 964us/step\n",
      "4/4 [==============================] - 0s 648us/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 658us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 975us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 973us/step\n",
      "4/4 [==============================] - 0s 983us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 996us/step\n",
      "4/4 [==============================] - 0s 983us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 992us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1000us/step\n",
      "4/4 [==============================] - 0s 1000us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 999us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 999us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 999us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 996us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 985us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1000us/step\n",
      "4/4 [==============================] - 0s 999us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 668us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 978us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 975us/step\n",
      "4/4 [==============================] - 0s 995us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 713us/step\n",
      "4/4 [==============================] - 0s 989us/step\n",
      "4/4 [==============================] - 0s 983us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1000us/step\n",
      "4/4 [==============================] - 0s 999us/step\n",
      "4/4 [==============================] - 0s 667us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 993us/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 999us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 999us/step\n",
      "4/4 [==============================] - 0s 990us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 981us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 992us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1000us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 964us/step\n",
      "4/4 [==============================] - 0s 979us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1000us/step\n",
      "4/4 [==============================] - 0s 978us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 996us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 673us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 989us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1000us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 680us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 994us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "{'1029_LEV': {'Linear Model': [1.768871571570635, 1.3707225424051286, 1.1655029916763306, 0.7663325721025467, 0.6250245231389999, 0.5596683585643768, 0.4607035970687866, 0.5361593437194824, 0.5138296473026276, 0.43046897649765015], 'Wide ReLU ANN': [0.5617390830814838, 0.49351791605353357, 0.47327164143323897, 0.4149248341470957, 0.4226074993610382, 0.3848393700644374, 0.37083969965577124, 0.4398356653377414, 0.4567626665905118, 0.36179728135466577], 'Deep ReLU ANN': [0.5625948396697641, 0.5162016713619232, 0.47287281915545465, 0.3998201033473015, 0.3696572086215019, 0.35344279382377863, 0.3876857726275921, 0.41459656819701196, 0.42809998489916323, 0.34474669583141804], 'Lookup Table Model': [1.709847707748413, 1.4336150300502777, 1.1501507759094238, 0.8434668397903442, 0.9108668851852417, 0.9290204620361329, 0.7777738285064697, 0.8783207058906555, 0.8939595031738281, 0.7260821342468262], 'Spline ANN (Partition 1)': [1.078141376376152, 0.7509997749328613, 0.5949880909919739, 0.5170997768640518, 0.4495882797241211, 0.4977460449934006, 0.4278928005695343, 0.5342857897281647, 0.5084220054745674, 0.42773303523659706], 'Lookup Table Model (Partition 1)': [1.7100303322076797, 1.4352771413326264, 1.1511892521381377, 0.8437968373298645, 0.9123074436187744, 0.9316021013259888, 0.7790839385986328, 0.8814051032066346, 0.8991651153564453, 0.7271499633789062], 'ABEL Spline (Partition 1)': [0.5901728790998458, 0.5197446650266647, 0.4964493876695633, 0.45953127652406695, 0.4462055167555809, 0.42663866057991984, 0.41650150083005427, 0.5239515691995621, 0.48749917298555373, 0.4188829194009304], 'Spline ANN (Partition 2)': [1.0788322508335113, 0.7265432959794998, 0.598121601343155, 0.5234417355060578, 0.44915196537971497, 0.4771904507279396, 0.42571294873952864, 0.5264126971364022, 0.49733135268092155, 0.4305943578481674], 'Lookup Table Model (Partition 2)': [1.7399337968259352, 1.5277177587864572, 1.2520920204627328, 0.9707385115791112, 0.878497465280816, 0.8201666789874434, 0.7816548043489456, 0.6827416923642159, 0.6992702323198319, 0.45110836004838345], 'ABEL Spline (Partition 2)': [0.5937015491724015, 0.5198871904611587, 0.49548446133732793, 0.4543902795854956, 0.4434116514027119, 0.40089832540601494, 0.4106139078736305, 0.5033004241064191, 0.48036986410617827, 0.41987309843301773], 'Spline ANN (Partition 4)': [1.0767209267616271, 0.7273052150011062, 0.5968182921409607, 0.5216343641281128, 0.44836937308311464, 0.46846681237220766, 0.4268093878030777, 0.523921063542366, 0.5006263506412506, 0.4390095287561417], 'Lookup Table Model (Partition 4)': [1.7941622398703476, 1.6530711057237932, 1.4373666004321421, 1.1889326572028223, 1.1212930982914986, 1.0421610912686448, 0.9484885820481577, 1.0157558606646488, 0.9412337699672207, 0.5911570805273368], 'ABEL Spline (Partition 4)': [0.5996553295850754, 0.517220194786787, 0.49255828976631166, 0.45544013200327754, 0.4452077180147171, 0.4045554596185684, 0.4129724895581603, 0.5028930374979973, 0.47755214452743533, 0.41700091943144796], 'Spline ANN (Partition 8)': [1.1231536781787872, 0.7442036658525467, 0.6078834593296051, 0.5261399626731873, 0.4481187528371811, 0.4709578788280487, 0.4272859725356102, 0.5241537547111511, 0.5017331928014755, 0.4385258847475052], 'Lookup Table Model (Partition 8)': [1.8125863781169755, 1.6942884204955773, 1.4938512769015506, 1.2638350469968282, 1.203898639230756, 1.1012865656573558, 1.0822430540333152, 1.0810731457686051, 1.0388999418640743, 0.6899676607239235], 'ABEL Spline (Partition 8)': [0.6083395540714264, 0.5143494257330894, 0.49184854567050934, 0.4528596201911569, 0.44209554348140956, 0.3956858139112592, 0.40730297852307557, 0.4950559672340751, 0.4706728874146938, 0.412103954218328], 'Spline ANN (Partition 10)': [1.087787578701973, 0.7077698647975922, 0.5987800121307373, 0.5166975277662277, 0.4479992800951004, 0.4699568068981171, 0.42730952978134157, 0.524319081902504, 0.501853019297123, 0.4381170117855072], 'Lookup Table Model (Partition 10)': [1.811923958262778, 1.6906347745175299, 1.496276582928258, 1.2620184337708633, 1.2024870898458175, 1.1110826422215905, 1.0754270252838614, 1.0771985609954573, 1.0371604898564692, 0.7007802889726008], 'ABEL Spline (Partition 10)': [0.5766472029685974, 0.5195770899951458, 0.4918902923166752, 0.4524316536076367, 0.4490194608271122, 0.4047055625915527, 0.4068795405700803, 0.5025949124060571, 0.47134549528360364, 0.41988721672445534]}, '1030_ERA': {'Linear Model': [3.851704098433256, 3.8167600041627883, 3.793640573620796, 3.126673499941826, 2.8547912001609803, 2.3957502603530885, 1.9781646847724914, 1.954804481267929, 2.01615882396698, 1.8157274842262268], 'Wide ReLU ANN': [1.0977110040187836, 1.3678170013427735, 1.2827938723564147, 1.2455036556720733, 1.2414821696281433, 1.0891758120059967, 1.296558792591095, 1.1285361897945405, 1.3286521172523498, 1.255157949924469], 'Deep ReLU ANN': [1.117334475517273, 1.4238841605186463, 1.3149187576770782, 1.2442735993862153, 1.321411325931549, 1.127181317806244, 1.2280715811252594, 1.1480957531929017, 1.3395765268802642, 1.2551873517036438], 'Lookup Table Model': [3.8217566275596617, 3.7517603611946106, 3.8117640948295595, 3.142330541610718, 2.8583573579788206, 2.483483874797821, 2.0626919651031494, 2.110766930580139, 2.1517206954956056, 1.9869832611083984], 'Spline ANN (Partition 1)': [3.0066320860385893, 2.4198481571674346, 2.168972816467285, 1.74079735994339, 1.6689309620857238, 1.340908589363098, 1.2733359456062316, 1.2762961030006408, 1.3422007966041565, 1.2997681152820588], 'Lookup Table Model (Partition 1)': [3.8217566275596617, 3.7517603611946106, 3.8117640948295595, 3.142711958885193, 2.8591658735275267, 2.484232065677643, 2.064553804397583, 2.1104909563064576, 2.1516903114318846, 1.9886314678192138], 'ABEL Spline (Partition 1)': [1.4121841526031493, 1.4062870121002198, 1.3002163004875182, 1.2572195100784302, 1.1762459039688111, 1.0999389457702637, 1.2624315237998962, 1.1165013492107392, 1.378118782043457, 1.2697154819965362], 'Spline ANN (Partition 2)': [2.9984861421585083, 2.420960750579834, 2.1779334783554076, 1.7269901466369628, 1.6353171801567077, 1.3190573096275329, 1.2496557807922364, 1.2536023569107055, 1.3583310317993165, 1.2885145437717438], 'Lookup Table Model (Partition 2)': [3.864778274297714, 3.8538604739308355, 3.9725824826955796, 3.3242172068357467, 3.026001821756363, 2.7092990350723265, 2.3384068167209624, 2.2959985435009003, 2.3516777300834657, 2.1623848879337313], 'ABEL Spline (Partition 2)': [1.3651133394241333, 1.4016562438011169, 1.3044234025478363, 1.253352084159851, 1.167751944065094, 1.1088683676719666, 1.2336700534820557, 1.1254957711696625, 1.3570105612277985, 1.2554886376857757], 'Spline ANN (Partition 4)': [3.024875419139862, 2.4656884491443636, 2.2399407744407656, 1.7403578519821168, 1.619064588546753, 1.3252210187911988, 1.2180362224578858, 1.2483940291404725, 1.3833024215698242, 1.2989273035526276], 'Lookup Table Model (Partition 4)': [3.895326355546713, 3.922768429219723, 4.090926377475261, 3.46721246778965, 3.1771083670854567, 2.8684030824899676, 2.568138606548309, 2.4918898820877073, 2.5777077174186704, 2.3560316371917724], 'ABEL Spline (Partition 4)': [1.3671044826507568, 1.4066969907283784, 1.3192499148845673, 1.2573814487457275, 1.165087262392044, 1.0739098954200745, 1.2186584568023682, 1.1365613090991973, 1.2910001516342162, 1.2340196478366852], 'Spline ANN (Partition 8)': [3.0920210802555084, 2.5695001924037935, 2.3408896279335023, 1.7723084092140198, 1.628063371181488, 1.3332432532310485, 1.187614278793335, 1.228562948703766, 1.3847037434577942, 1.2871676254272462], 'Lookup Table Model (Partition 8)': [3.917748043388128, 3.944295224696398, 4.124801411628723, 3.5133014035224917, 3.218943493962288, 2.945949738621712, 2.6553181833028794, 2.581787279844284, 2.6655541586875917, 2.4941220581531525], 'ABEL Spline (Partition 8)': [1.4016583561897278, 1.4109062111377717, 1.3077381455898285, 1.2706499767303467, 1.176720688343048, 1.080436544418335, 1.2079692542552949, 1.133978236913681, 1.2810512697696685, 1.2448545825481414], 'Spline ANN (Partition 10)': [3.1098007625341415, 2.585033633708954, 2.356415158510208, 1.7899081158638, 1.6354201245307922, 1.344482958316803, 1.1782165312767028, 1.2371184873580932, 1.3834873580932616, 1.2897022294998168], 'Lookup Table Model (Partition 10)': [3.915575578510761, 3.951877682507038, 4.116470365822315, 3.5212329691648483, 3.2327924394607543, 2.951970924735069, 2.6781894719600676, 2.601435785293579, 2.692721173763275, 2.4915156710147857], 'ABEL Spline (Partition 10)': [1.3981418108940125, 1.4250242686271668, 1.308300907611847, 1.2744365704059601, 1.1927536869049071, 1.0810698878765106, 1.1830892729759217, 1.1433552348613738, 1.272914743423462, 1.249728925228119]}}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def cross_val(models, data):\n",
    "    X, y = data.drop('target', axis=1).values, data['target'].values\n",
    "\n",
    "    kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    results = {}\n",
    "\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        X_train, X_test = preprocess_data(X_train, X_test)\n",
    "\n",
    "        for model, model_name in models:\n",
    "            #model_name = type(model).__name__\n",
    "            model.fit(X_train, y_train, epochs = 10, verbose=0)\n",
    "            y_pred = model.predict(X_test)\n",
    "            mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "            if model_name not in results:\n",
    "                results[model_name] = []\n",
    "\n",
    "            results[model_name].append(mae)\n",
    "    \n",
    "    return results\n",
    "\n",
    "all_results = {}\n",
    "\n",
    "for dataset, row in zip(datasets, filtered_datasets.iterrows()):\n",
    "    dataset_name = row[1]['dataset']\n",
    "    print(f\"Evaluating dataset: {dataset_name}\")\n",
    "\n",
    "    input_dimension = row[1]['n_features']\n",
    "    models = initialize_all_models(input_dimension, seed_val=42)\n",
    "    compile_models(models)\n",
    "\n",
    "    results = cross_val(models, dataset)\n",
    "    all_results[dataset_name] = results\n",
    "\n",
    "print(all_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "508a32d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                Model  Average MAE  Std Deviation\n",
      "0                        Linear Model     1.790073       0.970345\n",
      "1                       Wide ReLU ANN     0.835676       0.397663\n",
      "2                       Deep ReLU ANN     0.838483       0.413511\n",
      "3                  Lookup Table Model     1.921736       0.896426\n",
      "4            Spline ANN (Partition 1)     1.166229       0.587540\n",
      "5    Lookup Table Model (Partition 1)     1.922888       0.895788\n",
      "6           ABEL Spline (Partition 1)     0.873222       0.394664\n",
      "7            Spline ANN (Partition 2)     1.158109       0.584776\n",
      "8    Lookup Table Model (Partition 2)     1.985156       1.004764\n",
      "9           ABEL Spline (Partition 2)     0.864738       0.392545\n",
      "10           Spline ANN (Partition 4)     1.164674       0.591706\n",
      "11   Lookup Table Model (Partition 4)     2.157457       0.984095\n",
      "12          ABEL Spline (Partition 4)     0.859736       0.387231\n",
      "13           Spline ANN (Partition 8)     1.181812       0.600596\n",
      "14   Lookup Table Model (Partition 8)     2.226188       0.979995\n",
      "15          ABEL Spline (Partition 8)     0.860314       0.391282\n",
      "16          Spline ANN (Partition 10)     1.181509       0.609450\n",
      "17  Lookup Table Model (Partition 10)     2.230939       0.984440\n",
      "18         ABEL Spline (Partition 10)     0.861190       0.391692\n"
     ]
    }
   ],
   "source": [
    "# Create a DataFrame to store the results\n",
    "result_data = []\n",
    "\n",
    "# Iterate through all_results and compute mean and std for each model\n",
    "for model_name in all_results[list(all_results.keys())[0]].keys():\n",
    "    all_maes = [np.mean(all_results[dataset][model_name]) for dataset in all_results]\n",
    "    avg_mae = np.mean(all_maes)\n",
    "    std_mae = np.std(all_maes)\n",
    "    result_data.append([model_name, avg_mae, std_mae])\n",
    "\n",
    "# Convert the results to a pandas DataFrame\n",
    "results_df = pd.DataFrame(result_data, columns=['Model', 'Average MAE', 'Std Deviation'])\n",
    "print(results_df)\n",
    "\n",
    "# Add R-squared error,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309bc998",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results['1029_LEV'][]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef119c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc95a7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a6dd02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "429cfcbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating dataset: 1029_LEV\n",
      "29/29 [==============================] - 0s 779us/step - loss: 1.8526\n",
      "4/4 [==============================] - 0s 813us/step\n",
      "29/29 [==============================] - 0s 763us/step - loss: 1.2592\n",
      "4/4 [==============================] - 0s 980us/step\n",
      "29/29 [==============================] - 0s 903us/step - loss: 1.6903\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 685us/step - loss: 1.7783\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 1s 774us/step - loss: 1.7461\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 670us/step - loss: 1.7783\n",
      "4/4 [==============================] - 0s 999us/step\n",
      "29/29 [==============================] - 1s 887us/step - loss: 1.5555\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 1s 840us/step - loss: 1.7348\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 771us/step - loss: 1.7679\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 1s 926us/step - loss: 1.5720\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 869us/step - loss: 1.7235\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 661us/step - loss: 1.7636\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 1s 965us/step - loss: 1.6094\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 821us/step - loss: 1.7737\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 905us/step - loss: 1.7705\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "29/29 [==============================] - 1s 912us/step - loss: 1.5565\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 850us/step - loss: 1.7189\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 721us/step - loss: 1.7674\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 1s 950us/step - loss: 1.6073\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 713us/step - loss: 1.8349\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 783us/step - loss: 0.5831\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "29/29 [==============================] - 0s 796us/step - loss: 1.2129\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 639us/step - loss: 1.7543\n",
      "4/4 [==============================] - 0s 665us/step\n",
      "29/29 [==============================] - 0s 780us/step - loss: 1.6585\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "29/29 [==============================] - 0s 641us/step - loss: 1.7543\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 918us/step - loss: 1.1894\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 817us/step - loss: 1.6484\n",
      "4/4 [==============================] - 0s 979us/step\n",
      "29/29 [==============================] - 0s 672us/step - loss: 1.7457\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 855us/step - loss: 1.2220\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 803us/step - loss: 1.6385\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 695us/step - loss: 1.7494\n",
      "4/4 [==============================] - 0s 996us/step\n",
      "29/29 [==============================] - 0s 891us/step - loss: 1.2809\n",
      "4/4 [==============================] - 0s 996us/step\n",
      "29/29 [==============================] - 0s 764us/step - loss: 1.6898\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 713us/step - loss: 1.7566\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 853us/step - loss: 1.2174\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 798us/step - loss: 1.6370\n",
      "4/4 [==============================] - 0s 651us/step\n",
      "29/29 [==============================] - 0s 674us/step - loss: 1.7536\n",
      "4/4 [==============================] - 0s 659us/step\n",
      "29/29 [==============================] - 0s 961us/step - loss: 1.2727\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "29/29 [==============================] - 0s 706us/step - loss: 1.8053\n",
      "4/4 [==============================] - 0s 668us/step\n",
      "29/29 [==============================] - 0s 783us/step - loss: 0.4963\n",
      "4/4 [==============================] - 0s 992us/step\n",
      "29/29 [==============================] - 0s 783us/step - loss: 0.6821\n",
      "4/4 [==============================] - 0s 993us/step\n",
      "29/29 [==============================] - 0s 641us/step - loss: 1.7394\n",
      "4/4 [==============================] - 0s 978us/step\n",
      "29/29 [==============================] - 0s 781us/step - loss: 1.5778\n",
      "4/4 [==============================] - 0s 995us/step\n",
      "29/29 [==============================] - 0s 690us/step - loss: 1.7397\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 854us/step - loss: 0.9282\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "29/29 [==============================] - 0s 790us/step - loss: 1.5678\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 682us/step - loss: 1.7331\n",
      "4/4 [==============================] - 0s 690us/step\n",
      "29/29 [==============================] - 0s 854us/step - loss: 0.9439\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "29/29 [==============================] - 0s 769us/step - loss: 1.5605\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "29/29 [==============================] - 0s 627us/step - loss: 1.7419\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 950us/step - loss: 0.9825\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "29/29 [==============================] - 0s 750us/step - loss: 1.6141\n",
      "4/4 [==============================] - 0s 871us/step\n",
      "29/29 [==============================] - 0s 696us/step - loss: 1.7516\n",
      "4/4 [==============================] - 0s 985us/step\n",
      "29/29 [==============================] - 0s 854us/step - loss: 0.9395\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 0s 800us/step - loss: 1.5566\n",
      "4/4 [==============================] - 0s 720us/step\n",
      "29/29 [==============================] - 0s 666us/step - loss: 1.7483\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 890us/step - loss: 0.9673\n",
      "4/4 [==============================] - 0s 979us/step\n",
      "29/29 [==============================] - 0s 757us/step - loss: 1.8003\n",
      "4/4 [==============================] - 0s 996us/step\n",
      "29/29 [==============================] - 0s 722us/step - loss: 0.4856\n",
      "4/4 [==============================] - 0s 993us/step\n",
      "29/29 [==============================] - 0s 912us/step - loss: 0.5732\n",
      "4/4 [==============================] - 0s 995us/step\n",
      "29/29 [==============================] - 0s 620us/step - loss: 1.7402\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 820us/step - loss: 1.5117\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "29/29 [==============================] - 0s 605us/step - loss: 1.7405\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "29/29 [==============================] - 0s 929us/step - loss: 0.8438\n",
      "4/4 [==============================] - 0s 987us/step\n",
      "29/29 [==============================] - 0s 792us/step - loss: 1.5021\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 613us/step - loss: 1.7493\n",
      "4/4 [==============================] - 0s 668us/step\n",
      "29/29 [==============================] - 0s 892us/step - loss: 0.8499\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 793us/step - loss: 1.4973\n",
      "4/4 [==============================] - 0s 999us/step\n",
      "29/29 [==============================] - 0s 605us/step - loss: 1.7604\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 926us/step - loss: 0.8603\n",
      "4/4 [==============================] - 0s 993us/step\n",
      "29/29 [==============================] - 0s 781us/step - loss: 1.5527\n",
      "4/4 [==============================] - 0s 999us/step\n",
      "29/29 [==============================] - 0s 697us/step - loss: 1.7737\n",
      "4/4 [==============================] - 0s 998us/step\n",
      "29/29 [==============================] - 0s 854us/step - loss: 0.8318\n",
      "4/4 [==============================] - 0s 998us/step\n",
      "29/29 [==============================] - 0s 813us/step - loss: 1.4933\n",
      "4/4 [==============================] - 0s 985us/step\n",
      "29/29 [==============================] - 0s 690us/step - loss: 1.7697\n",
      "4/4 [==============================] - 0s 993us/step\n",
      "29/29 [==============================] - 0s 925us/step - loss: 0.8473\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 655us/step - loss: 1.7589\n",
      "4/4 [==============================] - 0s 705us/step\n",
      "29/29 [==============================] - 0s 712us/step - loss: 0.4812\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 769us/step - loss: 0.5192\n",
      "4/4 [==============================] - 0s 998us/step\n",
      "29/29 [==============================] - 0s 589us/step - loss: 1.7065\n",
      "4/4 [==============================] - 0s 998us/step\n",
      "29/29 [==============================] - 0s 753us/step - loss: 1.4101\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 606us/step - loss: 1.7067\n",
      "4/4 [==============================] - 0s 665us/step\n",
      "29/29 [==============================] - 0s 819us/step - loss: 0.7471\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "29/29 [==============================] - 0s 679us/step - loss: 1.4032\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 623us/step - loss: 1.7094\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 839us/step - loss: 0.7402\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 748us/step - loss: 1.4026\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 619us/step - loss: 1.7294\n",
      "4/4 [==============================] - 0s 664us/step\n",
      "29/29 [==============================] - 0s 990us/step - loss: 0.7446\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 777us/step - loss: 1.4551\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 685us/step - loss: 1.7426\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 908us/step - loss: 0.7145\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 784us/step - loss: 1.4019\n",
      "4/4 [==============================] - 0s 647us/step\n",
      "29/29 [==============================] - 0s 589us/step - loss: 1.7397\n",
      "4/4 [==============================] - 0s 771us/step\n",
      "29/29 [==============================] - 0s 903us/step - loss: 0.7354\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 687us/step - loss: 1.7301\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 712us/step - loss: 0.4791\n",
      "4/4 [==============================] - 0s 670us/step\n",
      "29/29 [==============================] - 0s 854us/step - loss: 0.4971\n",
      "4/4 [==============================] - 0s 663us/step\n",
      "29/29 [==============================] - 0s 547us/step - loss: 1.6812\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "29/29 [==============================] - 0s 792us/step - loss: 1.3160\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 572us/step - loss: 1.6813\n",
      "4/4 [==============================] - 0s 670us/step\n",
      "29/29 [==============================] - 0s 890us/step - loss: 0.6402\n",
      "4/4 [==============================] - 0s 995us/step\n",
      "29/29 [==============================] - 0s 719us/step - loss: 1.3113\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 615us/step - loss: 1.6874\n",
      "4/4 [==============================] - 0s 639us/step\n",
      "29/29 [==============================] - 0s 918us/step - loss: 0.6227\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 747us/step - loss: 1.3132\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "29/29 [==============================] - 0s 578us/step - loss: 1.7144\n",
      "4/4 [==============================] - 0s 671us/step\n",
      "29/29 [==============================] - 0s 945us/step - loss: 0.6318\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 786us/step - loss: 1.3721\n",
      "4/4 [==============================] - 0s 996us/step\n",
      "29/29 [==============================] - 0s 689us/step - loss: 1.7291\n",
      "4/4 [==============================] - 0s 760us/step\n",
      "29/29 [==============================] - 0s 915us/step - loss: 0.6185\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 781us/step - loss: 1.3130\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 570us/step - loss: 1.7256\n",
      "4/4 [==============================] - 0s 989us/step\n",
      "29/29 [==============================] - 0s 924us/step - loss: 0.6302\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 660us/step - loss: 1.7200\n",
      "4/4 [==============================] - 0s 995us/step\n",
      "29/29 [==============================] - 0s 754us/step - loss: 0.4769\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 777us/step - loss: 0.4887\n",
      "4/4 [==============================] - 0s 665us/step\n",
      "29/29 [==============================] - 0s 677us/step - loss: 1.6715\n",
      "4/4 [==============================] - 0s 666us/step\n",
      "29/29 [==============================] - 0s 743us/step - loss: 1.2428\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "29/29 [==============================] - 0s 600us/step - loss: 1.6716\n",
      "4/4 [==============================] - 0s 988us/step\n",
      "29/29 [==============================] - 0s 923us/step - loss: 0.6024\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "29/29 [==============================] - 0s 765us/step - loss: 1.2395\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "29/29 [==============================] - 0s 704us/step - loss: 1.7031\n",
      "4/4 [==============================] - 0s 998us/step\n",
      "29/29 [==============================] - 0s 890us/step - loss: 0.5830\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 712us/step - loss: 1.2432\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 676us/step - loss: 1.7366\n",
      "4/4 [==============================] - 0s 683us/step\n",
      "29/29 [==============================] - 0s 955us/step - loss: 0.5940\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 771us/step - loss: 1.2984\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 660us/step - loss: 1.7503\n",
      "4/4 [==============================] - 0s 991us/step\n",
      "29/29 [==============================] - 0s 962us/step - loss: 0.5921\n",
      "4/4 [==============================] - 0s 986us/step\n",
      "29/29 [==============================] - 0s 751us/step - loss: 1.2422\n",
      "4/4 [==============================] - 0s 995us/step\n",
      "29/29 [==============================] - 0s 656us/step - loss: 1.7515\n",
      "4/4 [==============================] - 0s 664us/step\n",
      "29/29 [==============================] - 0s 947us/step - loss: 0.5860\n",
      "4/4 [==============================] - 0s 998us/step\n",
      "29/29 [==============================] - 0s 647us/step - loss: 1.6704\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 697us/step - loss: 0.4632\n",
      "4/4 [==============================] - 0s 781us/step\n",
      "29/29 [==============================] - 0s 783us/step - loss: 0.4791\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 641us/step - loss: 1.6339\n",
      "4/4 [==============================] - 0s 999us/step\n",
      "29/29 [==============================] - 0s 723us/step - loss: 1.1311\n",
      "4/4 [==============================] - 0s 998us/step\n",
      "29/29 [==============================] - 0s 604us/step - loss: 1.6342\n",
      "4/4 [==============================] - 0s 917us/step\n",
      "29/29 [==============================] - 0s 904us/step - loss: 0.5686\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 711us/step - loss: 1.1288\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 539us/step - loss: 1.6556\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 920us/step - loss: 0.5457\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 771us/step - loss: 1.1355\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "29/29 [==============================] - 0s 684us/step - loss: 1.7008\n",
      "4/4 [==============================] - 0s 664us/step\n",
      "29/29 [==============================] - 0s 896us/step - loss: 0.5578\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 783us/step - loss: 1.1953\n",
      "4/4 [==============================] - 0s 969us/step\n",
      "29/29 [==============================] - 0s 717us/step - loss: 1.7161\n",
      "4/4 [==============================] - 0s 699us/step\n",
      "29/29 [==============================] - 0s 847us/step - loss: 0.5526\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 727us/step - loss: 1.1366\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 645us/step - loss: 1.7173\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 922us/step - loss: 0.5520\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 662us/step - loss: 1.6312\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 734us/step - loss: 0.4578\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 748us/step - loss: 0.4670\n",
      "4/4 [==============================] - 0s 669us/step\n",
      "29/29 [==============================] - 0s 604us/step - loss: 1.5947\n",
      "4/4 [==============================] - 0s 641us/step\n",
      "29/29 [==============================] - 0s 728us/step - loss: 1.0296\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 644us/step - loss: 1.5949\n",
      "4/4 [==============================] - 0s 998us/step\n",
      "29/29 [==============================] - 0s 924us/step - loss: 0.5431\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 820us/step - loss: 1.0315\n",
      "4/4 [==============================] - 0s 998us/step\n",
      "29/29 [==============================] - 0s 676us/step - loss: 1.6175\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 891us/step - loss: 0.5266\n",
      "4/4 [==============================] - 0s 979us/step\n",
      "29/29 [==============================] - 0s 713us/step - loss: 1.0398\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 606us/step - loss: 1.6643\n",
      "4/4 [==============================] - 0s 665us/step\n",
      "29/29 [==============================] - 0s 935us/step - loss: 0.5382\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 730us/step - loss: 1.1031\n",
      "4/4 [==============================] - 0s 985us/step\n",
      "29/29 [==============================] - 0s 686us/step - loss: 1.6823\n",
      "4/4 [==============================] - 0s 977us/step\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.5321\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 748us/step - loss: 1.0467\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 638us/step - loss: 1.6803\n",
      "4/4 [==============================] - 0s 664us/step\n",
      "29/29 [==============================] - 0s 984us/step - loss: 0.5337\n",
      "4/4 [==============================] - 0s 1000us/step\n",
      "29/29 [==============================] - 0s 594us/step - loss: 1.6401\n",
      "4/4 [==============================] - 0s 663us/step\n",
      "29/29 [==============================] - 0s 754us/step - loss: 0.4683\n",
      "4/4 [==============================] - 0s 969us/step\n",
      "29/29 [==============================] - 0s 854us/step - loss: 0.4694\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "29/29 [==============================] - 0s 622us/step - loss: 1.6071\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 702us/step - loss: 0.9926\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 678us/step - loss: 1.6068\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 926us/step - loss: 0.5360\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 749us/step - loss: 0.9935\n",
      "4/4 [==============================] - 0s 998us/step\n",
      "29/29 [==============================] - 0s 705us/step - loss: 1.6335\n",
      "4/4 [==============================] - 0s 996us/step\n",
      "29/29 [==============================] - 0s 926us/step - loss: 0.5245\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 712us/step - loss: 0.9979\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 644us/step - loss: 1.6848\n",
      "4/4 [==============================] - 0s 1000us/step\n",
      "29/29 [==============================] - 0s 913us/step - loss: 0.5312\n",
      "4/4 [==============================] - 0s 975us/step\n",
      "29/29 [==============================] - 0s 745us/step - loss: 1.0525\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 661us/step - loss: 1.7049\n",
      "4/4 [==============================] - 0s 691us/step\n",
      "29/29 [==============================] - 0s 854us/step - loss: 0.5264\n",
      "4/4 [==============================] - 0s 999us/step\n",
      "29/29 [==============================] - 0s 816us/step - loss: 0.9990\n",
      "4/4 [==============================] - 0s 992us/step\n",
      "29/29 [==============================] - 0s 712us/step - loss: 1.7018\n",
      "4/4 [==============================] - 0s 986us/step\n",
      "29/29 [==============================] - 0s 961us/step - loss: 0.5249\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "Evaluating dataset: 1030_ERA\n",
      "29/29 [==============================] - 0s 795us/step - loss: 4.1194\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "29/29 [==============================] - 0s 817us/step - loss: 3.4646\n",
      "4/4 [==============================] - 0s 681us/step\n",
      "29/29 [==============================] - 0s 860us/step - loss: 4.0446\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 753us/step - loss: 4.1437\n",
      "4/4 [==============================] - 0s 999us/step\n",
      "29/29 [==============================] - 0s 816us/step - loss: 4.1103\n",
      "4/4 [==============================] - 0s 985us/step\n",
      "29/29 [==============================] - 0s 906us/step - loss: 4.1437\n",
      "4/4 [==============================] - 0s 1000us/step\n",
      "29/29 [==============================] - 1s 926us/step - loss: 3.8639\n",
      "4/4 [==============================] - 0s 998us/step\n",
      "29/29 [==============================] - 0s 905us/step - loss: 4.0837\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 710us/step - loss: 4.1349\n",
      "4/4 [==============================] - 0s 998us/step\n",
      "29/29 [==============================] - 1s 904us/step - loss: 3.9064\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 819us/step - loss: 4.0778\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 715us/step - loss: 4.1218\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 1s 985us/step - loss: 3.9324\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 854us/step - loss: 4.0830\n",
      "4/4 [==============================] - 0s 998us/step\n",
      "29/29 [==============================] - 0s 750us/step - loss: 4.1282\n",
      "4/4 [==============================] - 0s 992us/step\n",
      "29/29 [==============================] - 1s 951us/step - loss: 3.9230\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 885us/step - loss: 4.0927\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 759us/step - loss: 4.1251\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 1s 941us/step - loss: 3.9508\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "29/29 [==============================] - 0s 719us/step - loss: 4.0652\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 785us/step - loss: 1.9381\n",
      "4/4 [==============================] - 0s 998us/step\n",
      "29/29 [==============================] - 0s 869us/step - loss: 3.3707\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 681us/step - loss: 4.0903\n",
      "4/4 [==============================] - 0s 994us/step\n",
      "29/29 [==============================] - 0s 885us/step - loss: 3.9718\n",
      "4/4 [==============================] - 0s 998us/step\n",
      "29/29 [==============================] - 0s 659us/step - loss: 4.0903\n",
      "4/4 [==============================] - 0s 998us/step\n",
      "29/29 [==============================] - 0s 926us/step - loss: 3.3795\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 819us/step - loss: 3.9474\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 668us/step - loss: 4.0863\n",
      "4/4 [==============================] - 0s 787us/step\n",
      "29/29 [==============================] - 0s 903us/step - loss: 3.4317\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 755us/step - loss: 3.9458\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 694us/step - loss: 4.0776\n",
      "4/4 [==============================] - 0s 656us/step\n",
      "29/29 [==============================] - 0s 891us/step - loss: 3.4739\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 759us/step - loss: 3.9575\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 729us/step - loss: 4.0879\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 885us/step - loss: 3.4891\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 773us/step - loss: 3.9648\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 712us/step - loss: 4.0852\n",
      "4/4 [==============================] - 0s 664us/step\n",
      "29/29 [==============================] - 0s 889us/step - loss: 3.5172\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "29/29 [==============================] - 0s 722us/step - loss: 3.9983\n",
      "4/4 [==============================] - 0s 665us/step\n",
      "29/29 [==============================] - 0s 839us/step - loss: 1.2927\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "29/29 [==============================] - 0s 843us/step - loss: 1.9071\n",
      "4/4 [==============================] - 0s 985us/step\n",
      "29/29 [==============================] - 0s 696us/step - loss: 4.0224\n",
      "4/4 [==============================] - 0s 995us/step\n",
      "29/29 [==============================] - 0s 819us/step - loss: 3.8188\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 688us/step - loss: 4.0224\n",
      "4/4 [==============================] - 0s 665us/step\n",
      "29/29 [==============================] - 0s 926us/step - loss: 2.9143\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 854us/step - loss: 3.7973\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 671us/step - loss: 4.0234\n",
      "4/4 [==============================] - 0s 674us/step\n",
      "29/29 [==============================] - 0s 875us/step - loss: 2.9721\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 783us/step - loss: 3.8000\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 650us/step - loss: 4.0183\n",
      "4/4 [==============================] - 0s 664us/step\n",
      "29/29 [==============================] - 0s 862us/step - loss: 3.0193\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "29/29 [==============================] - 0s 774us/step - loss: 3.8166\n",
      "4/4 [==============================] - 0s 675us/step\n",
      "29/29 [==============================] - 0s 657us/step - loss: 4.0282\n",
      "4/4 [==============================] - 0s 994us/step\n",
      "29/29 [==============================] - 0s 890us/step - loss: 3.0547\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 793us/step - loss: 3.8310\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "29/29 [==============================] - 0s 710us/step - loss: 4.0266\n",
      "4/4 [==============================] - 0s 663us/step\n",
      "29/29 [==============================] - 0s 854us/step - loss: 3.0866\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "29/29 [==============================] - 0s 586us/step - loss: 4.0155\n",
      "4/4 [==============================] - 0s 670us/step\n",
      "29/29 [==============================] - 0s 752us/step - loss: 1.2409\n",
      "4/4 [==============================] - 0s 998us/step\n",
      "29/29 [==============================] - 0s 798us/step - loss: 1.6185\n",
      "4/4 [==============================] - 0s 996us/step\n",
      "29/29 [==============================] - 0s 618us/step - loss: 4.0401\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 845us/step - loss: 3.7517\n",
      "4/4 [==============================] - 0s 673us/step\n",
      "29/29 [==============================] - 0s 676us/step - loss: 4.0401\n",
      "4/4 [==============================] - 0s 668us/step\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.6048\n",
      "4/4 [==============================] - 0s 996us/step\n",
      "29/29 [==============================] - 0s 813us/step - loss: 3.7324\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 681us/step - loss: 4.0459\n",
      "4/4 [==============================] - 0s 719us/step\n",
      "29/29 [==============================] - 0s 956us/step - loss: 2.6659\n",
      "4/4 [==============================] - 0s 986us/step\n",
      "29/29 [==============================] - 0s 783us/step - loss: 3.7402\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 677us/step - loss: 4.0454\n",
      "4/4 [==============================] - 0s 991us/step\n",
      "29/29 [==============================] - 0s 917us/step - loss: 2.7223\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 811us/step - loss: 3.7629\n",
      "4/4 [==============================] - 0s 651us/step\n",
      "29/29 [==============================] - 0s 695us/step - loss: 4.0571\n",
      "4/4 [==============================] - 0s 664us/step\n",
      "29/29 [==============================] - 0s 897us/step - loss: 2.7686\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "29/29 [==============================] - 0s 836us/step - loss: 3.7772\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 748us/step - loss: 4.0542\n",
      "4/4 [==============================] - 0s 665us/step\n",
      "29/29 [==============================] - 0s 984us/step - loss: 2.8098\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 633us/step - loss: 4.0005\n",
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 748us/step - loss: 1.2389\n",
      "4/4 [==============================] - 0s 978us/step\n",
      "29/29 [==============================] - 0s 818us/step - loss: 1.4605\n",
      "4/4 [==============================] - 0s 899us/step\n",
      "29/29 [==============================] - 0s 706us/step - loss: 4.0255\n",
      "4/4 [==============================] - 0s 759us/step\n",
      "29/29 [==============================] - 0s 799us/step - loss: 3.6524\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "29/29 [==============================] - 0s 644us/step - loss: 4.0255\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 964us/step - loss: 2.2498\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 712us/step - loss: 3.6355\n",
      "4/4 [==============================] - 0s 986us/step\n",
      "29/29 [==============================] - 0s 605us/step - loss: 4.0370\n",
      "4/4 [==============================] - 0s 1000us/step\n",
      "29/29 [==============================] - 0s 970us/step - loss: 2.3089\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 741us/step - loss: 3.6480\n",
      "4/4 [==============================] - 0s 998us/step\n",
      "29/29 [==============================] - 0s 644us/step - loss: 4.0399\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 904us/step - loss: 2.3704\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 726us/step - loss: 3.6783\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 724us/step - loss: 4.0555\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 939us/step - loss: 2.4406\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 752us/step - loss: 3.6903\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 701us/step - loss: 4.0615\n",
      "4/4 [==============================] - 0s 677us/step\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.4872\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 756us/step - loss: 3.9854\n",
      "4/4 [==============================] - 0s 662us/step\n",
      "29/29 [==============================] - 0s 732us/step - loss: 1.2473\n",
      "4/4 [==============================] - 0s 705us/step\n",
      "29/29 [==============================] - 0s 783us/step - loss: 1.3938\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 566us/step - loss: 4.0087\n",
      "4/4 [==============================] - 0s 840us/step\n",
      "29/29 [==============================] - 0s 781us/step - loss: 3.5508\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 679us/step - loss: 4.0087\n",
      "4/4 [==============================] - 0s 670us/step\n",
      "29/29 [==============================] - 0s 924us/step - loss: 2.0347\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "29/29 [==============================] - 0s 761us/step - loss: 3.5370\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 646us/step - loss: 4.0251\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 952us/step - loss: 2.0829\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 749us/step - loss: 3.5542\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 621us/step - loss: 4.0332\n",
      "4/4 [==============================] - 0s 659us/step\n",
      "29/29 [==============================] - 0s 975us/step - loss: 2.1360\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 762us/step - loss: 3.5877\n",
      "4/4 [==============================] - 0s 998us/step\n",
      "29/29 [==============================] - 0s 646us/step - loss: 4.0472\n",
      "4/4 [==============================] - 0s 671us/step\n",
      "29/29 [==============================] - 0s 925us/step - loss: 2.1868\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 766us/step - loss: 3.6086\n",
      "4/4 [==============================] - 0s 923us/step\n",
      "29/29 [==============================] - 0s 632us/step - loss: 4.0462\n",
      "4/4 [==============================] - 0s 674us/step\n",
      "29/29 [==============================] - 0s 895us/step - loss: 2.2283\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 742us/step - loss: 3.9725\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 746us/step - loss: 1.2252\n",
      "4/4 [==============================] - 0s 668us/step\n",
      "29/29 [==============================] - 0s 981us/step - loss: 1.3131\n",
      "4/4 [==============================] - 0s 1000us/step\n",
      "29/29 [==============================] - 0s 605us/step - loss: 3.9964\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "29/29 [==============================] - 0s 715us/step - loss: 3.4534\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 676us/step - loss: 3.9964\n",
      "4/4 [==============================] - 0s 666us/step\n",
      "29/29 [==============================] - 0s 935us/step - loss: 1.8292\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 714us/step - loss: 3.4432\n",
      "4/4 [==============================] - 0s 995us/step\n",
      "29/29 [==============================] - 0s 614us/step - loss: 4.0186\n",
      "4/4 [==============================] - 0s 996us/step\n",
      "29/29 [==============================] - 0s 913us/step - loss: 1.8885\n",
      "4/4 [==============================] - 0s 990us/step\n",
      "29/29 [==============================] - 0s 745us/step - loss: 3.4638\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 577us/step - loss: 4.0299\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "29/29 [==============================] - 0s 914us/step - loss: 1.9506\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 712us/step - loss: 3.5051\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "29/29 [==============================] - 0s 684us/step - loss: 4.0470\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 925us/step - loss: 1.9992\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 792us/step - loss: 3.5244\n",
      "4/4 [==============================] - 0s 996us/step\n",
      "29/29 [==============================] - 0s 758us/step - loss: 4.0505\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 2.0479\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 647us/step - loss: 3.9441\n",
      "4/4 [==============================] - 0s 977us/step\n",
      "29/29 [==============================] - 0s 750us/step - loss: 1.2511\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 857us/step - loss: 1.2763\n",
      "4/4 [==============================] - 0s 992us/step\n",
      "29/29 [==============================] - 0s 632us/step - loss: 3.9663\n",
      "4/4 [==============================] - 0s 999us/step\n",
      "29/29 [==============================] - 0s 727us/step - loss: 3.3384\n",
      "4/4 [==============================] - 0s 984us/step\n",
      "29/29 [==============================] - 0s 639us/step - loss: 3.9663\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 950us/step - loss: 1.6570\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 725us/step - loss: 3.3304\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "29/29 [==============================] - 0s 605us/step - loss: 3.9933\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 928us/step - loss: 1.6850\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 821us/step - loss: 3.3565\n",
      "4/4 [==============================] - 0s 660us/step\n",
      "29/29 [==============================] - 0s 614us/step - loss: 4.0089\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "29/29 [==============================] - 0s 955us/step - loss: 1.7250\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 748us/step - loss: 3.4020\n",
      "4/4 [==============================] - 0s 665us/step\n",
      "29/29 [==============================] - 0s 670us/step - loss: 4.0263\n",
      "4/4 [==============================] - 0s 664us/step\n",
      "29/29 [==============================] - 0s 917us/step - loss: 1.7725\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "29/29 [==============================] - 0s 793us/step - loss: 3.4264\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "29/29 [==============================] - 0s 675us/step - loss: 4.0257\n",
      "4/4 [==============================] - 0s 664us/step\n",
      "29/29 [==============================] - 0s 991us/step - loss: 1.8243\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 629us/step - loss: 3.8906\n",
      "4/4 [==============================] - 0s 651us/step\n",
      "29/29 [==============================] - 0s 732us/step - loss: 1.2131\n",
      "4/4 [==============================] - 0s 1000us/step\n",
      "29/29 [==============================] - 0s 821us/step - loss: 1.2234\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "29/29 [==============================] - 0s 583us/step - loss: 3.9106\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "29/29 [==============================] - 0s 763us/step - loss: 3.1984\n",
      "4/4 [==============================] - 0s 1000us/step\n",
      "29/29 [==============================] - 0s 686us/step - loss: 3.9106\n",
      "4/4 [==============================] - 0s 1000us/step\n",
      "29/29 [==============================] - 0s 997us/step - loss: 1.5748\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 748us/step - loss: 3.1931\n",
      "4/4 [==============================] - 0s 903us/step\n",
      "29/29 [==============================] - 0s 642us/step - loss: 3.9437\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 926us/step - loss: 1.5870\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 713us/step - loss: 3.2236\n",
      "4/4 [==============================] - 0s 999us/step\n",
      "29/29 [==============================] - 0s 613us/step - loss: 3.9638\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 917us/step - loss: 1.5978\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 748us/step - loss: 3.2727\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 687us/step - loss: 3.9808\n",
      "4/4 [==============================] - 0s 660us/step\n",
      "29/29 [==============================] - 0s 954us/step - loss: 1.6288\n",
      "4/4 [==============================] - 0s 1000us/step\n",
      "29/29 [==============================] - 0s 765us/step - loss: 3.3041\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 674us/step - loss: 3.9866\n",
      "4/4 [==============================] - 0s 788us/step\n",
      "29/29 [==============================] - 0s 921us/step - loss: 1.6595\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 660us/step - loss: 3.8628\n",
      "4/4 [==============================] - 0s 666us/step\n",
      "29/29 [==============================] - 0s 780us/step - loss: 1.2226\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 819us/step - loss: 1.2336\n",
      "4/4 [==============================] - 0s 998us/step\n",
      "29/29 [==============================] - 0s 611us/step - loss: 3.8827\n",
      "4/4 [==============================] - 0s 996us/step\n",
      "29/29 [==============================] - 0s 770us/step - loss: 3.1020\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 605us/step - loss: 3.8827\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "29/29 [==============================] - 0s 996us/step - loss: 1.5052\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 770us/step - loss: 3.0974\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 617us/step - loss: 3.9207\n",
      "4/4 [==============================] - 0s 979us/step\n",
      "29/29 [==============================] - 0s 944us/step - loss: 1.5112\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 783us/step - loss: 3.1263\n",
      "4/4 [==============================] - 0s 997us/step\n",
      "29/29 [==============================] - 0s 602us/step - loss: 3.9455\n",
      "4/4 [==============================] - 0s 804us/step\n",
      "29/29 [==============================] - 0s 933us/step - loss: 1.5172\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 790us/step - loss: 3.1763\n",
      "4/4 [==============================] - 0s 990us/step\n",
      "29/29 [==============================] - 0s 692us/step - loss: 3.9633\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 919us/step - loss: 1.5444\n",
      "4/4 [==============================] - 0s 998us/step\n",
      "29/29 [==============================] - 0s 799us/step - loss: 3.2039\n",
      "4/4 [==============================] - 0s 932us/step\n",
      "29/29 [==============================] - 0s 745us/step - loss: 3.9678\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 1.5654\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "{'1029_LEV': {'Sequential': [2.0221621349453924, 0.7933430811762809, 1.6941675129532814, 1.874968957975507, 0.5584732055664062, 0.7524310970306396, 1.9036995647475123, 0.5179093956947327, 0.589298689365387, 1.618078442439437, 0.4877166260778904, 0.511274830698967, 1.7129278630018234, 0.44329070568084716, 0.49818726181983947, 1.7118319395929575, 0.4322559240460396, 0.45962959721684454, 1.4660055024921894, 0.4231223513931036, 0.4359669440239668, 1.6609746345877647, 0.4848525023832917, 0.5162886396795511, 1.8431587083637715, 0.49203173197805883, 0.5089119470492005, 1.490471440255642, 0.40738728769123556, 0.44686184383928773], 'LookupTableModel': [1.9142543955240399, 1.9142684667930008, 1.905387876444729, 1.9080076811497566, 1.9122485671692993, 1.9110672793351113, 1.8899396319687367, 1.8899350018054246, 1.8847575262491592, 1.8885278181289322, 1.9034409697019146, 1.8985536113928538, 1.8081036318838597, 1.8083110586553812, 1.8014922329195542, 1.8132911333837547, 1.8223285286518511, 1.820177465659217, 1.5796460449695586, 1.5798372626304626, 1.5914751926530153, 1.6052439411461819, 1.6186946654133498, 1.6158612889138748, 1.6573491036891936, 1.6575453102588653, 1.6562337118736468, 1.6876634003561048, 1.695803644688276, 1.6916226891055703, 1.6577095618844033, 1.6579226329922676, 1.6606392135005443, 1.6909492759882414, 1.6986233998302487, 1.7005980918825663, 1.5154448807239533, 1.5155621522665024, 1.5589094472676515, 1.581716238696099, 1.6053723336088297, 1.6007245715876344, 1.6257051479816438, 1.626056571006775, 1.634676007591188, 1.6859855101405992, 1.7023161783383693, 1.6977101958375715, 1.7470620203018188, 1.747311155796051, 1.7748284313082694, 1.816077072772314, 1.841120716187288, 1.836094823491294, 1.4101443350315095, 1.4093966817855834, 1.4368894978240132, 1.4945999124285299, 1.5147702379376278, 1.520428311645519], 'SplineANN': [1.8532558636553587, 1.8390348202362656, 1.8194330599159003, 1.872157101535704, 1.8259838460758329, 1.7416573474556207, 1.7363400162756444, 1.7248060750961303, 1.7827316528558732, 1.7184978465735912, 1.5987681336700916, 1.5906991508603097, 1.5820401671528816, 1.6397625163197518, 1.5818318609893323, 1.3134201130270957, 1.308910748064518, 1.3089064338803291, 1.362701419889927, 1.3010995373129846, 1.3258855336904525, 1.3251051503419875, 1.3314724934101105, 1.378174014687538, 1.317106541097164, 1.2762221187353133, 1.2738585257530213, 1.269992555975914, 1.333870456814766, 1.2756953856348991, 1.036852818131447, 1.0341435497999192, 1.047569921016693, 1.0952686280012132, 1.0461382228136062, 1.1560481953620911, 1.1511010271310806, 1.1617904424667358, 1.203428481221199, 1.1547151374816895, 1.1609492480754853, 1.159602275490761, 1.1598336404561997, 1.233474457859993, 1.171936148405075, 0.7906290131807328, 0.7842392706871033, 0.7852913630008698, 0.8216626673936844, 0.7852529627084732], 'ANNEXSpline': [1.4999257853627206, 1.5352271458506583, 1.5798557204008103, 1.5171266666054726, 1.5767250341176986, 1.0591136956214904, 1.0948922175168991, 1.1792084974050523, 1.107523993253708, 1.1674172884225846, 0.8921161067485809, 0.904862345457077, 0.9245416581630707, 0.8933871400356292, 0.9174242281913757, 0.7292261898517609, 0.7073546552658081, 0.7162817096710206, 0.694001613855362, 0.7004704815149307, 0.6473675143718719, 0.6250235342979431, 0.6328435653448105, 0.6026121234893799, 0.6297770285606384, 0.6519442820549011, 0.6361334216594696, 0.6402204239368439, 0.6391555416584015, 0.6268364572525025, 0.5411466944217682, 0.505505946278572, 0.5268414086103439, 0.5112711149454117, 0.5115786463022232, 0.5971794700622559, 0.5869796323776245, 0.5935098761320114, 0.5917498898506165, 0.5888343012332916, 0.5928202909231186, 0.5849567168951034, 0.5824866133928299, 0.5856606394052506, 0.5831167197227478, 0.472498961687088, 0.4573080039024353, 0.47076265275478363, 0.4663167381286621, 0.4670894694328308]}, '1030_ERA': {'Sequential': [4.113400596622378, 2.5679875087738036, 3.82473254814744, 4.338627719730138, 1.4934976959228516, 2.6482257974147796, 4.538438334986568, 1.3304524397850037, 1.7417290306091309, 4.11698969334364, 1.250111185312271, 1.5086152648925781, 4.068437795042992, 1.2042402005195618, 1.5342229437828063, 3.72196109816432, 1.1057462334632873, 1.187011342048645, 3.7210522866249085, 1.2538172698020935, 1.4371716380119324, 3.5779251369833944, 1.1263535928726196, 1.1420820140838623, 3.7293762923777103, 1.392427167892456, 1.385933164358139, 3.7819717028737068, 1.2636505937576294, 1.2857616472244262], 'LookupTableModel': [4.082756719700992, 4.082756719700992, 4.0751338293612935, 4.069676394676789, 4.0783873639348895, 4.077768421549699, 4.27375672891736, 4.27375672891736, 4.2720419789315205, 4.264682581292, 4.271104560118983, 4.272650200673379, 4.594756770730019, 4.594756770730019, 4.599079503230751, 4.599275643697474, 4.608223932895344, 4.602306708362885, 4.145756711959839, 4.145756711959839, 4.157785454802215, 4.156498343683779, 4.1623362772166725, 4.166350749321282, 3.986756653189659, 3.986756653189659, 4.000313321501016, 4.008320941068232, 4.016567592583597, 4.020751071423292, 3.8477565944194794, 3.8477565944194794, 3.8685871970653536, 3.8718085834011435, 3.8893220276013016, 3.8898996597900988, 3.6687565356492997, 3.6687565356492997, 3.6903296859562396, 3.706121089309454, 3.7246612433344124, 3.7279889161884783, 3.6497564768791197, 3.6497564768791197, 3.6817870654165743, 3.7001049659401177, 3.7167995193600656, 3.7202245687693356, 3.86075641810894, 3.86075641810894, 3.892359848767519, 3.914555981233716, 3.9422393476963045, 3.933121068738401, 3.8217566275596617, 3.8217566275596617, 3.8646090473234653, 3.8865212456882, 3.91422220826149, 3.910145128145814], 'SplineANN': [4.005319544896484, 3.9786357152089478, 3.970757161155343, 3.9888673784583806, 3.9932457717135548, 4.1083895422518255, 4.089201661497355, 4.082202742099762, 4.106228424161673, 4.110546991676092, 4.350264202058315, 4.324585762321949, 4.331623423099518, 4.350767352283001, 4.362561088502407, 3.8138127809762956, 3.7984915468096734, 3.798786554634571, 3.824417304396629, 3.846082630753517, 3.5659908986091615, 3.556884179115295, 3.5708604672551156, 3.6040501546859742, 3.6191854017972944, 3.342407801747322, 3.33029114484787, 3.351766912937164, 3.3833912986516954, 3.410644761919975, 3.0806727427244187, 3.066518194079399, 3.0965988880395887, 3.1394124168157576, 3.1620518869161605, 2.9762780046463013, 2.966078900098801, 3.0022958582639694, 3.0440013998746873, 3.0719943910837175, 3.107071858048439, 3.1064900666475297, 3.140403176546097, 3.181905345916748, 3.2042036283016206, 3.0073892676830294, 3.0075096678733826, 3.0355189037323, 3.0867191714048388, 3.1131787848472596], 'ANNEXSpline': [3.570001561641693, 3.6207865777611734, 3.6564475902915, 3.6609519335627554, 3.6904928770661356, 3.329771190285683, 3.3885505282878876, 3.4388761287927627, 3.4675231343507766, 3.5067438358068466, 3.2804384076595308, 3.3496130537986755, 3.3911555933952333, 3.442576996088028, 3.4822922945022583, 2.5022494161128996, 2.58102241396904, 2.644864270687103, 2.7035262405872347, 2.7455925726890564, 2.2388322448730467, 2.274083368778229, 2.3299257731437684, 2.382048180103302, 2.4094763660430907, 1.7781009125709533, 1.8396649861335754, 1.8933011198043823, 1.9463502669334412, 1.9730963039398193, 1.3538410592079162, 1.3704875349998473, 1.4131499361991882, 1.4741781210899354, 1.5251283049583435, 1.562618088722229, 1.5752182507514954, 1.6044179487228394, 1.628317174911499, 1.6450569701194764, 1.5374274134635926, 1.5548824620246888, 1.6005820178985595, 1.6296319198608398, 1.664373621940613, 1.4254827070236207, 1.4376120400428771, 1.4309890842437745, 1.4374741744995116, 1.4442659258842467]}}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import pmlb\n",
    "from pmlb import fetch_data\n",
    "from model_definitions import *\n",
    "\n",
    "def compile_models(models, optimizer='adam', loss='mean_absolute_error'):\n",
    "    \"\"\"Compile TensorFlow/Keras models.\"\"\"\n",
    "    for model in models:\n",
    "        model.compile(optimizer=optimizer, loss=loss)\n",
    "\n",
    "\n",
    "def preprocess_data(train_data, test_data):\n",
    "    \"\"\"Preprocess the data by zero-centering, scaling to unit variance, and applying a sigmoid.\"\"\"\n",
    "    bias = np.mean(train_data, axis=0)\n",
    "    variance = np.std(train_data, axis=0)\n",
    "    \n",
    "    train_data = (train_data - bias) / variance\n",
    "    test_data = (test_data - bias) / variance\n",
    "    \n",
    "    train_data = 1 / (1 + np.exp(-train_data))\n",
    "    test_data = 1 / (1 + np.exp(-test_data))\n",
    "    \n",
    "    return train_data, test_data\n",
    "\n",
    "\n",
    "def cross_val(models, dataset_name, n_splits=10):\n",
    "    data = fetch_data(dataset_name)\n",
    "    X, y = data.drop('target', axis=1).values, data['target'].values\n",
    "\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    results = {}\n",
    "\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        X_train, X_test = preprocess_data(X_train, X_test)\n",
    "\n",
    "        for model in models:\n",
    "            model_name = type(model).__name__\n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred = model.predict(X_test)\n",
    "            mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "            if model_name not in results:\n",
    "                results[model_name] = []\n",
    "\n",
    "            results[model_name].append(mae)\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "def initialize_all_models(input_dimension: int, \n",
    "                          seed_val: int, \n",
    "                          output_dim: int = 1,\n",
    "                          hidden_units_wide: int = 1000,\n",
    "                          hidden_units_deep: int = 16,\n",
    "                          hidden_layers: int = 8,\n",
    "                          num_exps: int = 6) -> list:\n",
    "    \"\"\"Initialize models with given configurations.\"\"\"\n",
    "    common_args = {\n",
    "        'input_dim': input_dimension, \n",
    "        'output_dim': output_dim, \n",
    "        'seed': seed_val\n",
    "    }\n",
    "\n",
    "    models = [\n",
    "        create_linear_model(**common_args),\n",
    "        create_wide_relu_ann(hidden_units=hidden_units_wide, **common_args),\n",
    "        create_deep_relu_ann(hidden_units=hidden_units_deep, hidden_layers=hidden_layers, **common_args),\n",
    "        LookupTableModel(partition_num=1, default_val=-1., **common_args)\n",
    "    ]\n",
    "\n",
    "    for partition_num in [1,2,4,8,10]:\n",
    "        models.append(SplineANN(partition_num=partition_num, **common_args))\n",
    "        models.append(LookupTableModel(partition_num=partition_num, default_val=-1., **common_args))\n",
    "        models.append(ANNEXSpline(partition_num=partition_num, num_exps=num_exps, **common_args))\n",
    "\n",
    "    return models\n",
    "\n",
    "\n",
    "# Path to the TSV file\n",
    "metadata_path = os.path.join(os.path.dirname(pmlb.__file__), 'all_summary_stats.tsv')\n",
    "metadata = pd.read_csv(metadata_path, sep='\\t')\n",
    "\n",
    "# Filter datasets based on number of records (rows) and other criteria\n",
    "filtered_datasets = metadata[\n",
    "    (metadata['n_features'] < 5) &\n",
    "    (metadata['n_binary_features'] == 0) &\n",
    "    (metadata['n_categorical_features'] == 0) &\n",
    "    (metadata['n_continuous_features'] == metadata['n_features'] ) &\n",
    "    (metadata['n_instances'] >= 500) &  # Assuming 'n_instances' is the column for the number of records\n",
    "    (metadata['n_instances'] <= 1000) &\n",
    "    (metadata['endpoint_type'] == 'continuous') &\n",
    "    (metadata['task'] == 'regression')\n",
    "]\n",
    "\n",
    "all_results = {}\n",
    "\n",
    "for _, row in filtered_datasets.iterrows():\n",
    "    dataset_name = row['dataset']\n",
    "    print(f\"Evaluating dataset: {dataset_name}\")\n",
    "    \n",
    "    input_dimension = row['n_features']\n",
    "    models = initialize_all_models(input_dimension, seed_val=42)\n",
    "    compile_models(models)\n",
    "    \n",
    "    results = cross_val(models, dataset_name)\n",
    "    all_results[dataset_name] = results\n",
    "\n",
    "print(all_results)\n",
    "\n",
    "# Please wrap the filtering and data fetching in a separate function. I want the **data set** itself to be given as an input to the \n",
    "# cross_val function. Here is an example:\n",
    "\n",
    "# Function to fetch a dataset by name\n",
    "def fetch_dataset(row):\n",
    "    dataset_name = row[1][0]  # Adjust this based on the actual structure\n",
    "    #print(dataset_name)\n",
    "    data = fetch_data(dataset_name)\n",
    "    # Further processing if needed\n",
    "    return data\n",
    "\n",
    "# Fetch the filtered datasets in parallel\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    datasets = list(executor.map(fetch_dataset, filtered_datasets.iterrows()))\n",
    "\n",
    "# 'datasets' now contains the datasets that meet your criteria I want to contain/encapsulate the PMLB dependent code\n",
    "# in one function to make my life easier if I wat to use other data se\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c0c1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to fetch a dataset by name\n",
    "def fetch_dataset(row):\n",
    "    dataset_name = row[1][0]  # Adjust this based on the actual structure\n",
    "    #print(dataset_name)\n",
    "    data = fetch_data(dataset_name)\n",
    "    # Further processing if needed\n",
    "    return data\n",
    "\n",
    "# Fetch the filtered datasets in parallel\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    datasets = list(executor.map(fetch_dataset, filtered_datasets.iterrows()))\n",
    "\n",
    "# 'datasets' now contains the datasets that meet your criteria\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
