{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf2ef877",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary modules\n",
    "import gc\n",
    "import copy\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from model_data_definitions import *\n",
    "from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fc6deb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.save('data_dictionary_100_epochs_10_folds.npy', data)\n",
    "data = np.load('data_dictionary_100_epochs_10_folds.npy', allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc98b2d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Linear Model', 'Wide ReLU ANN', 'Deep ReLU ANN', 'ABEL-Spline (z=1)', 'ABEL-Spline (z=2)', 'ABEL-Spline (z=4)', 'ABEL-Spline (z=8)', 'ABEL-Spline (z=10)', 'Spline ANN (z=1)', 'Spline ANN (z=2)', 'Spline ANN (z=4)', 'Spline ANN (z=8)', 'Spline ANN (z=10)', 'Lookup Table (z=1)', 'Lookup Table (z=2)', 'Lookup Table (z=4)', 'Lookup Table (z=8)', 'Lookup Table (z=10)']\n"
     ]
    }
   ],
   "source": [
    "def modelNames():\n",
    "\n",
    "    models = [\"Linear Model\",\n",
    "              \"Wide ReLU ANN\",\n",
    "              \"Deep ReLU ANN\", \n",
    "              \"One Parameter\"\n",
    "    ]\n",
    "\n",
    "    for partition_num in [1,2,4,8,10]:\n",
    "        models.append(f\"Spline ANN (z={partition_num})\")\n",
    "        models.append(f\"Lookup Table (z={partition_num})\")\n",
    "        models.append(f\"ABEL-Spline (z={partition_num})\")\n",
    "\n",
    "    return models\n",
    "\n",
    "def modelNames():\n",
    "\n",
    "    models = [\"Linear Model\",\n",
    "              \"Wide ReLU ANN\",\n",
    "              \"Deep ReLU ANN\"\n",
    "             ]\n",
    "        \n",
    "    for partition_num in [1,2,4,8,10]: \n",
    "        models.append(f\"ABEL-Spline (z={partition_num})\")\n",
    "        \n",
    "    for partition_num in [1,2,4,8,10]: \n",
    "        models.append(f\"Spline ANN (z={partition_num})\")\n",
    "        \n",
    "    for partition_num in [1,2,4,8,10]: \n",
    "        models.append(f\"Lookup Table (z={partition_num})\")\n",
    "\n",
    "    return models\n",
    "\n",
    "model_names = modelNames()\n",
    "\n",
    "print(model_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ebd53c60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>n_instances</th>\n",
       "      <th>n_features</th>\n",
       "      <th>n_binary_features</th>\n",
       "      <th>n_categorical_features</th>\n",
       "      <th>n_continuous_features</th>\n",
       "      <th>endpoint_type</th>\n",
       "      <th>n_classes</th>\n",
       "      <th>imbalance</th>\n",
       "      <th>task</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1027_ESL</td>\n",
       "      <td>488</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>continuous</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.099363</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1029_LEV</td>\n",
       "      <td>1000</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>continuous</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.111245</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1030_ERA</td>\n",
       "      <td>1000</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>continuous</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.031251</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1096_FacultySalaries</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>continuous</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.004063</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>192_vineyard</td>\n",
       "      <td>52</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>continuous</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.040475</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>228_elusage</td>\n",
       "      <td>55</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>continuous</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.000953</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>230_machine_cpu</td>\n",
       "      <td>209</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>continuous</td>\n",
       "      <td>116.0</td>\n",
       "      <td>0.004906</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>485_analcatdata_vehicle</td>\n",
       "      <td>48</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>continuous</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0.000434</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>519_vinnie</td>\n",
       "      <td>380</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>continuous</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.030146</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>523_analcatdata_neavote</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>continuous</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.136914</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>529_pollen</td>\n",
       "      <td>3848</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>continuous</td>\n",
       "      <td>3784.0</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>556_analcatdata_apnea2</td>\n",
       "      <td>475</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>continuous</td>\n",
       "      <td>178.0</td>\n",
       "      <td>0.272393</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>557_analcatdata_apnea1</td>\n",
       "      <td>475</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>continuous</td>\n",
       "      <td>164.0</td>\n",
       "      <td>0.325260</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>579_fri_c0_250_5</td>\n",
       "      <td>250</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>continuous</td>\n",
       "      <td>250.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>594_fri_c2_100_5</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>continuous</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>596_fri_c2_250_5</td>\n",
       "      <td>250</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>continuous</td>\n",
       "      <td>250.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>597_fri_c2_500_5</td>\n",
       "      <td>500</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>continuous</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>599_fri_c2_1000_5</td>\n",
       "      <td>1000</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>continuous</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>601_fri_c1_250_5</td>\n",
       "      <td>250</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>continuous</td>\n",
       "      <td>250.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>609_fri_c0_1000_5</td>\n",
       "      <td>1000</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>continuous</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>611_fri_c3_100_5</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>continuous</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>612_fri_c1_1000_5</td>\n",
       "      <td>1000</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>continuous</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>613_fri_c3_250_5</td>\n",
       "      <td>250</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>continuous</td>\n",
       "      <td>250.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>617_fri_c3_500_5</td>\n",
       "      <td>500</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>continuous</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>624_fri_c0_100_5</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>continuous</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>628_fri_c3_1000_5</td>\n",
       "      <td>1000</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>continuous</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>631_fri_c1_500_5</td>\n",
       "      <td>500</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>continuous</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>649_fri_c0_500_5</td>\n",
       "      <td>500</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>continuous</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>656_fri_c1_100_5</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>continuous</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>663_rabe_266</td>\n",
       "      <td>120</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>continuous</td>\n",
       "      <td>96.0</td>\n",
       "      <td>0.001825</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>665_sleuth_case2002</td>\n",
       "      <td>147</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>continuous</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.096020</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>678_visualizing_environmental</td>\n",
       "      <td>111</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>continuous</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.019608</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>687_sleuth_ex1605</td>\n",
       "      <td>62</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>continuous</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.006465</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>690_visualizing_galaxy</td>\n",
       "      <td>323</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>continuous</td>\n",
       "      <td>208.0</td>\n",
       "      <td>0.001246</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>706_sleuth_case1202</td>\n",
       "      <td>93</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>continuous</td>\n",
       "      <td>79.0</td>\n",
       "      <td>0.001583</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>712_chscase_geyser1</td>\n",
       "      <td>222</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>continuous</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.012844</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>banana</td>\n",
       "      <td>5300</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>continuous</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.010691</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>titanic</td>\n",
       "      <td>2201</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>continuous</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.125266</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           dataset  n_instances  n_features  \\\n",
       "0                         1027_ESL          488           4   \n",
       "2                         1029_LEV         1000           4   \n",
       "3                         1030_ERA         1000           4   \n",
       "5             1096_FacultySalaries           50           4   \n",
       "13                    192_vineyard           52           2   \n",
       "23                     228_elusage           55           2   \n",
       "25                 230_machine_cpu          209           6   \n",
       "29         485_analcatdata_vehicle           48           4   \n",
       "32                      519_vinnie          380           2   \n",
       "34         523_analcatdata_neavote          100           2   \n",
       "36                      529_pollen         3848           4   \n",
       "40          556_analcatdata_apnea2          475           3   \n",
       "41          557_analcatdata_apnea1          475           3   \n",
       "48                579_fri_c0_250_5          250           5   \n",
       "60                594_fri_c2_100_5          100           5   \n",
       "62                596_fri_c2_250_5          250           5   \n",
       "63                597_fri_c2_500_5          500           5   \n",
       "65               599_fri_c2_1000_5         1000           5   \n",
       "66                601_fri_c1_250_5          250           5   \n",
       "74               609_fri_c0_1000_5         1000           5   \n",
       "75                611_fri_c3_100_5          100           5   \n",
       "76               612_fri_c1_1000_5         1000           5   \n",
       "77                613_fri_c3_250_5          250           5   \n",
       "80                617_fri_c3_500_5          500           5   \n",
       "86                624_fri_c0_100_5          100           5   \n",
       "89               628_fri_c3_1000_5         1000           5   \n",
       "90                631_fri_c1_500_5          500           5   \n",
       "102               649_fri_c0_500_5          500           5   \n",
       "107               656_fri_c1_100_5          100           5   \n",
       "111                   663_rabe_266          120           2   \n",
       "112            665_sleuth_case2002          147           6   \n",
       "114  678_visualizing_environmental          111           3   \n",
       "115              687_sleuth_ex1605           62           5   \n",
       "116         690_visualizing_galaxy          323           4   \n",
       "118            706_sleuth_case1202           93           6   \n",
       "119            712_chscase_geyser1          222           2   \n",
       "155                         banana         5300           2   \n",
       "270                        titanic         2201           3   \n",
       "\n",
       "     n_binary_features  n_categorical_features  n_continuous_features  \\\n",
       "0                    0                       0                      4   \n",
       "2                    0                       0                      4   \n",
       "3                    0                       0                      4   \n",
       "5                    0                       0                      4   \n",
       "13                   0                       0                      2   \n",
       "23                   0                       0                      2   \n",
       "25                   0                       0                      6   \n",
       "29                   0                       0                      4   \n",
       "32                   0                       0                      2   \n",
       "34                   0                       0                      2   \n",
       "36                   0                       0                      4   \n",
       "40                   0                       0                      3   \n",
       "41                   0                       0                      3   \n",
       "48                   0                       0                      5   \n",
       "60                   0                       0                      5   \n",
       "62                   0                       0                      5   \n",
       "63                   0                       0                      5   \n",
       "65                   0                       0                      5   \n",
       "66                   0                       0                      5   \n",
       "74                   0                       0                      5   \n",
       "75                   0                       0                      5   \n",
       "76                   0                       0                      5   \n",
       "77                   0                       0                      5   \n",
       "80                   0                       0                      5   \n",
       "86                   0                       0                      5   \n",
       "89                   0                       0                      5   \n",
       "90                   0                       0                      5   \n",
       "102                  0                       0                      5   \n",
       "107                  0                       0                      5   \n",
       "111                  0                       0                      2   \n",
       "112                  0                       0                      6   \n",
       "114                  0                       0                      3   \n",
       "115                  0                       0                      5   \n",
       "116                  0                       0                      4   \n",
       "118                  0                       0                      6   \n",
       "119                  0                       0                      2   \n",
       "155                  0                       0                      2   \n",
       "270                  0                       0                      3   \n",
       "\n",
       "    endpoint_type  n_classes  imbalance        task  \n",
       "0      continuous        9.0   0.099363  regression  \n",
       "2      continuous        5.0   0.111245  regression  \n",
       "3      continuous        9.0   0.031251  regression  \n",
       "5      continuous       39.0   0.004063  regression  \n",
       "13     continuous       19.0   0.040475  regression  \n",
       "23     continuous       52.0   0.000953  regression  \n",
       "25     continuous      116.0   0.004906  regression  \n",
       "29     continuous       47.0   0.000434  regression  \n",
       "32     continuous       16.0   0.030146  regression  \n",
       "34     continuous        8.0   0.136914  regression  \n",
       "36     continuous     3784.0   0.000004  regression  \n",
       "40     continuous      178.0   0.272393  regression  \n",
       "41     continuous      164.0   0.325260  regression  \n",
       "48     continuous      250.0   0.000000  regression  \n",
       "60     continuous      100.0   0.000000  regression  \n",
       "62     continuous      250.0   0.000000  regression  \n",
       "63     continuous      500.0   0.000000  regression  \n",
       "65     continuous     1000.0   0.000000  regression  \n",
       "66     continuous      250.0   0.000000  regression  \n",
       "74     continuous     1000.0   0.000000  regression  \n",
       "75     continuous      100.0   0.000000  regression  \n",
       "76     continuous     1000.0   0.000000  regression  \n",
       "77     continuous      250.0   0.000000  regression  \n",
       "80     continuous      500.0   0.000000  regression  \n",
       "86     continuous      100.0   0.000000  regression  \n",
       "89     continuous     1000.0   0.000000  regression  \n",
       "90     continuous      500.0   0.000000  regression  \n",
       "102    continuous      500.0   0.000000  regression  \n",
       "107    continuous      100.0   0.000000  regression  \n",
       "111    continuous       96.0   0.001825  regression  \n",
       "112    continuous       19.0   0.096020  regression  \n",
       "114    continuous       28.0   0.019608  regression  \n",
       "115    continuous       41.0   0.006465  regression  \n",
       "116    continuous      208.0   0.001246  regression  \n",
       "118    continuous       79.0   0.001583  regression  \n",
       "119    continuous       50.0   0.012844  regression  \n",
       "155    continuous        2.0   0.010691  regression  \n",
       "270    continuous        2.0   0.125266  regression  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_datasets_metadata, datasets = fetch_return_filtered_pmlb_data_sets()\n",
    "filtered_datasets_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4003b672",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('192_vineyard', 52, 2),\n",
       " ('228_elusage', 55, 2),\n",
       " ('523_analcatdata_neavote', 100, 2),\n",
       " ('663_rabe_266', 120, 2),\n",
       " ('712_chscase_geyser1', 222, 2),\n",
       " ('519_vinnie', 380, 2),\n",
       " ('banana', 5300, 2),\n",
       " ('678_visualizing_environmental', 111, 3),\n",
       " ('556_analcatdata_apnea2', 475, 3),\n",
       " ('557_analcatdata_apnea1', 475, 3),\n",
       " ('titanic', 2201, 3),\n",
       " ('485_analcatdata_vehicle', 48, 4),\n",
       " ('1096_FacultySalaries', 50, 4),\n",
       " ('690_visualizing_galaxy', 323, 4),\n",
       " ('1027_ESL', 488, 4),\n",
       " ('1029_LEV', 1000, 4),\n",
       " ('1030_ERA', 1000, 4),\n",
       " ('529_pollen', 3848, 4),\n",
       " ('687_sleuth_ex1605', 62, 5),\n",
       " ('594_fri_c2_100_5', 100, 5),\n",
       " ('611_fri_c3_100_5', 100, 5),\n",
       " ('624_fri_c0_100_5', 100, 5),\n",
       " ('656_fri_c1_100_5', 100, 5),\n",
       " ('579_fri_c0_250_5', 250, 5),\n",
       " ('596_fri_c2_250_5', 250, 5),\n",
       " ('601_fri_c1_250_5', 250, 5),\n",
       " ('613_fri_c3_250_5', 250, 5),\n",
       " ('597_fri_c2_500_5', 500, 5),\n",
       " ('617_fri_c3_500_5', 500, 5),\n",
       " ('631_fri_c1_500_5', 500, 5),\n",
       " ('649_fri_c0_500_5', 500, 5),\n",
       " ('599_fri_c2_1000_5', 1000, 5),\n",
       " ('609_fri_c0_1000_5', 1000, 5),\n",
       " ('612_fri_c1_1000_5', 1000, 5),\n",
       " ('628_fri_c3_1000_5', 1000, 5),\n",
       " ('706_sleuth_case1202', 93, 6),\n",
       " ('665_sleuth_case2002', 147, 6),\n",
       " ('230_machine_cpu', 209, 6)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instances_dict = filtered_datasets_metadata.set_index('dataset')['n_instances'].to_dict()\n",
    "features_dict = filtered_datasets_metadata.set_index('dataset')['n_features'].to_dict()\n",
    "\n",
    "unique_features_counts = sorted(list(set(features_dict.values())))\n",
    "\n",
    "sorted_dataset_names = []\n",
    "bracket_positions = {}\n",
    "\n",
    "for feature_count in unique_features_counts:\n",
    "    datasets_with_feature_count = [dataset for dataset, features in features_dict.items() if features == feature_count]\n",
    "    sorted_datasets = sorted(datasets_with_feature_count, key=lambda x: instances_dict[x])\n",
    "\n",
    "    if not sorted_datasets:\n",
    "        continue\n",
    "\n",
    "    start_index = len(sorted_dataset_names)\n",
    "    end_index = start_index + len(sorted_datasets) - 1\n",
    "\n",
    "    bracket_positions[feature_count] = (start_index, end_index)\n",
    "\n",
    "    sorted_dataset_names += [(dataset, instances_dict[dataset], features_dict[dataset]) for dataset in sorted_datasets]\n",
    "\n",
    "sorted_dataset_names\n",
    "\n",
    "dataset_names = sorted_dataset_names\n",
    "dataset_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a734e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate mean and standard deviation of a metric for each fold for each model, over all datasets\n",
    "def calculate_mean_std_metric(metric):\n",
    "    # Initialize dictionary to hold means and standard deviations\n",
    "    means_stds = {}\n",
    "\n",
    "    # Iterate over datasets\n",
    "    for dataset_name in data:\n",
    "        # Iterate over models\n",
    "        for model_name in data[dataset_name]:\n",
    "            # Initialize list to hold metric values for this model\n",
    "            metric_values = []\n",
    "\n",
    "            # Iterate over folds\n",
    "            for fold_number in data[dataset_name][model_name]:\n",
    "                # Add metric value to list\n",
    "                if metric == 'train_history':\n",
    "                    metric_values.append(data[dataset_name][model_name][fold_number][metric][-1])\n",
    "                else:\n",
    "                    metric_values.append(data[dataset_name][model_name][fold_number][metric])\n",
    "\n",
    "            # Calculate mean and standard deviation and add to dictionary\n",
    "            mean_metric = np.mean(metric_values)\n",
    "            std_metric = np.std(metric_values)\n",
    "            \n",
    "            if dataset_name not in means_stds:\n",
    "                means_stds[dataset_name] = {}\n",
    "                \n",
    "            if model_name not in means_stds[dataset_name]:\n",
    "                means_stds[dataset_name][model_name] = {}\n",
    "\n",
    "            means_stds[dataset_name][model_name]['mean'] = mean_metric\n",
    "            means_stds[dataset_name][model_name]['std'] = std_metric\n",
    "\n",
    "    return means_stds\n",
    "\n",
    "# Calculate mean and standard deviation of r_squared value for each fold for each model, over all datasets\n",
    "#mean_std_r_squared_values = calculate_mean_std_metric('r_squared_value')\n",
    "#print(mean_std_r_squared_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d770b696",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_std_over_all_metrics = {}\n",
    "\n",
    "for metric in ['r_squared_value','loss', 'test_error', 'train_history']:\n",
    "    mean_std_over_all_metrics[metric] = calculate_mean_std_metric(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "436990a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.030956447139549974"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model_names is a list of model names\n",
    "# dataset_names is a list of tuples containing (dataset_name_string, number_of_instances, number_of_input_features)\n",
    "\n",
    "# mean_std_over_all_metrics[metric][dataset_name][model_name][mean_or_std]\n",
    "mean_std_over_all_metrics['loss']['1027_ESL']['ABEL-Spline (z=1)']['mean']\n",
    "mean_std_over_all_metrics['loss']['1027_ESL']['ABEL-Spline (z=1)']['std']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e39bd5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('192_vineyard', 52, 2),\n",
       " ('228_elusage', 55, 2),\n",
       " ('523_analcatdata_neavote', 100, 2),\n",
       " ('663_rabe_266', 120, 2),\n",
       " ('712_chscase_geyser1', 222, 2),\n",
       " ('519_vinnie', 380, 2),\n",
       " ('banana', 5300, 2),\n",
       " ('678_visualizing_environmental', 111, 3),\n",
       " ('556_analcatdata_apnea2', 475, 3),\n",
       " ('557_analcatdata_apnea1', 475, 3),\n",
       " ('titanic', 2201, 3),\n",
       " ('485_analcatdata_vehicle', 48, 4),\n",
       " ('1096_FacultySalaries', 50, 4),\n",
       " ('690_visualizing_galaxy', 323, 4),\n",
       " ('1027_ESL', 488, 4),\n",
       " ('1029_LEV', 1000, 4),\n",
       " ('1030_ERA', 1000, 4),\n",
       " ('529_pollen', 3848, 4),\n",
       " ('687_sleuth_ex1605', 62, 5),\n",
       " ('594_fri_c2_100_5', 100, 5),\n",
       " ('611_fri_c3_100_5', 100, 5),\n",
       " ('624_fri_c0_100_5', 100, 5),\n",
       " ('656_fri_c1_100_5', 100, 5),\n",
       " ('579_fri_c0_250_5', 250, 5),\n",
       " ('596_fri_c2_250_5', 250, 5),\n",
       " ('601_fri_c1_250_5', 250, 5),\n",
       " ('613_fri_c3_250_5', 250, 5),\n",
       " ('597_fri_c2_500_5', 500, 5),\n",
       " ('617_fri_c3_500_5', 500, 5),\n",
       " ('631_fri_c1_500_5', 500, 5),\n",
       " ('649_fri_c0_500_5', 500, 5),\n",
       " ('599_fri_c2_1000_5', 1000, 5),\n",
       " ('609_fri_c0_1000_5', 1000, 5),\n",
       " ('612_fri_c1_1000_5', 1000, 5),\n",
       " ('628_fri_c3_1000_5', 1000, 5),\n",
       " ('706_sleuth_case1202', 93, 6),\n",
       " ('665_sleuth_case2002', 147, 6),\n",
       " ('230_machine_cpu', 209, 6)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1e06845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latex tables have been written to 'latex_tables.txt'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "list_of_metrics = ['r_squared_value', 'test_error', 'loss', 'train_history']\n",
    "#model_names = ['Model1', 'Model2'] # replace with actual model names\n",
    "#dataset_names = [('Dataset1', 100, 5), ('Dataset2', 200, 10)] # replace with actual dataset names\n",
    "\n",
    "# Create file\n",
    "with open(\"latex_tables.txt\", \"w\") as file:\n",
    "\n",
    "    for dataset in dataset_names:\n",
    "        file.write(\"\\\\begin{table}[h]\\n\")\n",
    "        file.write(\"\\caption{\" + dataset[0] + \": \" + str(dataset[1]) + \" instances, \" + str(dataset[2]) + \" features}\\n\")\n",
    "        file.write(\"\\\\label{tab:\" + dataset[0].replace(\" \", \"_\").lower() + \"}\\n\")\n",
    "        file.write(\"\\\\centering\\n\")\n",
    "        file.write(\"\\\\begin{tabular}{lrrrr}\\n\")\n",
    "        file.write(\"\\\\textbf{Model} & \\\\textbf{R squared} & \\\\textbf{Test MSE} & \\\\textbf{Test MAE} & \\\\textbf{Training MAE} \\\\\\\\ \\n\")\n",
    "\n",
    "        for model in model_names:\n",
    "            row = [model]\n",
    "            for metric in list_of_metrics:\n",
    "                mean = mean_std_over_all_metrics[metric][dataset[0]][model]['mean']\n",
    "                std = mean_std_over_all_metrics[metric][dataset[0]][model]['std']\n",
    "                row.append(\"$\" + str(round(mean, 2)) + \"\\pm\" + str(round(std, 2)) +\"$\")\n",
    "            file.write(\" & \".join(row) +\"\\\\\\\\\"+ \"\\n\")\n",
    "\n",
    "        file.write(\"\\end{{tabular}}\\n\")\n",
    "        file.write(\"\\end{{table}}\\n\\n\")\n",
    "\n",
    "print(\"Latex tables have been written to 'latex_tables.txt'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5fef0028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latex tables have been written to 'latex_tables.txt'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "list_of_metrics = ['r_squared_value', 'test_error', 'loss', 'train_history']\n",
    "#model_names = ['Model1', 'Model2'] # replace with actual model names\n",
    "#dataset_names = [('Dataset1', 100, 5), ('Dataset2', 200, 10)] # replace with actual dataset names\n",
    "\n",
    "# Create file\n",
    "with open(\"latex_tables.txt\", \"w\") as file:\n",
    "\n",
    "    for dataset in dataset_names:\n",
    "        # Replace '_' with '\\_'\n",
    "        dataset_name_latex = dataset[0].replace(\"_\", \"\\_\")\n",
    "        \n",
    "        file.write(\"\\\\begin{table}[h]\\n\")\n",
    "        file.write(\"\\caption{\" + dataset_name_latex + \": \" + str(dataset[1]) + \" instances, \" + str(dataset[2]) + \" features}\\n\")\n",
    "        file.write(\"\\\\label{tab:\" + dataset[0].replace(\" \", \"_\").lower() + \"}\\n\")\n",
    "        file.write(\"\\\\centering\\n\")\n",
    "        file.write(\"\\\\begin{tabular}{lrrrr}\\n\")\n",
    "        file.write(\"\\\\textbf{Model} & \\\\textbf{R squared} & \\\\textbf{Test MSE} & \\\\textbf{Test MAE} & \\\\textbf{Training MAE} \\\\\\\\ \\n\")\n",
    "\n",
    "        for model in model_names:\n",
    "            row = [model]\n",
    "            for metric in list_of_metrics:\n",
    "                mean = mean_std_over_all_metrics[metric][dataset[0]][model]['mean']\n",
    "                std = mean_std_over_all_metrics[metric][dataset[0]][model]['std']\n",
    "                row.append(\"$\" + str(round(mean, 2)) + \"\\pm\" + str(round(std, 2)) +\"$\")\n",
    "            file.write(\" & \".join(row) +\"\\\\\\\\\"+ \"\\n\")\n",
    "\n",
    "        file.write(\"\\end{{tabular}}\\n\")\n",
    "        file.write(\"\\end{{table}}\\n\\n\")\n",
    "\n",
    "print(\"Latex tables have been written to 'latex_tables.txt'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea443003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latex tables have been written to 'latex_tables.txt'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "list_of_metrics = ['r_squared_value', 'test_error', 'loss', 'train_history']\n",
    "# model_names = ['Model1', 'Model2'] # replace with actual model names\n",
    "# dataset_names = [('Dataset1', 100, 5), ('Dataset2', 200, 10)] # replace with actual dataset names\n",
    "\n",
    "# Create file\n",
    "with open(\"latex_tables.txt\", \"w\") as file:\n",
    "\n",
    "    for dataset in dataset_names:\n",
    "        # Replace '_' with '\\_'\n",
    "        dataset_name_latex = dataset[0].replace(\"_\", \"\\\\_\")\n",
    "        \n",
    "        file.write(\"\\\\begin{table}[h]\\n\")\n",
    "        file.write(\"\\caption{\" + dataset_name_latex + \": \" + str(dataset[1]) + \" instances, \" + str(dataset[2]) + \" features}\\n\")\n",
    "        file.write(\"\\\\label{tab:\" + dataset[0].replace(\" \", \"_\").lower() + \"}\\n\")\n",
    "        file.write(\"\\\\centering\\n\")\n",
    "        file.write(\"\\\\begin{tabular}{lrrrr}\\n\")\n",
    "        file.write(\"\\\\textbf{Model} & \\\\textbf{R squared} & \\\\textbf{Test MSE} & \\\\textbf{Test MAE} & \\\\textbf{Training MAE} \\\\\\\\ \\n\")\n",
    "\n",
    "        for model in model_names:\n",
    "            row = [model]\n",
    "            for metric in list_of_metrics:\n",
    "                mean = mean_std_over_all_metrics[metric][dataset[0]][model]['mean']\n",
    "                std = mean_std_over_all_metrics[metric][dataset[0]][model]['std']\n",
    "                row.append(\"$\" + str(round(mean, 2)) + \"\\\\pm\" + str(round(std, 2)) +\"$\")\n",
    "            file.write(\" & \".join(row) +\"\\\\\\\\\"+ \"\\n\")\n",
    "\n",
    "        file.write(\"\\\\end{tabular}\\n\")\n",
    "        file.write(\"\\\\end{table}\\n\\n\")\n",
    "\n",
    "print(\"Latex tables have been written to 'latex_tables.txt'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0cb2c6a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latex tables have been written to 'latex_tables.txt'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "list_of_metrics = ['r_squared_value', 'test_error', 'loss', 'train_history']\n",
    "# model_names = ['Model1', 'Model2'] # replace with actual model names\n",
    "# dataset_names = [('Dataset1', 100, 5), ('Dataset2', 200, 10)] # replace with actual dataset names\n",
    "\n",
    "# Create file\n",
    "with open(\"latex_tables.txt\", \"w\") as file:\n",
    "\n",
    "    for dataset in dataset_names:\n",
    "        # Replace '_' with '\\_'\n",
    "        dataset_name_latex = dataset[0].replace(\"_\", \"\\\\_\")\n",
    "        \n",
    "        file.write(\"\\\\begin{table}[h]\\n\")\n",
    "        file.write(\"\\\\caption{\" + \"\\\\tiny{\" + dataset_name_latex + \": \" + str(dataset[1]) + \" instances, \" + str(dataset[2]) + \" features}\" + \"}\\n\")\n",
    "        file.write(\"\\\\label{tab:\" + dataset[0].replace(\" \", \"_\").lower() + \"}\\n\")\n",
    "        file.write(\"\\\\centering\\n\")\n",
    "        file.write(\"\\\\tiny{\\n\") # Add tiny size \n",
    "        file.write(\"\\\\begin{tabular}{lrrrr}\\n\")\n",
    "        file.write(\"\\\\textbf{Model} & \\\\textbf{Avg. R Squared} & \\\\textbf{Avg. Test MSE} & \\\\textbf{Avg. Test MAE} & \\\\textbf{Avg. Training MAE} \\\\\\\\ \\n\")\n",
    "\n",
    "        for model in model_names:\n",
    "            row = [model]\n",
    "            for metric in list_of_metrics:\n",
    "                mean = mean_std_over_all_metrics[metric][dataset[0]][model]['mean']\n",
    "                std = mean_std_over_all_metrics[metric][dataset[0]][model]['std']\n",
    "                row.append(\"$\" + str(round(mean, 2)) + \"\\\\pm\" + str(round(std, 2)) +\"$\")\n",
    "            file.write(\" & \".join(row) +\"\\\\\\\\\"+ \"\\n\")\n",
    "\n",
    "        file.write(\"\\\\end{tabular}\\n\")\n",
    "        file.write(\"}\\n\") # Close tiny size\n",
    "        file.write(\"\\\\end{table}\\n\\n\")\n",
    "\n",
    "print(\"Latex tables have been written to 'latex_tables.txt'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8f75b1ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latex tables have been written to 'latex_tables.txt'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "list_of_metrics = ['r_squared_value', 'test_error', 'loss', 'train_history']\n",
    "# model_names = ['Model1', 'Model2'] # replace with actual model names\n",
    "# dataset_names = [('Dataset1', 100, 5), ('Dataset2', 200, 10)] # replace with actual dataset names\n",
    "\n",
    "# Create file\n",
    "with open(\"latex_tables.txt\", \"w\") as file:\n",
    "\n",
    "    for dataset in dataset_names:\n",
    "        # Replace '_' with '\\_'\n",
    "        dataset_name_latex = dataset[0].replace(\"_\", \"\\\\_\")\n",
    "        \n",
    "        file.write(\"\\\\begin{table}[!htb]\\n\")\n",
    "        file.write(\"\\\\caption{Dataset: \" + dataset_name_latex + \" (\" + str(dataset[1]) + \" instances, \" + str(dataset[2]) + \" features). Mean and standard deviation of test and training errors.}\\n\")\n",
    "        file.write(\"\\\\label{tab:\" + dataset[0].replace(\" \", \"_\").lower() + \"}\\n\")\n",
    "        file.write(\"\\\\centering\\n\")\n",
    "        file.write(\"\\\\small{\\n\") # Add small size \n",
    "        file.write(\"\\\\begin{tabular}{lrrrr}\\n\")\n",
    "        file.write(\"\\\\textbf{Model} & \\\\textbf{$R^2$} & \\\\textbf{T. MSE} & \\\\textbf{T. MAE} & \\\\textbf{Tr. MAE} \\\\\\\\ \\n\")\n",
    "\n",
    "        for model in model_names:\n",
    "            row = [model]\n",
    "            for metric in list_of_metrics:\n",
    "                mean = mean_std_over_all_metrics[metric][dataset[0]][model]['mean']\n",
    "                std = mean_std_over_all_metrics[metric][dataset[0]][model]['std']\n",
    "                row.append(\"$\" + str(round(mean, 3)) + \"\\\\pm\" + str(round(std, 3)) +\"$\")\n",
    "            file.write(\" & \".join(row) +\"\\\\\\\\\"+ \"\\n\")\n",
    "\n",
    "        file.write(\"\\\\end{tabular}\\n\")\n",
    "        file.write(\"}\\n\") # Close small size\n",
    "        file.write(\"\\\\end{table}\\n\\n\")\n",
    "\n",
    "print(\"Latex tables have been written to 'latex_tables.txt'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e0df7125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latex tables have been written to 'latex_tables.txt'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "list_of_metrics = ['r_squared_value', 'test_error', 'loss', 'train_history']\n",
    "# model_names = ['Model1', 'Model2'] # replace with actual model names\n",
    "# dataset_names = [('Dataset1', 100, 5), ('Dataset2', 200, 10)] # replace with actual dataset names\n",
    "\n",
    "# Create file\n",
    "with open(\"latex_tables.txt\", \"w\") as file:\n",
    "\n",
    "    for dataset in dataset_names:\n",
    "        # Replace '_' with '\\_'\n",
    "        dataset_name_latex = dataset[0].replace(\"_\", \"\\\\_\")\n",
    "        \n",
    "        file.write(\"\\\\begin{table}[h]\\n\")\n",
    "        file.write(\"\\\\caption{Dataset: \" + dataset_name_latex + \" (\" + str(dataset[1]) + \" instances, \" + str(dataset[2]) + \" features). Mean and standard deviation of test and training errors.}\\n\")\n",
    "        file.write(\"\\\\label{tab:\" + dataset[0].replace(\" \", \"_\").lower() + \"}\\n\")\n",
    "        file.write(\"\\\\centering\\n\")\n",
    "        file.write(\"\\\\tiny{\\n\") # Add small size \n",
    "        file.write(\"\\\\begin{tabular}{lcccc}\\n\")\n",
    "        file.write(\"\\\\textbf{Model} & \\\\textbf{$R^2$} & \\\\textbf{T. MSE} & \\\\textbf{T. MAE} & \\\\textbf{Tr. MAE} \\\\\\\\ \\n\")\n",
    "\n",
    "        for model in model_names:\n",
    "            row = [model]\n",
    "            for metric in list_of_metrics:\n",
    "                mean = mean_std_over_all_metrics[metric][dataset[0]][model]['mean']\n",
    "                std = mean_std_over_all_metrics[metric][dataset[0]][model]['std']\n",
    "                row.append(\"$\" + str(round(mean, 3)) + \"\\\\pm\" + str(round(std, 3)) +\"$\")\n",
    "            file.write(\" & \".join(row) +\"\\\\\\\\\"+ \"\\n\")\n",
    "\n",
    "        file.write(\"\\\\end{tabular}\\n\")\n",
    "        file.write(\"}\\n\") # Close small size\n",
    "        file.write(\"\\\\end{table}\\n\\n\")\n",
    "\n",
    "print(\"Latex tables have been written to 'latex_tables.txt'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c7860691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latex tables have been written to 'latex_tables.txt'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from math import log10, floor\n",
    "\n",
    "def round_sig(x, sig=3):\n",
    "    return round(x, sig-int(floor(log10(abs(x))))-1)\n",
    "\n",
    "list_of_metrics = ['r_squared_value', 'test_error', 'loss', 'train_history']\n",
    "# model_names = ['Model1', 'Model2'] # replace with actual model names\n",
    "# dataset_names = [('Dataset1', 100, 5), ('Dataset2', 200, 10)] # replace with actual dataset names\n",
    "\n",
    "# Create file\n",
    "with open(\"latex_tables.txt\", \"w\") as file:\n",
    "    file.write(\"\\\\begin{longtable}{llrrcccc}\\n\")\n",
    "    file.write(\"\\\\textbf{Dataset} & \\\\textbf{Features} & \\\\textbf{Instances} & \\\\textbf{Model} & \\\\textbf{$R^2$} & \\\\textbf{T. MSE} & \\\\textbf{T. MAE} & \\\\textbf{Tr. MAE} \\\\\\\\ \\n\")\n",
    "\n",
    "    for dataset in dataset_names:\n",
    "        # Replace '_' with '\\_'\n",
    "        dataset_name_latex = dataset[0].replace(\"_\", \"\\\\_\")\n",
    "\n",
    "        for model in model_names:\n",
    "            row = [dataset_name_latex,str(dataset[2]),str(dataset[1]),model]\n",
    "            for metric in list_of_metrics:\n",
    "                mean = mean_std_over_all_metrics[metric][dataset[0]][model]['mean']\n",
    "                std = mean_std_over_all_metrics[metric][dataset[0]][model]['std']\n",
    "                row.append(\"$\" + str(round_sig(mean)) + \"\\\\pm\" + str(round_sig(std)) +\"$\")\n",
    "            file.write(\" & \".join(row) +\"\\\\\\\\\"+ \"\\n\")\n",
    "\n",
    "    file.write(\"\\\\caption{Mean and standard deviation of test and training errors for each dataset and model.}\\n\")\n",
    "    file.write(\"\\\\label{tab:long_table}\\n\")\n",
    "    file.write(\"\\\\end{longtable}\\n\")\n",
    "\n",
    "print(\"Latex tables have been written to 'latex_tables.txt'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "25bd4fc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latex tables have been written to 'latex_tables.txt'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from math import log10, floor\n",
    "\n",
    "def round_sig(x, sig=3):\n",
    "    return round(x, sig-int(floor(log10(abs(x))))-1)\n",
    "\n",
    "list_of_metrics = ['r_squared_value', 'test_error', 'loss', 'train_history']\n",
    "# model_names = ['Model1', 'Model2'] # replace with actual model names\n",
    "# dataset_names = [('Dataset1', 100, 5), ('Dataset2', 200, 10)] # replace with actual dataset names\n",
    "\n",
    "# Create file\n",
    "with open(\"latex_tables.txt\", \"w\") as file:\n",
    "    file.write(\"\\\\begin{longtable}{llrrcccc}\\n\")\n",
    "    file.write(\"\\\\textbf{Dataset} & \\\\textbf{Features} & \\\\textbf{Instances} & \\\\textbf{Model} & \\\\textbf{$R^2$} & \\\\textbf{T. MSE} & \\\\textbf{T. MAE} & \\\\textbf{Tr. MAE} \\\\\\\\ \\n\")\n",
    "\n",
    "    for dataset in dataset_names:\n",
    "        # Replace '_' with '\\_'\n",
    "        dataset_name_latex = dataset[0].replace(\"_\", \"\\\\_\")\n",
    "\n",
    "        for model in model_names:\n",
    "            row = [dataset_name_latex,str(dataset[2]),str(dataset[1]),model]\n",
    "            for metric in list_of_metrics:\n",
    "                mean = mean_std_over_all_metrics[metric][dataset[0]][model]['mean']\n",
    "                std = mean_std_over_all_metrics[metric][dataset[0]][model]['std']\n",
    "                row.append(\"$\" + str(round_sig(mean)) + \"\\\\pm\" + str(round_sig(std)) +\"$\")\n",
    "            file.write(\"\\\\tiny{\" + \" & \".join(row) +\"\\\\\\\\\"+ \"}\\n\")\n",
    "\n",
    "    file.write(\"\\\\caption{Mean and standard deviation of test and training errors for each dataset and model.}\\n\")\n",
    "    file.write(\"\\\\label{tab:long_table}\\n\")\n",
    "    file.write(\"\\\\end{longtable}\\n\")\n",
    "\n",
    "print(\"Latex tables have been written to 'latex_tables.txt'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ac5e552c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latex tables have been written to 'latex_tables.txt'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from math import log10, floor\n",
    "\n",
    "def round_sig(x, sig=3):\n",
    "    return round(x, sig-int(floor(log10(abs(x))))-1)\n",
    "\n",
    "list_of_metrics = ['r_squared_value', 'test_error', 'loss', 'train_history']\n",
    "# model_names = ['Model1', 'Model2'] # replace with actual model names\n",
    "# dataset_names = [('Dataset1', 100, 5), ('Dataset2', 200, 10)] # replace with actual dataset names\n",
    "\n",
    "# Create file\n",
    "with open(\"latex_tables.txt\", \"w\") as file:\n",
    "    file.write(\"\\\\begin{longtable}{llrrcccc}\\n\")\n",
    "    file.write(\"\\\\caption{Mean and standard deviation of test and training errors for each dataset and model.}\\n\") # Caption in normal size\n",
    "    file.write(\"\\\\label{tab:long_table}\\n\")\n",
    "    file.write(\"{\\\\tiny \\n\") # Tiny size for table content\n",
    "    file.write(\"\\\\textbf{Dataset} & \\\\textbf{Features} & \\\\textbf{Instances} & \\\\textbf{Model} & \\\\textbf{$R^2$} & \\\\textbf{T. MSE} & \\\\textbf{T. MAE} & \\\\textbf{Tr. MAE} \\\\\\\\ \\n\")\n",
    "\n",
    "    for dataset in dataset_names:\n",
    "        # Replace '_' with '\\_'\n",
    "        dataset_name_latex = dataset[0].replace(\"_\", \"\\\\_\")\n",
    "\n",
    "        for model in model_names:\n",
    "            row = [dataset_name_latex,str(dataset[2]),str(dataset[1]),model]\n",
    "            for metric in list_of_metrics:\n",
    "                mean = mean_std_over_all_metrics[metric][dataset[0]][model]['mean']\n",
    "                std = mean_std_over_all_metrics[metric][dataset[0]][model]['std']\n",
    "                row.append(\"$\" + str(round_sig(mean)) + \"\\\\pm\" + str(round_sig(std)) +\"$\")\n",
    "            file.write(\" & \".join(row) +\"\\\\\\\\\"+ \"\\n\")\n",
    "\n",
    "    file.write(\"} \\n\") # Close the tiny size\n",
    "    file.write(\"\\\\end{longtable}\\n\")\n",
    "\n",
    "print(\"Latex tables have been written to 'latex_tables.txt'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0cc7432f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latex tables have been written to 'latex_tables.txt'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from math import log10, floor\n",
    "\n",
    "def round_sig(x, sig=3):\n",
    "    return round(x, sig-int(floor(log10(abs(x))))-1)\n",
    "\n",
    "list_of_metrics = ['r_squared_value', 'test_error', 'loss', 'train_history']\n",
    "# model_names = ['Model1', 'Model2'] # replace with actual model names\n",
    "# dataset_names = [('Dataset1', 100, 5), ('Dataset2', 200, 10)] # replace with actual dataset names\n",
    "\n",
    "# Create file\n",
    "with open(\"latex_tables.txt\", \"w\") as file:\n",
    "    file.write(\"\\\\begin{longtable}{llrrcccc}\\n\")\n",
    "    file.write(\"\\\\textbf{Dataset} & \\\\textbf{Features} & \\\\textbf{Instances} & \\\\textbf{Model} & \\\\textbf{$R^2$} & \\\\textbf{T. MSE} & \\\\textbf{T. MAE} & \\\\textbf{Tr. MAE} \\\\\\\\ \\n\")\n",
    "\n",
    "    for dataset in dataset_names:\n",
    "        # Replace '_' with '\\_'\n",
    "        dataset_name_latex = dataset[0].replace(\"_\", \"\\\\_\")\n",
    "\n",
    "        for model in model_names:\n",
    "            row = [dataset_name_latex,str(dataset[2]),str(dataset[1]),model]\n",
    "            for metric in list_of_metrics:\n",
    "                mean = mean_std_over_all_metrics[metric][dataset[0]][model]['mean']\n",
    "                std = mean_std_over_all_metrics[metric][dataset[0]][model]['std']\n",
    "                row.append(\"$\" + str(round_sig(mean)) + \"\\\\pm\" + str(round_sig(std)) +\"$\")\n",
    "            file.write(\" & \".join(row) +\"\\\\\\\\\"+ \"\\n\")\n",
    "\n",
    "    file.write(\"\\\\caption{Mean and standard deviation of test and training errors for each dataset and model.}\\n\")\n",
    "    file.write(\"\\\\label{tab:long_table}\\n\")\n",
    "    file.write(\"\\\\end{longtable}\\n\")\n",
    "\n",
    "print(\"Latex tables have been written to 'latex_tables.txt'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "13607e41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latex tables have been written to 'latex_tables.txt'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "list_of_metrics = ['r_squared_value', 'test_error', 'loss', 'train_history']\n",
    "# model_names = ['Model1', 'Model2'] # replace with actual model names\n",
    "# dataset_names = [('Dataset1', 100, 5), ('Dataset2', 200, 10)] # replace with actual dataset names\n",
    "\n",
    "# Create file\n",
    "with open(\"latex_tables.txt\", \"w\") as file:\n",
    "    file.write(\"\\\\begin{longtable}{llrrcccc}\\n\")\n",
    "    file.write(\"\\\\textbf{Dataset} & \\\\textbf{Features} & \\\\textbf{Instances} & \\\\textbf{Model} & \\\\textbf{$R^2$} & \\\\textbf{T. MSE} & \\\\textbf{T. MAE} & \\\\textbf{Tr. MAE} \\\\\\\\ \\n\")\n",
    "    file.write(\"\\\\begin{tiny}\\n\")\n",
    "\n",
    "    for dataset in dataset_names:\n",
    "        # Replace '_' with '\\_'\n",
    "        dataset_name_latex = dataset[0].replace(\"_\", \"\\\\_\")\n",
    "\n",
    "        for model in model_names:\n",
    "            row = [dataset_name_latex,str(dataset[2]),str(dataset[1]),model]\n",
    "            for metric in list_of_metrics:\n",
    "                mean = mean_std_over_all_metrics[metric][dataset[0]][model]['mean']\n",
    "                std = mean_std_over_all_metrics[metric][dataset[0]][model]['std']\n",
    "                row.append(\"$\" + \"{:.3f}\".format(mean) + \"\\\\pm\" + \"{:.3f}\".format(std) +\"$\")\n",
    "            file.write(\" & \".join(row) +\"\\\\\\\\\"+ \"\\n\")\n",
    "\n",
    "    file.write(\"\\\\end{tiny}\\n\")\n",
    "    file.write(\"\\\\caption{Mean and standard deviation of test and training errors for each dataset and model.}\\n\")\n",
    "    file.write(\"\\\\label{tab:long_table}\\n\")\n",
    "    file.write(\"\\\\end{longtable}\\n\")\n",
    "\n",
    "print(\"Latex tables have been written to 'latex_tables.txt'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "181c4c85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latex tables have been written to 'latex_tables.txt'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "list_of_metrics = ['r_squared_value', 'test_error', 'loss', 'train_history']\n",
    "# model_names = ['Model1', 'Model2'] # replace with actual model names\n",
    "# dataset_names = [('Dataset1', 100, 5), ('Dataset2', 200, 10)] # replace with actual dataset names\n",
    "\n",
    "# Create file\n",
    "with open(\"latex_tables.txt\", \"w\") as file:\n",
    "    file.write(\"\\\\begin{tiny}\\n\")\n",
    "    file.write(\"\\\\begin{longtable}{llrrcccc}\\n\")\n",
    "    file.write(\"\\\\textbf{Dataset} & \\\\textbf{$n$} & \\\\textbf{$\\\\textup{N}$} & \\\\textbf{Model} & \\\\textbf{$R^2$} & \\\\textbf{T. MSE} & \\\\textbf{T. MAE} & \\\\textbf{Tr. MAE} \\\\\\\\ \\n\")\n",
    "\n",
    "    for dataset in dataset_names:\n",
    "        # Replace '_' with '\\_'\n",
    "        dataset_name_latex = dataset[0].replace(\"_\", \"\\\\_\")\n",
    "\n",
    "        for model in model_names:\n",
    "            row = [dataset_name_latex,str(dataset[2]),str(dataset[1]),model]\n",
    "            for metric in list_of_metrics:\n",
    "                mean = mean_std_over_all_metrics[metric][dataset[0]][model]['mean']\n",
    "                std = mean_std_over_all_metrics[metric][dataset[0]][model]['std']\n",
    "                row.append(\"$\" + \"{:.3f}\".format(mean) + \"\\\\pm\" + \"{:.3f}\".format(std) +\"$\")\n",
    "            file.write(\" & \".join(row) +\"\\\\\\\\\"+ \"\\n\")\n",
    "\n",
    "    file.write(\"\\\\normalsize\\n\")\n",
    "    file.write(\"\\\\caption{\\\\normalsize{Mean and standard deviation of test and training errors for each dataset and model.}}\\n\")\n",
    "    file.write(\"\\\\end{longtable}\\n\")\n",
    "    file.write(\"\\\\label{tab:long_table}\\n\")\n",
    "    file.write(\"\\\\end{tiny}\\n\")\n",
    "\n",
    "print(\"Latex tables have been written to 'latex_tables.txt'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "28b660f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latex tables have been written to 'latex_tables.txt'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "list_of_metrics = ['r_squared_value', 'test_error', 'loss', 'train_history']\n",
    "# model_names = ['Model1', 'Model2'] # replace with actual model names\n",
    "# dataset_names = [('Dataset1', 100, 5), ('Dataset2', 200, 10)] # replace with actual dataset names\n",
    "\n",
    "# Create file\n",
    "with open(\"latex_tables.txt\", \"w\") as file:\n",
    "    file.write(\"\\\\begin{tiny}\\n\")\n",
    "    file.write(\"\\\\begin{longtable}{llrrcccc}\\n\")\n",
    "    file.write(\"\\\\textbf{Dataset} & \\\\textbf{$n$} & \\\\textbf{$\\\\textup{N}$} & \\\\textbf{Model} & \\\\textbf{$R^2$} & \\\\textbf{T. MSE} & \\\\textbf{T. MAE} & \\\\textbf{Tr. MAE} \\\\\\\\ \\n\")\n",
    "\n",
    "    for dataset in dataset_names:\n",
    "        # Replace '_' with '\\_'\n",
    "        dataset_name_latex = dataset[0].replace(\"_\", \"\\\\_\")\n",
    "\n",
    "        for model in model_names:\n",
    "            row = [dataset_name_latex,str(dataset[2]),str(dataset[1]),model]\n",
    "            for metric in list_of_metrics:\n",
    "                mean = mean_std_over_all_metrics[metric][dataset[0]][model]['mean']\n",
    "                std = mean_std_over_all_metrics[metric][dataset[0]][model]['std']\n",
    "                row.append(\"$\" + \"{:.3f}\".format(mean) + \"\\\\pm\" + \"{:.3f}\".format(std) +\"$\")\n",
    "            file.write(\" & \".join(row) +\"\\\\\\\\\"+ \"\\n\")\n",
    "\n",
    "    file.write(\"\\\\normalsize\\n\")\n",
    "    file.write(\"\\\\caption{\\\\normalsize{Mean and standard deviation of test and training errors for each dataset and model.}}\\n\")\n",
    "    file.write(\"\\\\end{longtable}\\n\")\n",
    "    file.write(\"\\\\label{tab:long_table}\\n\")\n",
    "    file.write(\"\\\\end{tiny}\\n\")\n",
    "\n",
    "print(\"Latex tables have been written to 'latex_tables.txt'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "43d30fe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latex tables have been written to 'latex_tables.txt'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "list_of_metrics = ['r_squared_value', 'test_error', 'loss', 'train_history']\n",
    "# model_names = ['Model1', 'Model2'] # replace with actual model names\n",
    "# dataset_names = [('Dataset1', 100, 5), ('Dataset2', 200, 10)] # replace with actual dataset names\n",
    "\n",
    "# Create file\n",
    "with open(\"latex_tables.txt\", \"w\") as file:\n",
    "    file.write(\"\\\\begin{tiny}\\n\")\n",
    "    file.write(\"\\\\begin{longtable}{llrrcccc}\\n\")\n",
    "    file.write(\"\\\\caption{Mean and standard deviation of test and training errors for each dataset and model.}\\n\")\n",
    "    file.write(\"\\\\label{tab:long_table}\\n\")\n",
    "    file.write(\"\\\\textbf{Dataset} & \\\\textbf{$n$} & \\\\textbf{$\\\\textup{N}$} & \\\\textbf{Model} & \\\\textbf{$R^2$} & \\\\textbf{T. MSE} & \\\\textbf{T. MAE} & \\\\textbf{Tr. MAE} \\\\\\\\ \\n\")\n",
    "    file.write(\"\\\\endhead\\n\")\n",
    "    file.write(\"\\\\multicolumn{8}{r}{\\\\small\\\\itshape Continued on next page}\\n\")\n",
    "    file.write(\"\\\\endfoot\\n\")\n",
    "\n",
    "    for dataset in dataset_names:\n",
    "        # Replace '_' with '\\_'\n",
    "        dataset_name_latex = dataset[0].replace(\"_\", \"\\\\_\")\n",
    "\n",
    "        for model in model_names:\n",
    "            row = [dataset_name_latex,str(dataset[2]),str(dataset[1]),model]\n",
    "            for metric in list_of_metrics:\n",
    "                mean = mean_std_over_all_metrics[metric][dataset[0]][model]['mean']\n",
    "                std = mean_std_over_all_metrics[metric][dataset[0]][model]['std']\n",
    "                row.append(\"$\" + \"{:.3f}\".format(mean) + \"\\\\pm\" + \"{:.3f}\".format(std) +\"$\")\n",
    "            file.write(\" & \".join(row) +\"\\\\\\\\\"+ \"\\n\")\n",
    "\n",
    "    file.write(\"\\\\end{longtable}\\n\")\n",
    "    file.write(\"\\\\end{tiny}\\n\")\n",
    "\n",
    "print(\"Latex tables have been written to 'latex_tables.txt'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "71df7c00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latex tables have been written to 'latex_tables.txt'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "list_of_metrics = ['r_squared_value', 'test_error', 'loss', 'train_history']\n",
    "# model_names = ['Model1', 'Model2'] # replace with actual model names\n",
    "# dataset_names = [('Dataset1', 100, 5), ('Dataset2', 200, 10)] # replace with actual dataset names\n",
    "\n",
    "# Create file\n",
    "with open(\"latex_tables.txt\", \"w\") as file:\n",
    "    file.write(\"\\\\begin{tiny}\\n\")\n",
    "    file.write(\"\\\\begin{longtable}{llrrcccc}\\n\")\n",
    "    file.write(\"\\\\caption{\\\\normalsize{PMLB: Mean and standard deviation of test and training error.}}\\n\")\n",
    "    file.write(\"\\\\label{tab:long_table}\" + \"\\\\\\\\\" + \"\\n\")\n",
    "    file.write(\"\\\\textbf{Dataset} & \\\\textbf{$n$} & \\\\textbf{$\\\\textup{N}$} & \\\\textbf{Model} & \\\\textbf{$R^2$} & \\\\textbf{T. MSE} & \\\\textbf{T. MAE} & \\\\textbf{Tr. MAE} \\\\\\\\ \\n\")\n",
    "\n",
    "    for dataset in dataset_names:\n",
    "        # Replace '_' with '\\_'\n",
    "        dataset_name_latex = dataset[0].replace(\"_\", \"\\\\_\")\n",
    "\n",
    "        for model in model_names:\n",
    "            row = [dataset_name_latex,str(dataset[2]),str(dataset[1]),model]\n",
    "            for metric in list_of_metrics:\n",
    "                mean = mean_std_over_all_metrics[metric][dataset[0]][model]['mean']\n",
    "                std = mean_std_over_all_metrics[metric][dataset[0]][model]['std']\n",
    "                row.append(\"$\" + \"{:.3f}\".format(mean) + \"\\\\pm\" + \"{:.3f}\".format(std) +\"$\")\n",
    "            file.write(\" & \".join(row) +\"\\\\\\\\\"+ \"\\n\")\n",
    "\n",
    "    \n",
    "    file.write(\"\\\\end{longtable}\\n\")\n",
    "    file.write(\"\\\\end{tiny}\\n\")\n",
    "\n",
    "print(\"Latex tables have been written to 'latex_tables.txt'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "970226e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latex tables have been written to 'latex_tables.txt'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "list_of_metrics = ['r_squared_value', 'test_error', 'loss', 'train_history']\n",
    "# model_names = ['Model1', 'Model2'] # replace with actual model names\n",
    "# dataset_names = [('Dataset1', 100, 5), ('Dataset2', 200, 10)] # replace with actual dataset names\n",
    "\n",
    "# Create file\n",
    "with open(\"latex_tables.txt\", \"w\") as file:\n",
    "    file.write(\"\\\\begin{tiny}\\n\")\n",
    "    file.write(\"\\\\begin{longtable}{llrrcccc}\\n\")\n",
    "    file.write(\"\\\\caption{\\\\normalsize{PMLB: Mean and standard deviation of test and training error.}}\\n\")\n",
    "    file.write(\"\\\\label{tab:long_table}\" + \"\\\\\\\\\" + \"\\n\")\n",
    "    table_header = \"\\\\textbf{Dataset} & \\\\textbf{$n$} & \\\\textbf{$\\\\textup{N}$} & \\\\textbf{Model} & \\\\textbf{$R^2$} & \\\\textbf{T. MSE} & \\\\textbf{T. MAE} & \\\\textbf{Tr. MAE}\"\n",
    "    file.write(table_header + \" \\\\\\\\ \\n\")\n",
    "\n",
    "    # Add header to each page\n",
    "    file.write(\"\\\\endhead\\n\")\n",
    "\n",
    "    # Add footer to each page if desired\n",
    "    #file.write(\"Footer \\\\\\\\ \\n\")\n",
    "    #file.write(\"\\\\endfoot\\n\")\n",
    "\n",
    "    \n",
    "    for dataset in dataset_names:\n",
    "        # Replace '_' with '\\_'\n",
    "        dataset_name_latex = dataset[0].replace(\"_\", \"\\\\_\")\n",
    "\n",
    "        for model in model_names:\n",
    "            row = [dataset_name_latex,str(dataset[2]),str(dataset[1]),model]\n",
    "            for metric in list_of_metrics:\n",
    "                mean = mean_std_over_all_metrics[metric][dataset[0]][model]['mean']\n",
    "                std = mean_std_over_all_metrics[metric][dataset[0]][model]['std']\n",
    "                row.append(\"$\" + \"{:.3f}\".format(mean) + \"\\\\pm\" + \"{:.3f}\".format(std) +\"$\")\n",
    "            file.write(\" & \".join(row) +\"\\\\\\\\\"+ \"\\n\")\n",
    "\n",
    "    \n",
    "    file.write(\"\\\\end{longtable}\\n\")\n",
    "    file.write(\"\\\\end{tiny}\\n\")\n",
    "\n",
    "print(\"Latex tables have been written to 'latex_tables.txt'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "31e78a9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latex tables have been written to 'latex_tables.txt'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "list_of_metrics = ['r_squared_value', 'test_error', 'loss', 'train_history']\n",
    "# model_names = ['Model1', 'Model2'] # replace with actual model names\n",
    "# dataset_names = [('Dataset1', 100, 5), ('Dataset2', 200, 10)] # replace with actual dataset names\n",
    "\n",
    "# Create file\n",
    "with open(\"latex_tables.txt\", \"w\") as file:\n",
    "    file.write(\"\\\\begin{tiny}\\n\")\n",
    "    file.write(\"\\\\begin{longtable}{llrrcccc}\\n\")\n",
    "    file.write(\"\\\\caption{\\\\normalsize{PMLB: Mean and standard deviation of test and training error.}}\\n\")\n",
    "    file.write(\"\\\\label{tab:long_table}\" + \"\\\\\\\\\" + \"\\n\")\n",
    "    \n",
    "    table_header = \"\\\\textbf{Dataset} & \\\\textbf{$n$} & \\\\textbf{$\\\\textup{N}$} & \\\\textbf{Model} & \\\\textbf{$R^2$} & \\\\textbf{T. MSE} & \\\\textbf{T. MAE} & \\\\textbf{Tr. MAE}\"\n",
    "    file.write(table_header + \" \\\\\\\\ \\n\")\n",
    "\n",
    "    # Add header to each page\n",
    "    file.write(\"\\\\endhead\\n\")\n",
    "\n",
    "    # Add footer to each page when table continues on next page\n",
    "    file.write(\"\\\\multicolumn{8}{r}{Continued on next page} \\\\\\\\ \\n\")\n",
    "    file.write(\"\\\\endfoot\\n\")\n",
    "\n",
    "    # Footer for the final page of the table\n",
    "    file.write(\"\\\\endlastfoot\\n\")\n",
    "\n",
    "    for dataset in dataset_names:\n",
    "        # Replace '_' with '\\_'\n",
    "        dataset_name_latex = dataset[0].replace(\"_\", \"\\\\_\")\n",
    "\n",
    "        for model in model_names:\n",
    "            row = [dataset_name_latex,str(dataset[2]),str(dataset[1]),model]\n",
    "            for metric in list_of_metrics:\n",
    "                mean = mean_std_over_all_metrics[metric][dataset[0]][model]['mean']\n",
    "                std = mean_std_over_all_metrics[metric][dataset[0]][model]['std']\n",
    "                row.append(\"$\" + \"{:.3f}\".format(mean) + \"\\\\pm\" + \"{:.3f}\".format(std) +\"$\")\n",
    "            file.write(\" & \".join(row) +\"\\\\\\\\\"+ \"\\n\")\n",
    "\n",
    "    file.write(\"\\\\end{longtable}\\n\")\n",
    "    file.write(\"\\\\end{tiny}\\n\")\n",
    "\n",
    "print(\"Latex tables have been written to 'latex_tables.txt'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a30397",
   "metadata": {},
   "outputs": [],
   "source": [
    "\\begin{longtable}{llrrcccc}\n",
    "    \\caption{\\normalsize{PMLB: Mean and standard deviation of test and training error.}}\n",
    "    \\label{tab:pmlb_mean_data}\\\\\n",
    "    \\textbf{Dataset} & \\textbf{$n$} & \\textbf{$\\textup{N}$} & \\textbf{Model} & \\textbf{$R^2$} & \\textbf{T. MSE} & \\textbf{T. MAE} & \\textbf{Tr. MAE} \\\\ \n",
    "    \\endfirsthead\n",
    "    \\multicolumn{8}{c}{\\tablename\\ \\thetable{} -- Continued from previous page} \\\\\n",
    "    \\textbf{Dataset} & \\textbf{$n$} & \\textbf{$\\textup{N}$} & \\textbf{Model} & \\textbf{$R^2$} & \\textbf{T. MSE} & \\textbf{T. MAE} & \\textbf{Tr. MAE} \\\\ \n",
    "    \\endhead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1c8c5fdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latex tables have been written to 'latex_tables.txt'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "list_of_metrics = ['r_squared_value', 'test_error', 'loss', 'train_history']\n",
    "# model_names = ['Model1', 'Model2'] # replace with actual model names\n",
    "# dataset_names = [('Dataset1', 100, 5), ('Dataset2', 200, 10)] # replace with actual dataset names\n",
    "\n",
    "# Create file\n",
    "with open(\"latex_tables.txt\", \"w\") as file:\n",
    "    file.write(\"\\\\begin{tiny}\\n\")\n",
    "    file.write(\"\\\\begin{longtable}{llrrcccc}\\n\")\n",
    "    file.write(\"\\\\caption{\\\\normalsize{PMLB: Mean and standard deviation of test and training error.}}\\n\")\n",
    "    file.write(\"\\\\label{tab:pmlb_mean_data}\" + \"\\\\\\\\\" + \"\\n\")\n",
    "    \n",
    "    table_header = \"\\\\textbf{Dataset} & \\\\textbf{$n$} & \\\\textbf{$\\\\textup{N}$} & \\\\textbf{Model} & \\\\textbf{$R^2$} & \\\\textbf{T. MSE} & \\\\textbf{T. MAE} & \\\\textbf{Tr. MAE}\"\n",
    "    file.write(table_header + \" \\\\\\\\ \\n\")\n",
    "\n",
    "    # Header to each page after first page\n",
    "    file.write(\"\\\\endfirsthead\\n\")\n",
    "    \n",
    "    # For subsequent pages\n",
    "    file.write(\"\\\\multicolumn{8}{c}{\\\\tablename\\\\ \\\\thetable{} -- Continued from previous page} \\\\\\\\\\n\")\n",
    "    file.write(table_header + \" \\\\\\\\ \\n\")\n",
    "    \n",
    "    # Add header to each subsequent page\n",
    "    file.write(\"\\\\endhead\\n\")\n",
    "\n",
    "    # Add footer to each page when table continues on next page\n",
    "    file.write(\"\\\\multicolumn{8}{r}{Continued on next page} \\\\\\\\ \\n\")\n",
    "    file.write(\"\\\\endfoot\\n\")\n",
    "\n",
    "    # Footer for the final page of the table\n",
    "    file.write(\"\\\\endlastfoot\\n\")\n",
    "\n",
    "    for dataset in dataset_names:\n",
    "        # Replace '_' with '\\_'\n",
    "        dataset_name_latex = dataset[0].replace(\"_\", \"\\\\_\")\n",
    "\n",
    "        for model in model_names:\n",
    "            row = [dataset_name_latex,str(dataset[2]),str(dataset[1]),model]\n",
    "            for metric in list_of_metrics:\n",
    "                mean = mean_std_over_all_metrics[metric][dataset[0]][model]['mean']\n",
    "                std = mean_std_over_all_metrics[metric][dataset[0]][model]['std']\n",
    "                row.append(\"$\" + \"{:.3f}\".format(mean) + \"\\\\pm\" + \"{:.3f}\".format(std) +\"$\")\n",
    "            file.write(\" & \".join(row) +\"\\\\\\\\\"+ \"\\n\")\n",
    "\n",
    "    file.write(\"\\\\end{longtable}\\n\")\n",
    "    file.write(\"\\\\end{tiny}\\n\")\n",
    "\n",
    "print(\"Latex tables have been written to 'latex_tables.txt'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67628d18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
