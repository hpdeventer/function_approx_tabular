{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6283161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    dataset  n_instances  n_features  n_binary_features  \\\n",
      "2  1029_LEV         1000           4                  0   \n",
      "3  1030_ERA         1000           4                  0   \n",
      "\n",
      "   n_categorical_features  n_continuous_features endpoint_type  n_classes  \\\n",
      "2                       0                      4    continuous        5.0   \n",
      "3                       0                      4    continuous        9.0   \n",
      "\n",
      "   imbalance        task  \n",
      "2   0.111245  regression  \n",
      "3   0.031251  regression  \n"
     ]
    }
   ],
   "source": [
    "# we need a way to specify unique model name, or save model outputs based on indices.\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from model_data_definitions import *\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# expensive and slow operation done once.\n",
    "filtered_datasets, datasets = fetch_return_filtered_pmlb_data_sets() \n",
    "print(filtered_datasets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed617ec0",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['target'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 85\u001b[0m\n\u001b[0;32m     82\u001b[0m     pool\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 85\u001b[0m   \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[2], line 62\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     59\u001b[0m num_folds \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m\n\u001b[0;32m     60\u001b[0m epoch_number \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m \n\u001b[1;32m---> 62\u001b[0m dataset_list \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_cross_validation_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_folds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     64\u001b[0m pool \u001b[38;5;241m=\u001b[39m mp\u001b[38;5;241m.\u001b[39mPool(mp\u001b[38;5;241m.\u001b[39mcpu_count())\n\u001b[0;32m     66\u001b[0m all_results \u001b[38;5;241m=\u001b[39m []\n",
      "Cell \u001b[1;32mIn[2], line 9\u001b[0m, in \u001b[0;36mgenerate_cross_validation_dataset\u001b[1;34m(data, num_folds)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_cross_validation_dataset\u001b[39m(data, num_folds):\n\u001b[1;32m----> 9\u001b[0m     X, y \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtarget\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mvalues, data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m     11\u001b[0m     dataset_list \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     12\u001b[0m     kf \u001b[38;5;241m=\u001b[39m KFold(n_splits\u001b[38;5;241m=\u001b[39mnum_folds)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:5258\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   5110\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(\n\u001b[0;32m   5111\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   5112\u001b[0m     labels: IndexLabel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5119\u001b[0m     errors: IgnoreRaise \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   5120\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   5121\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   5122\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[0;32m   5123\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5256\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[0;32m   5257\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 5258\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   5259\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5260\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5261\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5262\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5263\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5264\u001b[0m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5265\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5266\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:4549\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4547\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m   4548\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 4549\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4551\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[0;32m   4552\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:4591\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[1;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[0;32m   4589\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4590\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 4591\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m \u001b[43maxis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4592\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[0;32m   4594\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[0;32m   4595\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6696\u001b[0m, in \u001b[0;36mIndex.drop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   6694\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m   6695\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 6696\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(labels[mask])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6697\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[0;32m   6698\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['target'] not found in axis\""
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import multiprocessing as mp\n",
    "\n",
    "def generate_cross_validation_dataset(data, num_folds):\n",
    "    X, y = data.drop('target', axis=1).values, data['target'].values\n",
    "    \n",
    "    dataset_list = []\n",
    "    kf = KFold(n_splits=num_folds)\n",
    "    \n",
    "    for fold, (train_index, test_index) in enumerate(kf.split(X)):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        dataset_list.append((X_train, y_train, X_test, y_test , fold+1))\n",
    "    \n",
    "    return dataset_list\n",
    "\n",
    "def train_evaluate_model(params):\n",
    "    \n",
    "    model_tuple , fold_data , epoch_number = params \n",
    "    model, name = model_tuple\n",
    "\n",
    "    X_train, y_train, X_test, y_test , fold = fold_data\n",
    "    \n",
    "    history = model.fit(X_train, y_train,\n",
    "                        epochs=epoch_number,\n",
    "                        verbose=0,\n",
    "                        validation_data=(X_test,y_test))\n",
    "    \n",
    "    loss = model.evaluate(X_test,y_test , verbose=0)\n",
    "\n",
    "    predictions = model.predict(X_test)\n",
    "    \n",
    "    r_squared_value = r2_score(y_test,predictions)\n",
    "    \n",
    "    test_error = mean_squared_error(y_test,predictions)\n",
    "\n",
    "    results = {\n",
    "        'model': name,\n",
    "        'fold': fold,\n",
    "        'train_history': history.history['loss'],\n",
    "        'val_history': history.history['val_loss'],\n",
    "        'loss': loss,\n",
    "        'r_squared_value': r_squared_value,\n",
    "        'test_error': test_error}\n",
    "    \n",
    "    # save results   \n",
    "    return results\n",
    "\n",
    "def main():\n",
    "\n",
    "    # assuming some pandas dataframe here\n",
    "    data = pd.DataFrame() \n",
    "\n",
    "    num_folds = 5\n",
    "    epoch_number = 100 \n",
    "\n",
    "    dataset_list = generate_cross_validation_dataset(data, num_folds)\n",
    "\n",
    "    pool = mp.Pool(mp.cpu_count())\n",
    "\n",
    "    all_results = []\n",
    "    \n",
    "    for fold_data in dataset_list:\n",
    "        \n",
    "        input_dim = fold_data[0].shape[1]\n",
    "        \n",
    "        models = initialize_all_models(input_dim, seed_val=fold_data[-1])\n",
    "        \n",
    "        compile_models(models)\n",
    "        \n",
    "        job_params=[(model , fold_data , epoch_number) for model in models]\n",
    "        \n",
    "        results=pool.map(train_evaluate_model, job_params)\n",
    "        \n",
    "        all_results.extend(results)\n",
    "    \n",
    "    pool.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e77d639",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd188b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77bc45ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a260337",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3d2440",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824fbfdd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8ba770",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104d421b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774086dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56edf72a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f1f99c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_cross_validation_dataset(data, num_folds):\n",
    "    X, y = data.drop('target', axis=1).values, data['target'].values\n",
    "    \n",
    "    dataset_list = []\n",
    "    kf = KFold(n_splits=num_folds)\n",
    "    fold = 0\n",
    "\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        fold += 1\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        dataset_list.append((X_train, y_train, X_test, y_test , fold))\n",
    "    \n",
    "    return dataset_list\n",
    "\n",
    "def generate_cross_validation_models(input_dim, num_folds):\n",
    "    model_lists = []\n",
    "    for fold in range(num_folds):\n",
    "        models = initialize_all_models(input_dim, seed_val=fold)\n",
    "        compile_models(models)\n",
    "        model_lists.append(models)\n",
    "    return model_lists\n",
    "\n",
    "def train_evaluate_model(model_tuple, fold_data, epoch_number):\n",
    "    \n",
    "    model, name = model_tuple\n",
    "    X_train, y_train, X_test, y_test , fold = fold_data\n",
    "    \n",
    "    history = model.fit(X_train, y_train,\n",
    "                        epochs=epoch_number,\n",
    "                        verbose=0,\n",
    "                        validation_data=(X_test, y_test))\n",
    "\n",
    "    loss = model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "    predictions = model.predict(X_test)\n",
    "    r_squared_value = r2_score(y_test,predictions)\n",
    "    test_error = mean_squared_error(y_test,predictions)\n",
    "\n",
    "    results = {\n",
    "        'model': name,\n",
    "        'fold': fold,\n",
    "        'train_history': history['loss'],\n",
    "        'val_history': history['val_loss'],\n",
    "        'loss': loss,\n",
    "        'r_squared_value': r_squared_value,\n",
    "        'test_error': test_error}\n",
    "    \n",
    "    return results    \n",
    "\n",
    "def cross_validation(data, epoch_number, num_folds):\n",
    "    \n",
    "    # Generate cross validation datasets\n",
    "    cv_datasets = generate_cross_validation_dataset(data, num_folds)\n",
    "    cv_models = generate_cross_validation_models(X_train.shape[1], num_folds)\n",
    "    \n",
    "    for fold in range(num_folds):\n",
    "        fold_data = cv_datasets[fold]\n",
    "        models = cv_models[fold]\n",
    "        for model_tuple in models:\n",
    "            train_evaluate_model(model_tuple, fold_data, epoch_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e59b056",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae6dde9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf57f42c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e5f695",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17596319",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967724d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1597de9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126f91b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(data, epoch_number, num_folds):\n",
    "    \n",
    "    # Generate cross validation datasets\n",
    "    cv_datasets = generate_cross_validation_dataset(data, num_folds)\n",
    "    cv_models = generate_cross_validation_models(X_train.shape[1], num_folds)\n",
    "    \n",
    "    for fold in range(num_folds):\n",
    "        fold_data = cv_datasets[fold]\n",
    "        models = cv_models[fold]\n",
    "        for model_tuple in models:\n",
    "            train_evaluate_model(model_tuple, fold_data, epoch_number)\n",
    "            \n",
    "            \n",
    "    \n",
    "    all_results = []\n",
    "    \n",
    "    for fold_data in cv_datasets:\n",
    "        X_train, y_train, X_test, y_test , fold = fold_data\n",
    "        \n",
    "        # Generate models for this fold\n",
    "        models = generate_cross_validation_models(X_train.shape[1], num_folds)\n",
    "        \n",
    "        fold_results = []\n",
    "        \n",
    "        # Train and evaluate each model on this fold's data\n",
    "        for model_tuple in models:\n",
    "            result = train_evaluate_model(model_tuple, fold_data, epoch_number)\n",
    "            fold_results.append(result)\n",
    "        \n",
    "        all_results.append(fold_results)\n",
    "\n",
    "    return all_results\n",
    "\n",
    "all_results = {}\n",
    "\n",
    "for dataset, row in zip(datasets, filtered_datasets.iterrows()):\n",
    "    dataset_name = row[1]['dataset']\n",
    "    print(f\"Evaluating dataset: {dataset_name}\")\n",
    "\n",
    "    results = cross_validation(dataset)\n",
    "    all_results[dataset_name] = results\n",
    "\n",
    "# save results to a JSON file\n",
    "with open('results.json', 'w') as f:\n",
    "    json.dump(all_results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab1d3f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085a9e83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1abb58c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a51163",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd3e7ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9350a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# the k-fold\n",
    "[(train_index, test_index) for train_index,test_index in kf.split(X)]\n",
    "\n",
    "input_dimension = row[1]['n_features']\n",
    "X_train, X_test = X[train_index], X[test_index]\n",
    "\n",
    "models = initialize_all_models(X_train.shape[1], seed_val=fold) #input dimension specify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb3b46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_evaluate_model(model_name_tuple, data, indices, fold, epochs):\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
