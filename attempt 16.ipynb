{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79dee4ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Importing necessary modules\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from model_data_definitions import *\n",
    "from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor\n",
    "\n",
    "# Function to generate cross validation dataset\n",
    "def generate_cross_validation_dataset(data, num_folds):\n",
    "    X, y = data.drop('target', axis=1).values, data['target'].values\n",
    "    \n",
    "    dataset_list = []\n",
    "    kf = KFold(n_splits=num_folds)\n",
    "    fold = 0\n",
    "\n",
    "    # Splitting data into training and testing set for each fold in the cross-validation \n",
    "    for train_index, test_index in kf.split(X):\n",
    "        fold += 1\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        X_train, X_test = preprocess_data(X_train, X_test)\n",
    "        y_train, y_test = preprocess_target_values(y_train, y_test)\n",
    "        \n",
    "        dataset_list.append((X_train, y_train, X_test, y_test , fold))\n",
    "    \n",
    "    return dataset_list\n",
    "\n",
    "# Function to train and evaluate model\n",
    "def train_evaluate_model(model_tuple, fold_data, epoch_number, dataset_name,num_folds):\n",
    "    \n",
    "    model, name = model_tuple\n",
    "    X_train, y_train, X_test, y_test , fold = fold_data\n",
    "    \n",
    "    # Training the model \n",
    "    history = model.fit(X_train,\n",
    "                        y_train,\n",
    "                        epochs=epoch_number,\n",
    "                        verbose=0,\n",
    "                        validation_data=(X_test,y_test))\n",
    "\n",
    "     # Evaluating the trained model on test data \n",
    "    loss = model.evaluate(X_test,y_test)\n",
    "\n",
    "     # Making predictions on the test data \n",
    "    predictions = model.predict(X_test)\n",
    "    \n",
    "     # Calculate metrics \n",
    "    r_squared_value=r2_score(y_true=y_test,y_pred=predictions)\n",
    "    test_error=mean_squared_error(y_true=y_test,y_pred=predictions)\n",
    "\n",
    "    results = {\n",
    "        'model': name,\n",
    "        'fold': fold,\n",
    "        'train_history': history.history['loss'],\n",
    "        'val_history': history.history['val_loss'],\n",
    "        'loss': loss,\n",
    "        'r_squared_value': r_squared_value,\n",
    "        'test_error': test_error}\n",
    "\n",
    "    # Save results to numpy file\n",
    "    if not os.path.exists('aggregate_results'):\n",
    "        os.makedirs('aggregate_results')\n",
    "\n",
    "    np.save(f'aggregate_results/{dataset_name}-{name}-epochs-{epoch_number}-fold-{fold}-of-{num_folds}.npy', results)\n",
    "\n",
    "# Function to evaluate models in parallel\n",
    "def evaluate_models_parallel(fold_data, dataset_name, epoch_number,num_folds):\n",
    "    \n",
    "    models = initialize_all_models(fold_data[0].shape[1], seed_val=fold_data[4])\n",
    "    compile_models(models)\n",
    "\n",
    "     # Training and evaluating all models in parallel using ThreadPoolExecutor \n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        futures = {executor.submit(train_evaluate_model, \n",
    "                                   model, \n",
    "                                   fold_data, \n",
    "                                   epoch_number, \n",
    "                                   dataset_name,\n",
    "                                   num_folds): model for model in models}\n",
    "        for future in futures:\n",
    "            future.result()  # Just to make sure all tasks are finished\n",
    "\n",
    "# Function to evaluate all folds in parallel\n",
    "def evaluate_all_folds_parallel(kfold_datasets, dataset_name, epoch_number,num_folds):\n",
    "    \n",
    "     # Evaluating all folds in parallel using ThreadPoolExecutor \n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        futures = {executor.submit(evaluate_models_parallel, \n",
    "                                   fold_data, \n",
    "                                   dataset_name, \n",
    "                                   epoch_number,\n",
    "                                   num_folds): fold_data for fold_data in kfold_datasets}\n",
    "        for future in futures:\n",
    "            future.result()  # Just to make sure all tasks are finished\n",
    "\n",
    "# New function to retrieve all datasets and their names and feed it to relevant functions with a for loop.\n",
    "def retrieve_datasets_and_run_evaluations(num_folds=5, epoch_number=100):\n",
    "    # Fetching data \n",
    "    filtered_datasets_metadata, datasets = fetch_return_filtered_pmlb_data_sets()\n",
    "\n",
    "    for dataset, row in zip(datasets, filtered_datasets_metadata.iterrows()):\n",
    "        dataset_name = row[1]['dataset']\n",
    "        kfold_datasets = generate_cross_validation_dataset(dataset, num_folds)\n",
    "        evaluate_all_folds_parallel(kfold_datasets, dataset_name, epoch_number,num_folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8fcdb3e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>n_instances</th>\n",
       "      <th>n_features</th>\n",
       "      <th>n_binary_features</th>\n",
       "      <th>n_categorical_features</th>\n",
       "      <th>n_continuous_features</th>\n",
       "      <th>endpoint_type</th>\n",
       "      <th>n_classes</th>\n",
       "      <th>imbalance</th>\n",
       "      <th>task</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1027_ESL</td>\n",
       "      <td>488</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>continuous</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.099363</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1029_LEV</td>\n",
       "      <td>1000</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>continuous</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.111245</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1030_ERA</td>\n",
       "      <td>1000</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>continuous</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.031251</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1096_FacultySalaries</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>continuous</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.004063</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>192_vineyard</td>\n",
       "      <td>52</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>continuous</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.040475</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>228_elusage</td>\n",
       "      <td>55</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>continuous</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.000953</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>230_machine_cpu</td>\n",
       "      <td>209</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>continuous</td>\n",
       "      <td>116.0</td>\n",
       "      <td>0.004906</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>485_analcatdata_vehicle</td>\n",
       "      <td>48</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>continuous</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0.000434</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>519_vinnie</td>\n",
       "      <td>380</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>continuous</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.030146</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>523_analcatdata_neavote</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>continuous</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.136914</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>529_pollen</td>\n",
       "      <td>3848</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>continuous</td>\n",
       "      <td>3784.0</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>556_analcatdata_apnea2</td>\n",
       "      <td>475</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>continuous</td>\n",
       "      <td>178.0</td>\n",
       "      <td>0.272393</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>557_analcatdata_apnea1</td>\n",
       "      <td>475</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>continuous</td>\n",
       "      <td>164.0</td>\n",
       "      <td>0.325260</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>579_fri_c0_250_5</td>\n",
       "      <td>250</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>continuous</td>\n",
       "      <td>250.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>594_fri_c2_100_5</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>continuous</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>596_fri_c2_250_5</td>\n",
       "      <td>250</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>continuous</td>\n",
       "      <td>250.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>597_fri_c2_500_5</td>\n",
       "      <td>500</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>continuous</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>599_fri_c2_1000_5</td>\n",
       "      <td>1000</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>continuous</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>601_fri_c1_250_5</td>\n",
       "      <td>250</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>continuous</td>\n",
       "      <td>250.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>609_fri_c0_1000_5</td>\n",
       "      <td>1000</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>continuous</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>611_fri_c3_100_5</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>continuous</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>612_fri_c1_1000_5</td>\n",
       "      <td>1000</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>continuous</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>613_fri_c3_250_5</td>\n",
       "      <td>250</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>continuous</td>\n",
       "      <td>250.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>617_fri_c3_500_5</td>\n",
       "      <td>500</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>continuous</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>624_fri_c0_100_5</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>continuous</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>628_fri_c3_1000_5</td>\n",
       "      <td>1000</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>continuous</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>631_fri_c1_500_5</td>\n",
       "      <td>500</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>continuous</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>649_fri_c0_500_5</td>\n",
       "      <td>500</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>continuous</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>656_fri_c1_100_5</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>continuous</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>663_rabe_266</td>\n",
       "      <td>120</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>continuous</td>\n",
       "      <td>96.0</td>\n",
       "      <td>0.001825</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>665_sleuth_case2002</td>\n",
       "      <td>147</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>continuous</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.096020</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>678_visualizing_environmental</td>\n",
       "      <td>111</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>continuous</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.019608</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>687_sleuth_ex1605</td>\n",
       "      <td>62</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>continuous</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.006465</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>690_visualizing_galaxy</td>\n",
       "      <td>323</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>continuous</td>\n",
       "      <td>208.0</td>\n",
       "      <td>0.001246</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>706_sleuth_case1202</td>\n",
       "      <td>93</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>continuous</td>\n",
       "      <td>79.0</td>\n",
       "      <td>0.001583</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>712_chscase_geyser1</td>\n",
       "      <td>222</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>continuous</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.012844</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>banana</td>\n",
       "      <td>5300</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>continuous</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.010691</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>titanic</td>\n",
       "      <td>2201</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>continuous</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.125266</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           dataset  n_instances  n_features  \\\n",
       "0                         1027_ESL          488           4   \n",
       "2                         1029_LEV         1000           4   \n",
       "3                         1030_ERA         1000           4   \n",
       "5             1096_FacultySalaries           50           4   \n",
       "13                    192_vineyard           52           2   \n",
       "23                     228_elusage           55           2   \n",
       "25                 230_machine_cpu          209           6   \n",
       "29         485_analcatdata_vehicle           48           4   \n",
       "32                      519_vinnie          380           2   \n",
       "34         523_analcatdata_neavote          100           2   \n",
       "36                      529_pollen         3848           4   \n",
       "40          556_analcatdata_apnea2          475           3   \n",
       "41          557_analcatdata_apnea1          475           3   \n",
       "48                579_fri_c0_250_5          250           5   \n",
       "60                594_fri_c2_100_5          100           5   \n",
       "62                596_fri_c2_250_5          250           5   \n",
       "63                597_fri_c2_500_5          500           5   \n",
       "65               599_fri_c2_1000_5         1000           5   \n",
       "66                601_fri_c1_250_5          250           5   \n",
       "74               609_fri_c0_1000_5         1000           5   \n",
       "75                611_fri_c3_100_5          100           5   \n",
       "76               612_fri_c1_1000_5         1000           5   \n",
       "77                613_fri_c3_250_5          250           5   \n",
       "80                617_fri_c3_500_5          500           5   \n",
       "86                624_fri_c0_100_5          100           5   \n",
       "89               628_fri_c3_1000_5         1000           5   \n",
       "90                631_fri_c1_500_5          500           5   \n",
       "102               649_fri_c0_500_5          500           5   \n",
       "107               656_fri_c1_100_5          100           5   \n",
       "111                   663_rabe_266          120           2   \n",
       "112            665_sleuth_case2002          147           6   \n",
       "114  678_visualizing_environmental          111           3   \n",
       "115              687_sleuth_ex1605           62           5   \n",
       "116         690_visualizing_galaxy          323           4   \n",
       "118            706_sleuth_case1202           93           6   \n",
       "119            712_chscase_geyser1          222           2   \n",
       "155                         banana         5300           2   \n",
       "270                        titanic         2201           3   \n",
       "\n",
       "     n_binary_features  n_categorical_features  n_continuous_features  \\\n",
       "0                    0                       0                      4   \n",
       "2                    0                       0                      4   \n",
       "3                    0                       0                      4   \n",
       "5                    0                       0                      4   \n",
       "13                   0                       0                      2   \n",
       "23                   0                       0                      2   \n",
       "25                   0                       0                      6   \n",
       "29                   0                       0                      4   \n",
       "32                   0                       0                      2   \n",
       "34                   0                       0                      2   \n",
       "36                   0                       0                      4   \n",
       "40                   0                       0                      3   \n",
       "41                   0                       0                      3   \n",
       "48                   0                       0                      5   \n",
       "60                   0                       0                      5   \n",
       "62                   0                       0                      5   \n",
       "63                   0                       0                      5   \n",
       "65                   0                       0                      5   \n",
       "66                   0                       0                      5   \n",
       "74                   0                       0                      5   \n",
       "75                   0                       0                      5   \n",
       "76                   0                       0                      5   \n",
       "77                   0                       0                      5   \n",
       "80                   0                       0                      5   \n",
       "86                   0                       0                      5   \n",
       "89                   0                       0                      5   \n",
       "90                   0                       0                      5   \n",
       "102                  0                       0                      5   \n",
       "107                  0                       0                      5   \n",
       "111                  0                       0                      2   \n",
       "112                  0                       0                      6   \n",
       "114                  0                       0                      3   \n",
       "115                  0                       0                      5   \n",
       "116                  0                       0                      4   \n",
       "118                  0                       0                      6   \n",
       "119                  0                       0                      2   \n",
       "155                  0                       0                      2   \n",
       "270                  0                       0                      3   \n",
       "\n",
       "    endpoint_type  n_classes  imbalance        task  \n",
       "0      continuous        9.0   0.099363  regression  \n",
       "2      continuous        5.0   0.111245  regression  \n",
       "3      continuous        9.0   0.031251  regression  \n",
       "5      continuous       39.0   0.004063  regression  \n",
       "13     continuous       19.0   0.040475  regression  \n",
       "23     continuous       52.0   0.000953  regression  \n",
       "25     continuous      116.0   0.004906  regression  \n",
       "29     continuous       47.0   0.000434  regression  \n",
       "32     continuous       16.0   0.030146  regression  \n",
       "34     continuous        8.0   0.136914  regression  \n",
       "36     continuous     3784.0   0.000004  regression  \n",
       "40     continuous      178.0   0.272393  regression  \n",
       "41     continuous      164.0   0.325260  regression  \n",
       "48     continuous      250.0   0.000000  regression  \n",
       "60     continuous      100.0   0.000000  regression  \n",
       "62     continuous      250.0   0.000000  regression  \n",
       "63     continuous      500.0   0.000000  regression  \n",
       "65     continuous     1000.0   0.000000  regression  \n",
       "66     continuous      250.0   0.000000  regression  \n",
       "74     continuous     1000.0   0.000000  regression  \n",
       "75     continuous      100.0   0.000000  regression  \n",
       "76     continuous     1000.0   0.000000  regression  \n",
       "77     continuous      250.0   0.000000  regression  \n",
       "80     continuous      500.0   0.000000  regression  \n",
       "86     continuous      100.0   0.000000  regression  \n",
       "89     continuous     1000.0   0.000000  regression  \n",
       "90     continuous      500.0   0.000000  regression  \n",
       "102    continuous      500.0   0.000000  regression  \n",
       "107    continuous      100.0   0.000000  regression  \n",
       "111    continuous       96.0   0.001825  regression  \n",
       "112    continuous       19.0   0.096020  regression  \n",
       "114    continuous       28.0   0.019608  regression  \n",
       "115    continuous       41.0   0.006465  regression  \n",
       "116    continuous      208.0   0.001246  regression  \n",
       "118    continuous       79.0   0.001583  regression  \n",
       "119    continuous       50.0   0.012844  regression  \n",
       "155    continuous        2.0   0.010691  regression  \n",
       "270    continuous        2.0   0.125266  regression  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_datasets_metadata, datasets = fetch_return_filtered_pmlb_data_sets()\n",
    "filtered_datasets_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55886022",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 36ms/step - loss: 0.6726\n",
      "8/8 [==============================] - 0s 43ms/step - loss: 0.3224\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.4220\n",
      "8/8 [==============================] - 0s 11ms/step\n",
      "8/8 [==============================] - 0s 8ms/step\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.3878\n",
      "8/8 [==============================] - 0s 11ms/step\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.8908\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.8894\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.8899\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.8902\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.7485\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.8823\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.7476\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.8877\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.7425\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.7537\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.7543\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.7511\n",
      "8/8 [==============================] - 1s 14ms/step\n",
      "8/8 [==============================] - 1s 22ms/step\n",
      "8/8 [==============================] - 1s 16ms/step\n",
      "8/8 [==============================] - 1s 21ms/step\n",
      "8/8 [==============================] - 1s 12ms/step\n",
      "8/8 [==============================] - 1s 15ms/step\n",
      "8/8 [==============================] - 1s 10ms/step\n",
      "8/8 [==============================] - 1s 14ms/step\n",
      "8/8 [==============================] - 1s 12ms/step\n",
      "8/8 [==============================] - 1s 22ms/step\n",
      "8/8 [==============================] - 1s 19ms/step\n",
      "8/8 [==============================] - 1s 15ms/step\n",
      "8/8 [==============================] - 3s 12ms/step\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.7035\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.7391\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.8576\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.8583\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.7394\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.7173\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.7563\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.7436\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.8639\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.8719\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.8801\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.7183\n",
      "8/8 [==============================] - 2s 3ms/step\n",
      "8/8 [==============================] - 2s 4ms/step\n",
      "8/8 [==============================] - 2s 6ms/step\n",
      "8/8 [==============================] - 2s 8ms/step\n",
      "8/8 [==============================] - 2s 6ms/step\n",
      "8/8 [==============================] - 2s 4ms/step\n",
      "8/8 [==============================] - 2s 9ms/step\n",
      "8/8 [==============================] - 2s 4ms/step\n",
      "8/8 [==============================] - 2s 2ms/step\n",
      "8/8 [==============================] - 2s 3ms/step\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.8075\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.6972\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.8177\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.6854\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.7224\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.8590\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.7144\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.6611\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.8119\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.8115\n",
      "8/8 [==============================] - 2s 5ms/step\n",
      "8/8 [==============================] - 2s 5ms/step\n",
      "8/8 [==============================] - 2s 4ms/step\n",
      "8/8 [==============================] - 2s 4ms/step\n",
      "8/8 [==============================] - 2s 3ms/step\n",
      "8/8 [==============================] - 2s 3ms/step\n",
      "8/8 [==============================] - 2s 3ms/step\n",
      "8/8 [==============================] - 2s 2ms/step\n",
      "8/8 [==============================] - 2s 3ms/step\n",
      "8/8 [==============================] - 2s 1ms/step\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.7994\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.5882\n",
      "16/16 [==============================] - 1s 10ms/step\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.5877\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.8234\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.8122\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.8159\n",
      "16/16 [==============================] - 1s 9ms/steposs: 0.83\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.8212\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.8207\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.8119\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.5734\n",
      "16/16 [==============================] - 0s 14ms/step\n",
      "16/16 [==============================] - 1s 11ms/stepss: 0.\n",
      "16/16 [==============================] - 1s 10ms/stepss: 0.\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.7862\n",
      "16/16 [==============================] - 1s 17ms/stepss: 0.76\n",
      "16/16 [==============================] - 1s 15ms/stepss: 0.75\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.7911\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.7844\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.7814\n",
      "16/16 [==============================] - 1s 15ms/stepss: 0.769\n",
      "16/16 [==============================] - 1s 20ms/step\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.7810\n",
      "16/16 [==============================] - 1s 16ms/step\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.7878\n",
      "16/16 [==============================] - 1s 9ms/step\n",
      "16/16 [==============================] - 1s 11ms/step\n",
      "16/16 [==============================] - 1s 15ms/step\n",
      "16/16 [==============================] - 1s 12ms/step\n",
      "16/16 [==============================] - 1s 16ms/step\n",
      "16/16 [==============================] - 1s 17ms/step\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.7666\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.7520\n",
      "16/16 [==============================] - 1s 3ms/step\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.8237\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.8162\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.8006\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.8000\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.8068\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.7859\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.7643\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.7730\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.7681\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.7791\n",
      "16/16 [==============================] - 2s 3ms/step\n",
      "16/16 [==============================] - 2s 4ms/step\n",
      "16/16 [==============================] - 2s 4ms/step\n",
      "16/16 [==============================] - 2s 3ms/step\n",
      "16/16 [==============================] - 2s 2ms/step\n",
      "16/16 [==============================] - 1s 5ms/step\n",
      "16/16 [==============================] - 1s 6ms/step\n",
      "16/16 [==============================] - 1s 4ms/step\n",
      "16/16 [==============================] - 1s 4ms/step\n",
      "16/16 [==============================] - 1s 3ms/step\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.7512\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.7641\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.7478\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 8ms/step - loss: 0.7593\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.7726\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.7145\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.7171\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.7296\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.7055\n",
      "16/16 [==============================] - 2s 4ms/step\n",
      "16/16 [==============================] - 2s 5ms/step\n",
      "16/16 [==============================] - 2s 5ms/step\n",
      "16/16 [==============================] - 2s 6ms/step\n",
      "16/16 [==============================] - 2s 4ms/step\n",
      "16/16 [==============================] - 2s 4ms/step\n",
      "16/16 [==============================] - 2s 5ms/step\n",
      "16/16 [==============================] - 2s 3ms/step\n",
      "16/16 [==============================] - 2s 3ms/step\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.7232\n",
      "16/16 [==============================] - 0s 1ms/step\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.6305\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.8493\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.7284\n",
      "16/16 [==============================] - 1s 16ms/stepss: 0.\n",
      "16/16 [==============================] - 1s 14ms/step\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.6287\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.8787\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.8883\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.8882\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.7836\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.7762\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.7768\n",
      "16/16 [==============================] - 1s 15ms/stepss: 0.88\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.8803\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.8803\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.7744\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.8852\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.7765\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.7834\n",
      "16/16 [==============================] - 1s 12ms/step\n",
      "16/16 [==============================] - 1s 15ms/step\n",
      "16/16 [==============================] - 1s 12ms/step\n",
      "16/16 [==============================] - 1s 13ms/step\n",
      "16/16 [==============================] - 1s 18ms/step\n",
      "16/16 [==============================] - 1s 18ms/step\n",
      "16/16 [==============================] - 1s 19ms/step\n",
      "16/16 [==============================] - 1s 23ms/step\n",
      "16/16 [==============================] - 1s 18ms/step\n",
      "16/16 [==============================] - 1s 17ms/step\n",
      "16/16 [==============================] - 1s 19ms/step\n",
      "16/16 [==============================] - 1s 20ms/step\n",
      "16/16 [==============================] - 1s 20ms/step\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.8720\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7662\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.7742\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.8805\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.7615\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.7743\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.8832\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.8833\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.8837\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.7703\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.8790\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.7696\n",
      "16/16 [==============================] - 2s 2ms/step\n",
      " 1/16 [>.............................] - ETA: 26sWARNING:tensorflow:5 out of the last 23 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001D6850D9000> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      " 4/16 [======>.......................] - ETA: 0s WARNING:tensorflow:6 out of the last 26 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001D6A40BF2E0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "16/16 [==============================] - 2s 8ms/step\n",
      "16/16 [==============================] - 2s 6ms/step\n",
      "16/16 [==============================] - 2s 6ms/step\n",
      "16/16 [==============================] - 2s 8ms/step\n",
      "16/16 [==============================] - 2s 10ms/step\n",
      "16/16 [==============================] - 2s 6ms/step\n",
      "16/16 [==============================] - 2s 6ms/step\n",
      "16/16 [==============================] - 2s 7ms/step\n",
      "16/16 [==============================] - 2s 4ms/step\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.7406\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.8691\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.8640\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.8567\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.8661\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.7533\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.7397\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.7490\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.7538\n",
      "16/16 [==============================] - 2s 2ms/step\n",
      "16/16 [==============================] - 2s 4ms/step\n",
      "16/16 [==============================] - 2s 3ms/step\n",
      "16/16 [==============================] - 1s 3ms/step\n",
      "16/16 [==============================] - 2s 3ms/step\n",
      "16/16 [==============================] - 2s 4ms/step\n",
      "16/16 [==============================] - 2s 4ms/step\n",
      "16/16 [==============================] - 2s 3ms/step\n",
      "16/16 [==============================] - 2s 4ms/step\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.8609\n",
      "16/16 [==============================] - 0s 1ms/step\n",
      "WARNING:tensorflow:5 out of the last 20 calls to <function Model.make_train_function.<locals>.train_function at 0x000001D6FFA44E50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 21 calls to <function Model.make_train_function.<locals>.train_function at 0x000001D6A532B1C0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4437\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.9556\n",
      "WARNING:tensorflow:5 out of the last 38 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D70D4ED000> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9181\n",
      "1/1 [==============================] - 0s 250ms/step\n",
      "WARNING:tensorflow:6 out of the last 40 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D694AECCA0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 235ms/step\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.8623\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.7834\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.9424\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.7976\n",
      "1/1 [==============================] - 0s 356ms/step\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.7955\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.9602\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.7814\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.7958\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.9388\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.9376\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.9596\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.9602\n",
      "1/1 [==============================] - 0s 429ms/step\n",
      "1/1 [==============================] - 1s 509ms/step\n",
      "1/1 [==============================] - 1s 577ms/step\n",
      "1/1 [==============================] - 1s 540ms/step\n",
      "1/1 [==============================] - 1s 527ms/step\n",
      "1/1 [==============================] - 1s 523ms/step\n",
      "1/1 [==============================] - 1s 631ms/step\n",
      "1/1 [==============================] - 1s 549ms/step\n",
      "1/1 [==============================] - 0s 447ms/step\n",
      "1/1 [==============================] - 1s 521ms/step\n",
      "1/1 [==============================] - 1s 552ms/step\n",
      "1/1 [==============================] - 0s 474ms/step\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.9407\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.6870\n",
      "1/1 [==============================] - 0s 415ms/step\n",
      "1/1 [==============================] - 0s 377ms/step\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.8083\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.9544\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.7953\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.9699\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.9552\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.8104\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.7746\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.8179\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.9321\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.9242\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.9725\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.0070\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.9623\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.7964\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8052\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.7490\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.9206\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.8049\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.7611\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.9655\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.7834\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 1.2020\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.7097\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.2894\n",
      "1/1 [==============================] - 0s 405ms/step\n",
      "1/1 [==============================] - 0s 308ms/step\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7428\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.8091\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 1.8076\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.8091\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.7824\n",
      "1/1 [==============================] - 0s 463ms/step\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.3762\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.4226\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.3762\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.7990\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.7926\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.3972\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.4164\n",
      "1/1 [==============================] - 0s 484ms/step\n",
      "1/1 [==============================] - 0s 482ms/steps: 1.40\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.4020\n",
      "1/1 [==============================] - 1s 536ms/step\n",
      "1/1 [==============================] - 1s 515ms/step\n",
      "1/1 [==============================] - 0s 488ms/step\n",
      "1/1 [==============================] - 1s 516ms/step\n",
      "1/1 [==============================] - 1s 515ms/step\n",
      "1/1 [==============================] - 1s 560ms/step\n",
      "1/1 [==============================] - 1s 537ms/step\n",
      "1/1 [==============================] - 1s 526ms/step\n",
      "1/1 [==============================] - 0s 449ms/step\n",
      "1/1 [==============================] - 0s 427ms/step\n",
      "1/1 [==============================] - 0s 416ms/step\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.2676\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.7836\n",
      "1/1 [==============================] - 0s 498ms/step\n",
      "1/1 [==============================] - 0s 371ms/step\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.8064\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.3980\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 70ms/step - loss: 1.4052\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.8068\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.7847\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.7776\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.4440\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1.4141\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.8033\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.4124\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.8123\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.3605\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.7991\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.8050\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.3887\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.8227\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 1.7911\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.3125\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.4108\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.4376\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.3544\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.1975\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 1.3522\n",
      "1/1 [==============================] - 0s 457ms/step\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.1401\n",
      "1/1 [==============================] - 0s 271ms/step\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.9334\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.9316\n",
      "1/1 [==============================] - 0s 404ms/step\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.9334\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.8621\n",
      "1/1 [==============================] - 0s 355ms/step\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.8396\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.8627\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.9328\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.9223\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.8587\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.8621\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.8418\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.9383\n",
      "1/1 [==============================] - 0s 471ms/step\n",
      "1/1 [==============================] - 0s 487ms/step\n",
      "1/1 [==============================] - 0s 485ms/step\n",
      "1/1 [==============================] - 0s 404ms/step\n",
      "1/1 [==============================] - 0s 499ms/step\n",
      "1/1 [==============================] - 1s 510ms/step\n",
      "1/1 [==============================] - 0s 465ms/step\n",
      "1/1 [==============================] - 1s 544ms/step\n",
      "1/1 [==============================] - 1s 533ms/step\n",
      "1/1 [==============================] - 0s 448ms/step\n",
      "1/1 [==============================] - 0s 498ms/step\n",
      "1/1 [==============================] - 0s 494ms/step\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.9382\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.8919\n",
      "1/1 [==============================] - 0s 386ms/step\n",
      "1/1 [==============================] - 0s 344ms/step\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.8566\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.9360\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.9345\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.8544\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.8361\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.9358\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.9233\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.8477\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.9332\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.8744\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.8465\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9362\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.8296\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.9026\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.8252\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.9155\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.8507\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9516\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.9205\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8274\n",
      "1/1 [==============================] - 0s 98ms/step\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.3897\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.8025\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.5529\n",
      "4/4 [==============================] - 0s 5ms/step\n",
      "4/4 [==============================] - 0s 7ms/step\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.5691\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6239\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.5874\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.6084\n",
      "4/4 [==============================] - 0s 16ms/step\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.6160\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.6214\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.6051\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.6215\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.5923\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.6038\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.5891\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.5842\n",
      "4/4 [==============================] - 1s 12ms/step\n",
      "4/4 [==============================] - 1s 12ms/step\n",
      "4/4 [==============================] - 1s 33ms/step\n",
      "4/4 [==============================] - 1s 43ms/step\n",
      "4/4 [==============================] - 1s 16ms/step\n",
      "4/4 [==============================] - 1s 13ms/step\n",
      "4/4 [==============================] - 1s 31ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 27ms/step\n",
      "4/4 [==============================] - 1s 11ms/step\n",
      "4/4 [==============================] - 1s 31ms/step\n",
      "4/4 [==============================] - 1s 16ms/step\n",
      "4/4 [==============================] - 1s 13ms/step\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.5628\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6030\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "4/4 [==============================] - 0s 5ms/step\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.5906\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.5847\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.5873\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.5731\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.5964\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.5654\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.5560\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.6273\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.5542\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.5820\n",
      "4/4 [==============================] - 3s 4ms/step\n",
      "4/4 [==============================] - 2s 3ms/step\n",
      "4/4 [==============================] - 2s 8ms/step\n",
      "4/4 [==============================] - 2s 5ms/step\n",
      "4/4 [==============================] - 2s 9ms/step\n",
      "4/4 [==============================] - 2s 7ms/step\n",
      "4/4 [==============================] - 2s 5ms/step\n",
      "4/4 [==============================] - 2s 3ms/step\n",
      "4/4 [==============================] - 1s 4ms/step\n",
      "4/4 [==============================] - 1s 3ms/step\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.5899\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6712\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5910\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5027\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5228\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.5847\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4737\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6139\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5313\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5802\n",
      "4/4 [==============================] - 2s 7ms/step\n",
      "4/4 [==============================] - 2s 9ms/step\n",
      "4/4 [==============================] - 2s 2ms/step\n",
      "4/4 [==============================] - 2s 3ms/step\n",
      "4/4 [==============================] - 2s 4ms/step\n",
      "4/4 [==============================] - 2s 3ms/step\n",
      "4/4 [==============================] - 2s 3ms/step\n",
      "4/4 [==============================] - 2s 5ms/step\n",
      "4/4 [==============================] - 2s 4ms/step\n",
      "4/4 [==============================] - 2s 5ms/step\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6038\n",
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "# Call the new function \n",
    "start_time = time.time()\n",
    "retrieve_datasets_and_run_evaluations(num_folds=2, epoch_number=1)\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"The experiment took {elapsed_time} seconds to complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c075d92e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Call the new function \n",
    "start_time = time.time()\n",
    "retrieve_datasets_and_run_evaluations(num_folds=5, epoch_number=1)\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"The experiment took {elapsed_time} seconds to complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c42c9a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Call the new function \n",
    "start_time = time.time()\n",
    "retrieve_datasets_and_run_evaluations(num_folds=10, epoch_number=1)\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"The experiment took {elapsed_time} seconds to complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb602f5d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Call the new function \n",
    "start_time = time.time()\n",
    "retrieve_datasets_and_run_evaluations(num_folds=10, epoch_number=5)\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"The experiment took {elapsed_time} seconds to complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7595e798",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Call the new function \n",
    "start_time = time.time()\n",
    "retrieve_datasets_and_run_evaluations(num_folds=10, epoch_number=10)\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"The experiment took {elapsed_time} seconds to complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0591b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Call the new function \n",
    "start_time = time.time()\n",
    "retrieve_datasets_and_run_evaluations(num_folds=10, epoch_number=20)\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"The experiment took {elapsed_time} seconds to complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3f5010",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Call the new function \n",
    "start_time = time.time()\n",
    "retrieve_datasets_and_run_evaluations(num_folds=10, epoch_number=40)\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"The experiment took {elapsed_time} seconds to complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557ecdbd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Call the new function \n",
    "start_time = time.time()\n",
    "retrieve_datasets_and_run_evaluations(num_folds=10, epoch_number=100)\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"The experiment took {elapsed_time} seconds to complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3dd9e56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
